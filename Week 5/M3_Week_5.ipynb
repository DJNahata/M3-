{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M3 Week 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiEnls6qd62k"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "import os\r\n",
        "import keras\r\n",
        "\r\n",
        "class DataRetrieval():\r\n",
        "    \"\"\"CLASS:DataRetrieval\"\"\"\r\n",
        "    def __init__(self, data_dir):\r\n",
        "        self.data_dir = data_dir\r\n",
        "    \r\n",
        "    def get_train_data(self, augmentation=True, img_input=(256,256), batch_size=16):\r\n",
        "        if augmentation:\r\n",
        "            datagen = ImageDataGenerator(\r\n",
        "                featurewise_center=False,\r\n",
        "                samplewise_center=False,\r\n",
        "                featurewise_std_normalization=False,\r\n",
        "                samplewise_std_normalization=False, \r\n",
        "                rotation_range=5,\r\n",
        "                width_shift_range=0.2,\r\n",
        "                height_shift_range=0.2,\r\n",
        "                shear_range=0.,\r\n",
        "                zoom_range=0.2,\r\n",
        "                fill_mode='nearest',\r\n",
        "                horizontal_flip=True,\r\n",
        "                vertical_flip=False,\r\n",
        "                rescale=1./255\r\n",
        "            )\r\n",
        "        else:\r\n",
        "            datagen = ImageDataGenerator(\r\n",
        "                featurewise_center=False,\r\n",
        "                samplewise_center=False,\r\n",
        "                featurewise_std_normalization=False,\r\n",
        "                samplewise_std_normalization=False,\r\n",
        "            )\r\n",
        "        return datagen.flow_from_directory(\r\n",
        "            self.data_dir+os.sep+'train',\r\n",
        "            target_size=img_input,\r\n",
        "            batch_size=batch_size,\r\n",
        "            class_mode='categorical'\r\n",
        "        )\r\n",
        "\r\n",
        "    def get_validation_data(self, img_input=(256,256), batch_size=16):\r\n",
        "        datagen = ImageDataGenerator(\r\n",
        "            featurewise_center=False,\r\n",
        "            samplewise_center=False,\r\n",
        "            featurewise_std_normalization=False,\r\n",
        "            samplewise_std_normalization=False,\r\n",
        "            rescale=1./255\r\n",
        "        )\r\n",
        "        return datagen.flow_from_directory(\r\n",
        "            self.data_dir+os.sep+'test',\r\n",
        "            target_size=img_input,\r\n",
        "            batch_size=batch_size,\r\n",
        "            class_mode='categorical'\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z61lUvPBRdZk"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "def RoJoPow(input_shape=(256,256,3), optimizer=optimizers.Adam(), dropout=0.5):\r\n",
        "    # -- FIRST BLOCK -- #\r\n",
        "    inputs = layers.Input(shape=input_shape)\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(inputs)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- SECOND BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,32))(y)\r\n",
        "    y = layers.Dense(units=8,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=32,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- THIRD BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,64))(y)\r\n",
        "    y = layers.Dense(units=16,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=64,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- FOURTH BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,64))(y)\r\n",
        "    y = layers.Dense(units=16,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=64,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- FIFTH BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,128))(y)\r\n",
        "    y = layers.Dense(units=32,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=128,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- SIXTH BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,128))(y)\r\n",
        "    y = layers.Dense(units=32,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=128,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- DECISION BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=8, kernel_size=1, strides=1, padding='valid')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,8))(y)\r\n",
        "    y = layers.Dense(units=8,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=8,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = layers.Activation('softmax')(x)\r\n",
        "\r\n",
        "    model = models.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZPIomMt4wVI",
        "outputId": "4f1454b4-9302-4d0e-dd62-e12a64d04bc9"
      },
      "source": [
        "model = final()\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 256, 256, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 128, 128, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 128, 128, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 32, 32, 8)         1032      \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_10  (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "activation_54 (Activation)   (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 299,240\n",
            "Trainable params: 298,264\n",
            "Non-trainable params: 976\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP-X_21HjsXN"
      },
      "source": [
        "def RoJoPow2(input_shape=(256,256,3), optimizer=optimizers.Adam(), dropout=0.5):\r\n",
        "    # -- FIRST BLOCK -- #\r\n",
        "    inputs = layers.Input(shape=input_shape)\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(inputs)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- SECOND BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,64))(y)\r\n",
        "    y = layers.Dense(units=16,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=64,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- THIRD BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,128))(y)\r\n",
        "    y = layers.Dense(units=32,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=128,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- FOURTH BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,128))(y)\r\n",
        "    y = layers.Dense(units=32,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=128,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "    # -- DECISION BLOCK -- #\r\n",
        "    x = layers.Conv2D(filters=8, kernel_size=1, strides=1, padding='valid')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    y = layers.GlobalAveragePooling2D()(x)\r\n",
        "    y = layers.Reshape((1,1,8))(y)\r\n",
        "    y = layers.Dense(units=8,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('relu')(y)\r\n",
        "    y = layers.Dense(units=8,kernel_initializer='he_normal')(y)\r\n",
        "    y = layers.Activation('sigmoid')(y)\r\n",
        "    x = layers.multiply([x, y])\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = layers.Activation('softmax')(x)\r\n",
        "\r\n",
        "    model = models.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgZp7YUhoh3c"
      },
      "source": [
        "def mkdir(dirname):\r\n",
        "\r\n",
        "    if os.path.isdir(dirname) and os.path.exists(dirname):\r\n",
        "        return\r\n",
        "\r\n",
        "    if not os.path.isdir(dirname) and os.path.exists(dirname):\r\n",
        "        logging.info(f\"remove file {dirname} and run this script again\")\r\n",
        "\r\n",
        "    os.mkdir(dirname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SosSDqcZju0T"
      },
      "source": [
        "import zipfile\r\n",
        "import os\r\n",
        "\r\n",
        "path = os.getcwd() + '/datasets'\r\n",
        "mkdir(path)\r\n",
        "\r\n",
        "with zipfile.ZipFile(\"MIT_split-20210124T132955Z-001.zip\", 'r') as zip_ref:\r\n",
        "    zip_ref.extractall(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q__-snMfeuLe"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "\r\n",
        "def otherC(input_shape=(256,256,3), optimizer=optimizers.Adam(), dropout=0.5):\r\n",
        "    inputs = layers.Input(shape=input_shape)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(inputs)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Dropout(dropout)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=8, kernel_size=1, strides=1, padding='valid')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = layers.Activation('softmax')(x)\r\n",
        "\r\n",
        "    model = models.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUU3wrt7-wbf"
      },
      "source": [
        "def baselineA(input_shape=(256,256,3), optimizer=optimizers.Adam(), dropout=0.5):\r\n",
        "    inputs = layers.Input(shape=input_shape)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(inputs)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=8, kernel_size=1, strides=1, padding='valid')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = layers.Activation('softmax')(x)\r\n",
        "\r\n",
        "    model = models.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVTtS9CBQCQ9"
      },
      "source": [
        "def baselineB(input_shape=(256,256,3), optimizer=optimizers.Adam(), dropout=0.5):\r\n",
        "    inputs = layers.Input(shape=input_shape)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(inputs)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=8, kernel_size=1, strides=1, padding='valid')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = layers.Activation('softmax')(x)\r\n",
        "\r\n",
        "    model = models.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P4A_DQQrekH"
      },
      "source": [
        "def final(input_shape=(256,256,3), optimizer=optimizers.Adam(), dropout=0.5):\r\n",
        "    inputs = layers.Input(shape=input_shape)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(inputs)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.MaxPooling2D(pool_size=2)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.Dropout(0.5)(x)\r\n",
        "\r\n",
        "    x = layers.Conv2D(filters=8, kernel_size=1, strides=1, padding='valid')(x)\r\n",
        "    x = layers.Activation('relu')(x)\r\n",
        "    x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "    x = layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = layers.Activation('softmax')(x)\r\n",
        "\r\n",
        "    model = models.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCTV6DwlolGk",
        "outputId": "f0b1aef9-68ec-49c6-ca1c-52fc06f4e492"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random\r\n",
        "\r\n",
        "from keras.utils import plot_model\r\n",
        "from keras import optimizers\r\n",
        "from keras import callbacks\r\n",
        "\r\n",
        "#from utils.Data import DataRetrieval\r\n",
        "#from models import *\r\n",
        "\r\n",
        "\r\n",
        "# Parameters\r\n",
        "batch_size = 16\r\n",
        "epochs = 200\r\n",
        "input_shape = (256,256,3)\r\n",
        "learning_rate = 1e-3\r\n",
        "data_dir = '/content/datasets/MIT_split'\r\n",
        "work_dir = '/content/baselineB'\r\n",
        "if not os.path.exists(work_dir):\r\n",
        "    os.makedirs(work_dir)\r\n",
        "\r\n",
        "# Create model\r\n",
        "optimizer = optimizers.Adam(lr=learning_rate)\r\n",
        "model = final(input_shape=input_shape, optimizer=optimizer, dropout=0.6)\r\n",
        "\r\n",
        "# Print model\r\n",
        "model.summary()\r\n",
        "plot_model(model, to_file=work_dir+os.sep+'structure.png', show_shapes=True, show_layer_names=True)\r\n",
        "\r\n",
        "# Prepare data\r\n",
        "DR = DataRetrieval(data_dir)\r\n",
        "train_generator = DR.get_train_data(augmentation=True, batch_size=batch_size)\r\n",
        "validation_generator = DR.get_validation_data(batch_size=batch_size)\r\n",
        "\r\n",
        "# Train model\r\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=10)\r\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20)\r\n",
        "\r\n",
        "history = model.fit_generator(\r\n",
        "    train_generator,\r\n",
        "    steps_per_epoch=(int(train_generator.n//batch_size)),\r\n",
        "    epochs=epochs,\r\n",
        "    validation_data=validation_generator,\r\n",
        "    validation_steps= (int(validation_generator.n//batch_size)),\r\n",
        "    callbacks=[reduce_lr, early_stopping])\r\n",
        "\r\n",
        "# Summarize history for accuracy\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')\r\n",
        "plt.savefig(work_dir+os.sep+'accuracy.jpg')\r\n",
        "plt.close()\r\n",
        "# Summarize history for loss\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')\r\n",
        "plt.savefig(work_dir+os.sep+'loss.jpg')\r\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 8)         1032      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 299,240\n",
            "Trainable params: 298,264\n",
            "Non-trainable params: 976\n",
            "_________________________________________________________________\n",
            "Found 1881 images belonging to 8 classes.\n",
            "Found 807 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "117/117 [==============================] - 38s 255ms/step - loss: 1.7227 - accuracy: 0.3640 - val_loss: 2.9706 - val_accuracy: 0.0938\n",
            "Epoch 2/200\n",
            "117/117 [==============================] - 30s 255ms/step - loss: 1.4248 - accuracy: 0.5754 - val_loss: 3.2072 - val_accuracy: 0.0938\n",
            "Epoch 3/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 1.2970 - accuracy: 0.6554 - val_loss: 2.0973 - val_accuracy: 0.2362\n",
            "Epoch 4/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 1.2216 - accuracy: 0.6595 - val_loss: 1.4140 - val_accuracy: 0.4512\n",
            "Epoch 5/200\n",
            "117/117 [==============================] - 30s 255ms/step - loss: 1.1185 - accuracy: 0.7127 - val_loss: 1.0526 - val_accuracy: 0.6587\n",
            "Epoch 6/200\n",
            "117/117 [==============================] - 30s 255ms/step - loss: 1.0935 - accuracy: 0.7035 - val_loss: 0.9911 - val_accuracy: 0.7000\n",
            "Epoch 7/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 1.0225 - accuracy: 0.7432 - val_loss: 0.8727 - val_accuracy: 0.7225\n",
            "Epoch 8/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.9664 - accuracy: 0.7574 - val_loss: 0.8848 - val_accuracy: 0.7113\n",
            "Epoch 9/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.8939 - accuracy: 0.7765 - val_loss: 0.8888 - val_accuracy: 0.6988\n",
            "Epoch 10/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.9053 - accuracy: 0.7481 - val_loss: 0.8214 - val_accuracy: 0.7450\n",
            "Epoch 11/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.7961 - accuracy: 0.8018 - val_loss: 0.7468 - val_accuracy: 0.7513\n",
            "Epoch 12/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.8041 - accuracy: 0.7907 - val_loss: 0.7288 - val_accuracy: 0.7825\n",
            "Epoch 13/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.7523 - accuracy: 0.8077 - val_loss: 0.8383 - val_accuracy: 0.7212\n",
            "Epoch 14/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.7249 - accuracy: 0.8251 - val_loss: 0.6887 - val_accuracy: 0.7925\n",
            "Epoch 15/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.7255 - accuracy: 0.8208 - val_loss: 0.5379 - val_accuracy: 0.8650\n",
            "Epoch 16/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.7168 - accuracy: 0.8114 - val_loss: 0.5234 - val_accuracy: 0.8438\n",
            "Epoch 17/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.6524 - accuracy: 0.8394 - val_loss: 0.5561 - val_accuracy: 0.8313\n",
            "Epoch 18/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.6335 - accuracy: 0.8343 - val_loss: 0.5463 - val_accuracy: 0.8388\n",
            "Epoch 19/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.5769 - accuracy: 0.8704 - val_loss: 0.6769 - val_accuracy: 0.7563\n",
            "Epoch 20/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.6144 - accuracy: 0.8487 - val_loss: 0.5172 - val_accuracy: 0.8537\n",
            "Epoch 21/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.5432 - accuracy: 0.8705 - val_loss: 0.4774 - val_accuracy: 0.8500\n",
            "Epoch 22/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.5648 - accuracy: 0.8537 - val_loss: 0.6191 - val_accuracy: 0.8075\n",
            "Epoch 23/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.5488 - accuracy: 0.8529 - val_loss: 0.5612 - val_accuracy: 0.8150\n",
            "Epoch 24/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.5075 - accuracy: 0.8717 - val_loss: 0.7236 - val_accuracy: 0.7638\n",
            "Epoch 25/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.5424 - accuracy: 0.8614 - val_loss: 0.4962 - val_accuracy: 0.8475\n",
            "Epoch 26/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.4860 - accuracy: 0.8723 - val_loss: 0.3978 - val_accuracy: 0.8675\n",
            "Epoch 27/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.4844 - accuracy: 0.8685 - val_loss: 0.4463 - val_accuracy: 0.8788\n",
            "Epoch 28/200\n",
            "117/117 [==============================] - 29s 251ms/step - loss: 0.4555 - accuracy: 0.8899 - val_loss: 0.5687 - val_accuracy: 0.8100\n",
            "Epoch 29/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.4608 - accuracy: 0.8720 - val_loss: 0.5509 - val_accuracy: 0.8200\n",
            "Epoch 30/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.4668 - accuracy: 0.8755 - val_loss: 0.5262 - val_accuracy: 0.8313\n",
            "Epoch 31/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.4593 - accuracy: 0.8762 - val_loss: 0.5406 - val_accuracy: 0.8150\n",
            "Epoch 32/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.4192 - accuracy: 0.9056 - val_loss: 0.5613 - val_accuracy: 0.8200\n",
            "Epoch 33/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.4213 - accuracy: 0.8934 - val_loss: 0.7058 - val_accuracy: 0.7425\n",
            "Epoch 34/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.4201 - accuracy: 0.8947 - val_loss: 0.3360 - val_accuracy: 0.8913\n",
            "Epoch 35/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.3646 - accuracy: 0.9077 - val_loss: 0.4716 - val_accuracy: 0.8512\n",
            "Epoch 36/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.3805 - accuracy: 0.9004 - val_loss: 0.5467 - val_accuracy: 0.8300\n",
            "Epoch 37/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.3994 - accuracy: 0.9083 - val_loss: 0.3813 - val_accuracy: 0.8612\n",
            "Epoch 38/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.3680 - accuracy: 0.9030 - val_loss: 0.4068 - val_accuracy: 0.8700\n",
            "Epoch 39/200\n",
            "117/117 [==============================] - 29s 252ms/step - loss: 0.3831 - accuracy: 0.9038 - val_loss: 0.4299 - val_accuracy: 0.8650\n",
            "Epoch 40/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.3680 - accuracy: 0.8994 - val_loss: 0.2966 - val_accuracy: 0.9175\n",
            "Epoch 41/200\n",
            "117/117 [==============================] - 29s 252ms/step - loss: 0.3360 - accuracy: 0.9215 - val_loss: 0.3453 - val_accuracy: 0.8963\n",
            "Epoch 42/200\n",
            "117/117 [==============================] - 29s 252ms/step - loss: 0.3561 - accuracy: 0.9150 - val_loss: 0.3158 - val_accuracy: 0.8963\n",
            "Epoch 43/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.3536 - accuracy: 0.9125 - val_loss: 0.3334 - val_accuracy: 0.9000\n",
            "Epoch 44/200\n",
            "117/117 [==============================] - 29s 251ms/step - loss: 0.3398 - accuracy: 0.9173 - val_loss: 0.3127 - val_accuracy: 0.8938\n",
            "Epoch 45/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.3002 - accuracy: 0.9273 - val_loss: 0.3416 - val_accuracy: 0.8825\n",
            "Epoch 46/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.3128 - accuracy: 0.9268 - val_loss: 0.3770 - val_accuracy: 0.8838\n",
            "Epoch 47/200\n",
            "117/117 [==============================] - 29s 251ms/step - loss: 0.3150 - accuracy: 0.9274 - val_loss: 0.4006 - val_accuracy: 0.8712\n",
            "Epoch 48/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.3214 - accuracy: 0.9266 - val_loss: 0.5304 - val_accuracy: 0.8200\n",
            "Epoch 49/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.2840 - accuracy: 0.9288 - val_loss: 0.3020 - val_accuracy: 0.9025\n",
            "Epoch 50/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.2938 - accuracy: 0.9253 - val_loss: 0.3633 - val_accuracy: 0.8938\n",
            "Epoch 51/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.2556 - accuracy: 0.9423 - val_loss: 0.2163 - val_accuracy: 0.9337\n",
            "Epoch 52/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.2300 - accuracy: 0.9580 - val_loss: 0.2258 - val_accuracy: 0.9362\n",
            "Epoch 53/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.2358 - accuracy: 0.9451 - val_loss: 0.2058 - val_accuracy: 0.9375\n",
            "Epoch 54/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.2092 - accuracy: 0.9644 - val_loss: 0.2482 - val_accuracy: 0.9250\n",
            "Epoch 55/200\n",
            "117/117 [==============================] - 30s 257ms/step - loss: 0.2451 - accuracy: 0.9485 - val_loss: 0.2200 - val_accuracy: 0.9275\n",
            "Epoch 56/200\n",
            "117/117 [==============================] - 30s 257ms/step - loss: 0.2062 - accuracy: 0.9570 - val_loss: 0.2212 - val_accuracy: 0.9337\n",
            "Epoch 57/200\n",
            "117/117 [==============================] - 30s 256ms/step - loss: 0.2369 - accuracy: 0.9395 - val_loss: 0.2085 - val_accuracy: 0.9350\n",
            "Epoch 58/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.2154 - accuracy: 0.9607 - val_loss: 0.2225 - val_accuracy: 0.9312\n",
            "Epoch 59/200\n",
            "117/117 [==============================] - 30s 255ms/step - loss: 0.2187 - accuracy: 0.9564 - val_loss: 0.2121 - val_accuracy: 0.9362\n",
            "Epoch 60/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.2267 - accuracy: 0.9507 - val_loss: 0.2421 - val_accuracy: 0.9187\n",
            "Epoch 61/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.2160 - accuracy: 0.9564 - val_loss: 0.2248 - val_accuracy: 0.9300\n",
            "Epoch 62/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1865 - accuracy: 0.9658 - val_loss: 0.2356 - val_accuracy: 0.9225\n",
            "Epoch 63/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1800 - accuracy: 0.9689 - val_loss: 0.2437 - val_accuracy: 0.9262\n",
            "Epoch 64/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1917 - accuracy: 0.9551 - val_loss: 0.2067 - val_accuracy: 0.9325\n",
            "Epoch 65/200\n",
            "117/117 [==============================] - 30s 255ms/step - loss: 0.2019 - accuracy: 0.9603 - val_loss: 0.2031 - val_accuracy: 0.9388\n",
            "Epoch 66/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1995 - accuracy: 0.9666 - val_loss: 0.2012 - val_accuracy: 0.9400\n",
            "Epoch 67/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1916 - accuracy: 0.9641 - val_loss: 0.1997 - val_accuracy: 0.9350\n",
            "Epoch 68/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.2089 - accuracy: 0.9577 - val_loss: 0.2070 - val_accuracy: 0.9400\n",
            "Epoch 69/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.2088 - accuracy: 0.9596 - val_loss: 0.2127 - val_accuracy: 0.9388\n",
            "Epoch 70/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1574 - accuracy: 0.9766 - val_loss: 0.1994 - val_accuracy: 0.9337\n",
            "Epoch 71/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.1955 - accuracy: 0.9614 - val_loss: 0.2034 - val_accuracy: 0.9362\n",
            "Epoch 72/200\n",
            "117/117 [==============================] - 29s 251ms/step - loss: 0.1954 - accuracy: 0.9632 - val_loss: 0.2114 - val_accuracy: 0.9337\n",
            "Epoch 73/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1915 - accuracy: 0.9611 - val_loss: 0.2117 - val_accuracy: 0.9325\n",
            "Epoch 74/200\n",
            "117/117 [==============================] - 29s 251ms/step - loss: 0.1828 - accuracy: 0.9668 - val_loss: 0.2066 - val_accuracy: 0.9350\n",
            "Epoch 75/200\n",
            "117/117 [==============================] - 29s 252ms/step - loss: 0.1818 - accuracy: 0.9622 - val_loss: 0.2032 - val_accuracy: 0.9388\n",
            "Epoch 76/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1969 - accuracy: 0.9632 - val_loss: 0.2030 - val_accuracy: 0.9375\n",
            "Epoch 77/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1868 - accuracy: 0.9615 - val_loss: 0.2038 - val_accuracy: 0.9375\n",
            "Epoch 78/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1671 - accuracy: 0.9742 - val_loss: 0.2082 - val_accuracy: 0.9325\n",
            "Epoch 79/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1962 - accuracy: 0.9669 - val_loss: 0.2149 - val_accuracy: 0.9350\n",
            "Epoch 80/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1916 - accuracy: 0.9698 - val_loss: 0.2078 - val_accuracy: 0.9325\n",
            "Epoch 81/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1699 - accuracy: 0.9766 - val_loss: 0.2054 - val_accuracy: 0.9325\n",
            "Epoch 82/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.1727 - accuracy: 0.9652 - val_loss: 0.2046 - val_accuracy: 0.9325\n",
            "Epoch 83/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.1887 - accuracy: 0.9581 - val_loss: 0.2060 - val_accuracy: 0.9337\n",
            "Epoch 84/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.1698 - accuracy: 0.9706 - val_loss: 0.2032 - val_accuracy: 0.9350\n",
            "Epoch 85/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.1624 - accuracy: 0.9751 - val_loss: 0.2047 - val_accuracy: 0.9325\n",
            "Epoch 86/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1789 - accuracy: 0.9687 - val_loss: 0.2048 - val_accuracy: 0.9350\n",
            "Epoch 87/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1716 - accuracy: 0.9750 - val_loss: 0.1999 - val_accuracy: 0.9350\n",
            "Epoch 88/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1855 - accuracy: 0.9741 - val_loss: 0.1987 - val_accuracy: 0.9337\n",
            "Epoch 89/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1875 - accuracy: 0.9624 - val_loss: 0.2057 - val_accuracy: 0.9350\n",
            "Epoch 90/200\n",
            "117/117 [==============================] - 30s 255ms/step - loss: 0.1824 - accuracy: 0.9674 - val_loss: 0.2045 - val_accuracy: 0.9362\n",
            "Epoch 91/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1820 - accuracy: 0.9719 - val_loss: 0.2039 - val_accuracy: 0.9337\n",
            "Epoch 92/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1884 - accuracy: 0.9699 - val_loss: 0.2060 - val_accuracy: 0.9350\n",
            "Epoch 93/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1821 - accuracy: 0.9657 - val_loss: 0.2068 - val_accuracy: 0.9325\n",
            "Epoch 94/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1948 - accuracy: 0.9677 - val_loss: 0.2043 - val_accuracy: 0.9350\n",
            "Epoch 95/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1721 - accuracy: 0.9697 - val_loss: 0.2050 - val_accuracy: 0.9362\n",
            "Epoch 96/200\n",
            "117/117 [==============================] - 30s 252ms/step - loss: 0.1838 - accuracy: 0.9612 - val_loss: 0.2006 - val_accuracy: 0.9337\n",
            "Epoch 97/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1745 - accuracy: 0.9744 - val_loss: 0.2076 - val_accuracy: 0.9325\n",
            "Epoch 98/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1800 - accuracy: 0.9716 - val_loss: 0.2059 - val_accuracy: 0.9325\n",
            "Epoch 99/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1726 - accuracy: 0.9740 - val_loss: 0.2050 - val_accuracy: 0.9350\n",
            "Epoch 100/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1803 - accuracy: 0.9693 - val_loss: 0.2027 - val_accuracy: 0.9337\n",
            "Epoch 101/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1717 - accuracy: 0.9732 - val_loss: 0.2016 - val_accuracy: 0.9350\n",
            "Epoch 102/200\n",
            "117/117 [==============================] - 29s 252ms/step - loss: 0.1605 - accuracy: 0.9798 - val_loss: 0.2052 - val_accuracy: 0.9325\n",
            "Epoch 103/200\n",
            "117/117 [==============================] - 30s 255ms/step - loss: 0.1760 - accuracy: 0.9686 - val_loss: 0.2059 - val_accuracy: 0.9325\n",
            "Epoch 104/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1765 - accuracy: 0.9694 - val_loss: 0.2035 - val_accuracy: 0.9337\n",
            "Epoch 105/200\n",
            "117/117 [==============================] - 30s 254ms/step - loss: 0.1712 - accuracy: 0.9720 - val_loss: 0.2058 - val_accuracy: 0.9350\n",
            "Epoch 106/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1748 - accuracy: 0.9730 - val_loss: 0.2054 - val_accuracy: 0.9350\n",
            "Epoch 107/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1842 - accuracy: 0.9621 - val_loss: 0.2005 - val_accuracy: 0.9362\n",
            "Epoch 108/200\n",
            "117/117 [==============================] - 30s 253ms/step - loss: 0.1698 - accuracy: 0.9741 - val_loss: 0.2004 - val_accuracy: 0.9350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkxRoaZVr637"
      },
      "source": [
        "def zipdir(path, ziph):\r\n",
        "    # ziph is zipfile handle\r\n",
        "    for root, dirs, files in os.walk(path):\r\n",
        "        for file in files:\r\n",
        "            ziph.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), os.path.join(path, '..')))\r\n",
        "  \r\n",
        "if __name__ == '__main__':\r\n",
        "    zipf = zipfile.ZipFile('Final_results_108_epochs.zip', 'w', zipfile.ZIP_DEFLATED)\r\n",
        "    zipdir('/content/Final', zipf)\r\n",
        "    zipf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jncwy5ZyAvfE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}