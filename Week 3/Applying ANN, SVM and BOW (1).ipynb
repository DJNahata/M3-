{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zk1F35W3pLQ1"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction import image as skImage\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "\n",
    "# -- DATA GETTER -- #\n",
    "class DataGetter():\n",
    "    \"\"\"CLASS::DataGetter:\"\"\"\n",
    "    def __init__(self, data_dir, img_size, classes, phase='train'):\n",
    "        self.phase = phase\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.classes = classes\n",
    "        self.data_paths = []\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "    \n",
    "    def load_data(self):\n",
    "        for category in self.classes:\n",
    "            self.data_paths.append(glob(self.data_dir+os.sep+self.phase+os.sep+category+os.sep+'*.jpg'))\n",
    "        for k, category in enumerate(self.data_paths):\n",
    "            for img_path in category:\n",
    "                img = load_img(img_path)\n",
    "                img = img.resize((self.img_size,self.img_size))\n",
    "                self.data.append(np.expand_dims(img_to_array(img),axis=0))\n",
    "                self.label.append(k)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if not isinstance(key, int):\n",
    "            raise ValueError('Key has to be of type: int')\n",
    "        return (self.data[key],self.label[key])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2EOZtGDbqzja"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Reshape, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "# -- MODEL -- #\n",
    "class Model_MLP():\n",
    "    \"\"\"CLASS::Model_MLP\"\"\"\n",
    "    def __init__(self, config_dict, trained=False):\n",
    "        model = self.get_model_structure(config_dict)\n",
    "        if trained:\n",
    "            model.load_weights(config_dict['weights_path'])\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.model = Model(inputs=model.inputs, outputs=layer_outputs)\n",
    "\n",
    "    def get_model_structure(self,config_dict):\n",
    "        model = Sequential()\n",
    "        size = config_dict['img_size']\n",
    "        model.add(Reshape((size*size*3,),input_shape=(size, size, 3)))\n",
    "        for layer in config_dict['layers']:\n",
    "            model.add(Dense(units=layer['units'], activation=layer['activation']))\n",
    "        model.add(Dense(units=8, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "    def predict(self,tensor):\n",
    "        return self.model.predict(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "StE0ZShX9_1X",
    "outputId": "067067dd-abc4-4245-ded2-9dcc08fb365b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "022-kgUraNJb"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "with zipfile.ZipFile(\"MIT_split-20210124T132955Z-001.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.getcwd())\n",
    "\n",
    "path1 = os.getcwd() + \"/\" + \"MIT_split\"\n",
    "print(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVgGy7W2akEU",
    "outputId": "77b82401-8b18-4526-ee45-7de4849ec80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/MIT_split\n"
     ]
    }
   ],
   "source": [
    "path1 = os.getcwd() + \"/\" + \"MIT_split\"\n",
    "print(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GowcqDYDwSCt"
   },
   "source": [
    "# Experimentation With different Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eQpH6cXwSM6",
    "outputId": "47e15e2b-59aa-410f-bc1d-6c5531ebdb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_32 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 2048)              25167872  \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 27,274,248\n",
      "Trainable params: 27,274,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 5s 43ms/step - loss: 2.1556 - accuracy: 0.1940 - val_loss: 1.6383 - val_accuracy: 0.4175\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.6489 - accuracy: 0.3872 - val_loss: 1.6296 - val_accuracy: 0.3487\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.5067 - accuracy: 0.4642 - val_loss: 1.4454 - val_accuracy: 0.5150\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3488 - accuracy: 0.5252 - val_loss: 1.3820 - val_accuracy: 0.5300\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.3357 - accuracy: 0.5186 - val_loss: 1.5190 - val_accuracy: 0.4288\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.2762 - accuracy: 0.5488 - val_loss: 1.2735 - val_accuracy: 0.5625\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.2313 - accuracy: 0.5671 - val_loss: 1.2939 - val_accuracy: 0.5450\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1404 - accuracy: 0.6074 - val_loss: 1.2601 - val_accuracy: 0.5375\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0817 - accuracy: 0.6240 - val_loss: 1.2748 - val_accuracy: 0.5400\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 1.0584 - accuracy: 0.6317 - val_loss: 1.1994 - val_accuracy: 0.5700\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0142 - accuracy: 0.6515 - val_loss: 1.2514 - val_accuracy: 0.5362\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9799 - accuracy: 0.6717 - val_loss: 1.1505 - val_accuracy: 0.5788\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9330 - accuracy: 0.6879 - val_loss: 1.1887 - val_accuracy: 0.5962\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9050 - accuracy: 0.6942 - val_loss: 1.2778 - val_accuracy: 0.5437\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.8797 - accuracy: 0.7129 - val_loss: 1.3528 - val_accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8075 - accuracy: 0.7305 - val_loss: 1.1719 - val_accuracy: 0.5763\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8329 - accuracy: 0.7108 - val_loss: 1.0947 - val_accuracy: 0.6275\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.7568 - accuracy: 0.7464 - val_loss: 1.2516 - val_accuracy: 0.5688\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7407 - accuracy: 0.7488 - val_loss: 1.2355 - val_accuracy: 0.5400\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7100 - accuracy: 0.7561 - val_loss: 1.1239 - val_accuracy: 0.6075\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.6977 - accuracy: 0.7622 - val_loss: 1.1144 - val_accuracy: 0.6062\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.6407 - accuracy: 0.7955 - val_loss: 1.1198 - val_accuracy: 0.6187\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.6822 - accuracy: 0.7671 - val_loss: 1.2018 - val_accuracy: 0.6087\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.6700 - accuracy: 0.7809 - val_loss: 1.4731 - val_accuracy: 0.5487\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5754 - accuracy: 0.8209 - val_loss: 1.2945 - val_accuracy: 0.5713\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5317 - accuracy: 0.8163 - val_loss: 1.0505 - val_accuracy: 0.6450\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.5214 - accuracy: 0.8362 - val_loss: 1.0724 - val_accuracy: 0.6313\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.4874 - accuracy: 0.8528 - val_loss: 1.1847 - val_accuracy: 0.6050\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.4862 - accuracy: 0.8347 - val_loss: 1.1186 - val_accuracy: 0.6100\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.4424 - accuracy: 0.8587 - val_loss: 1.0867 - val_accuracy: 0.6300\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.4076 - accuracy: 0.8831 - val_loss: 1.1078 - val_accuracy: 0.6325\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.4083 - accuracy: 0.8815 - val_loss: 1.0922 - val_accuracy: 0.6475\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.4197 - accuracy: 0.8807 - val_loss: 1.1709 - val_accuracy: 0.6212\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.4332 - accuracy: 0.8657 - val_loss: 1.3124 - val_accuracy: 0.5587\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3625 - accuracy: 0.8864 - val_loss: 1.0866 - val_accuracy: 0.6525\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3871 - accuracy: 0.8692 - val_loss: 1.1988 - val_accuracy: 0.5962\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.3413 - accuracy: 0.8848 - val_loss: 1.1669 - val_accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.3128 - accuracy: 0.9029 - val_loss: 1.2351 - val_accuracy: 0.6112\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2823 - accuracy: 0.9183 - val_loss: 1.1904 - val_accuracy: 0.6212\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.3143 - accuracy: 0.9115 - val_loss: 1.3227 - val_accuracy: 0.6050\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2482 - accuracy: 0.9269 - val_loss: 1.1152 - val_accuracy: 0.6513\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2471 - accuracy: 0.9295 - val_loss: 1.2794 - val_accuracy: 0.6212\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2327 - accuracy: 0.9304 - val_loss: 1.1752 - val_accuracy: 0.6350\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.2039 - accuracy: 0.9530 - val_loss: 1.0633 - val_accuracy: 0.6600\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1932 - accuracy: 0.9477 - val_loss: 1.1304 - val_accuracy: 0.6562\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.2183 - accuracy: 0.9361 - val_loss: 1.1459 - val_accuracy: 0.6400\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2310 - accuracy: 0.9331 - val_loss: 1.1065 - val_accuracy: 0.6550\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1948 - accuracy: 0.9475 - val_loss: 1.1110 - val_accuracy: 0.6550\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1481 - accuracy: 0.9659 - val_loss: 1.2520 - val_accuracy: 0.6100\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1670 - accuracy: 0.9585 - val_loss: 1.1207 - val_accuracy: 0.6612\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1324 - accuracy: 0.9676 - val_loss: 1.1218 - val_accuracy: 0.6662\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1253 - accuracy: 0.9772 - val_loss: 1.3202 - val_accuracy: 0.6100\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1537 - accuracy: 0.9644 - val_loss: 1.1668 - val_accuracy: 0.6538\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1033 - accuracy: 0.9829 - val_loss: 1.1835 - val_accuracy: 0.6500\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1114 - accuracy: 0.9720 - val_loss: 1.1203 - val_accuracy: 0.6550\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1344 - accuracy: 0.9654 - val_loss: 1.1223 - val_accuracy: 0.6675\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1012 - accuracy: 0.9799 - val_loss: 1.1791 - val_accuracy: 0.6587\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1525 - accuracy: 0.9630 - val_loss: 1.1990 - val_accuracy: 0.6562\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0743 - accuracy: 0.9865 - val_loss: 1.2014 - val_accuracy: 0.6750\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0675 - accuracy: 0.9921 - val_loss: 1.1625 - val_accuracy: 0.6612\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0757 - accuracy: 0.9892 - val_loss: 1.1671 - val_accuracy: 0.6737\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0569 - accuracy: 0.9880 - val_loss: 1.1583 - val_accuracy: 0.6650\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0721 - accuracy: 0.9860 - val_loss: 1.2761 - val_accuracy: 0.6375\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0683 - accuracy: 0.9847 - val_loss: 1.2648 - val_accuracy: 0.6625\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1092 - accuracy: 0.9769 - val_loss: 1.1097 - val_accuracy: 0.6625\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0879 - accuracy: 0.9864 - val_loss: 1.1732 - val_accuracy: 0.6637\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0535 - accuracy: 0.9942 - val_loss: 1.2177 - val_accuracy: 0.6762\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0528 - accuracy: 0.9934 - val_loss: 1.2541 - val_accuracy: 0.6675\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0494 - accuracy: 0.9932 - val_loss: 1.2221 - val_accuracy: 0.6737\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0499 - accuracy: 0.9935 - val_loss: 1.3156 - val_accuracy: 0.6625\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0612 - accuracy: 0.9918 - val_loss: 1.2830 - val_accuracy: 0.6600\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0460 - accuracy: 0.9933 - val_loss: 1.2432 - val_accuracy: 0.6737\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0299 - accuracy: 0.9984 - val_loss: 1.2813 - val_accuracy: 0.6587\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0367 - accuracy: 0.9984 - val_loss: 1.2360 - val_accuracy: 0.6862\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0311 - accuracy: 0.9958 - val_loss: 1.2608 - val_accuracy: 0.6687\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0257 - accuracy: 0.9980 - val_loss: 1.6197 - val_accuracy: 0.5987\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0779 - accuracy: 0.9804 - val_loss: 1.3359 - val_accuracy: 0.6475\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0309 - accuracy: 0.9973 - val_loss: 1.2781 - val_accuracy: 0.6712\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0217 - accuracy: 0.9988 - val_loss: 1.3245 - val_accuracy: 0.6650\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0201 - accuracy: 0.9998 - val_loss: 1.3389 - val_accuracy: 0.6737\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0296 - accuracy: 0.9969 - val_loss: 1.2608 - val_accuracy: 0.6787\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0227 - accuracy: 0.9987 - val_loss: 1.2631 - val_accuracy: 0.6812\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0202 - accuracy: 0.9989 - val_loss: 1.2800 - val_accuracy: 0.6737\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0196 - accuracy: 0.9982 - val_loss: 1.3087 - val_accuracy: 0.6750\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0231 - accuracy: 0.9979 - val_loss: 1.3067 - val_accuracy: 0.6762\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2440 - accuracy: 0.9611 - val_loss: 1.2186 - val_accuracy: 0.6525\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0924 - accuracy: 0.9880 - val_loss: 1.2077 - val_accuracy: 0.6600\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0392 - accuracy: 0.9979 - val_loss: 1.3203 - val_accuracy: 0.6525\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0317 - accuracy: 0.9991 - val_loss: 1.2697 - val_accuracy: 0.6675\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0271 - accuracy: 0.9985 - val_loss: 1.2570 - val_accuracy: 0.6675\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0413 - accuracy: 0.9945 - val_loss: 1.3230 - val_accuracy: 0.6450\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0463 - accuracy: 0.9958 - val_loss: 1.2644 - val_accuracy: 0.6575\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0215 - accuracy: 0.9997 - val_loss: 1.3431 - val_accuracy: 0.6650\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0223 - accuracy: 0.9995 - val_loss: 1.2644 - val_accuracy: 0.6750\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.0256 - accuracy: 0.9963 - val_loss: 1.3038 - val_accuracy: 0.6850\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0164 - accuracy: 0.9987 - val_loss: 1.2905 - val_accuracy: 0.6800\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0128 - accuracy: 0.9995 - val_loss: 1.3521 - val_accuracy: 0.6587\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0184 - accuracy: 0.9991 - val_loss: 1.3118 - val_accuracy: 0.6712\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0134 - accuracy: 0.9995 - val_loss: 1.3180 - val_accuracy: 0.6775\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0137 - accuracy: 0.9994 - val_loss: 1.2977 - val_accuracy: 0.6750\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_33 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 3072)              37751808  \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 768)               2360064   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 8)                 6152      \n",
      "=================================================================\n",
      "Total params: 40,118,024\n",
      "Trainable params: 40,118,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 2.1633 - accuracy: 0.2263 - val_loss: 1.7428 - val_accuracy: 0.3350\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.6772 - accuracy: 0.3805 - val_loss: 1.4771 - val_accuracy: 0.5175\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.4988 - accuracy: 0.4608 - val_loss: 1.5107 - val_accuracy: 0.4375\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.4023 - accuracy: 0.4994 - val_loss: 1.4937 - val_accuracy: 0.4288\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3424 - accuracy: 0.5226 - val_loss: 1.3445 - val_accuracy: 0.5537\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.2818 - accuracy: 0.5482 - val_loss: 1.3994 - val_accuracy: 0.5013\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.1843 - accuracy: 0.5833 - val_loss: 1.2519 - val_accuracy: 0.5425\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.1197 - accuracy: 0.6053 - val_loss: 1.2655 - val_accuracy: 0.5575\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0906 - accuracy: 0.6236 - val_loss: 1.2909 - val_accuracy: 0.5400\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0443 - accuracy: 0.6503 - val_loss: 1.2348 - val_accuracy: 0.5725\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9998 - accuracy: 0.6576 - val_loss: 1.1688 - val_accuracy: 0.5950\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0137 - accuracy: 0.6607 - val_loss: 1.1843 - val_accuracy: 0.5738\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8948 - accuracy: 0.6992 - val_loss: 1.2790 - val_accuracy: 0.5688\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9027 - accuracy: 0.6640 - val_loss: 1.2127 - val_accuracy: 0.5688\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8973 - accuracy: 0.6919 - val_loss: 1.2713 - val_accuracy: 0.5562\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8264 - accuracy: 0.7315 - val_loss: 1.1590 - val_accuracy: 0.5825\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8328 - accuracy: 0.7062 - val_loss: 1.1458 - val_accuracy: 0.6275\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7167 - accuracy: 0.7558 - val_loss: 1.1509 - val_accuracy: 0.5863\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.6831 - accuracy: 0.7762 - val_loss: 1.3027 - val_accuracy: 0.5675\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7217 - accuracy: 0.7743 - val_loss: 1.0784 - val_accuracy: 0.6313\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.6438 - accuracy: 0.7954 - val_loss: 1.2653 - val_accuracy: 0.5775\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.6413 - accuracy: 0.7873 - val_loss: 1.1785 - val_accuracy: 0.5925\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6054 - accuracy: 0.7996 - val_loss: 1.1414 - val_accuracy: 0.6187\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5759 - accuracy: 0.8168 - val_loss: 1.0765 - val_accuracy: 0.6438\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5708 - accuracy: 0.8155 - val_loss: 1.1454 - val_accuracy: 0.5863\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5173 - accuracy: 0.8507 - val_loss: 1.1802 - val_accuracy: 0.6087\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5530 - accuracy: 0.8217 - val_loss: 1.1876 - val_accuracy: 0.6100\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5478 - accuracy: 0.8157 - val_loss: 1.1551 - val_accuracy: 0.5788\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.4881 - accuracy: 0.8467 - val_loss: 1.1333 - val_accuracy: 0.6087\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.4119 - accuracy: 0.8798 - val_loss: 1.1717 - val_accuracy: 0.5987\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.4384 - accuracy: 0.8579 - val_loss: 1.2911 - val_accuracy: 0.5600\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3803 - accuracy: 0.8868 - val_loss: 1.1203 - val_accuracy: 0.6375\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3681 - accuracy: 0.8894 - val_loss: 1.2146 - val_accuracy: 0.6363\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3512 - accuracy: 0.8829 - val_loss: 1.1682 - val_accuracy: 0.6150\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3400 - accuracy: 0.9033 - val_loss: 1.0881 - val_accuracy: 0.6275\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3099 - accuracy: 0.9063 - val_loss: 1.0885 - val_accuracy: 0.6388\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2617 - accuracy: 0.9281 - val_loss: 1.0389 - val_accuracy: 0.6525\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2700 - accuracy: 0.9263 - val_loss: 1.1669 - val_accuracy: 0.6162\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2877 - accuracy: 0.9142 - val_loss: 1.1086 - val_accuracy: 0.6475\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2606 - accuracy: 0.9306 - val_loss: 1.1308 - val_accuracy: 0.6450\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2606 - accuracy: 0.9291 - val_loss: 1.2583 - val_accuracy: 0.6187\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2500 - accuracy: 0.9265 - val_loss: 1.1698 - val_accuracy: 0.6263\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2233 - accuracy: 0.9390 - val_loss: 1.2215 - val_accuracy: 0.6263\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1779 - accuracy: 0.9549 - val_loss: 1.1111 - val_accuracy: 0.6562\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1954 - accuracy: 0.9394 - val_loss: 1.2948 - val_accuracy: 0.6237\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1803 - accuracy: 0.9491 - val_loss: 1.1602 - val_accuracy: 0.6650\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1760 - accuracy: 0.9570 - val_loss: 1.1528 - val_accuracy: 0.6200\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2296 - accuracy: 0.9424 - val_loss: 1.5685 - val_accuracy: 0.5750\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1769 - accuracy: 0.9541 - val_loss: 1.0978 - val_accuracy: 0.6650\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1387 - accuracy: 0.9654 - val_loss: 1.1862 - val_accuracy: 0.6438\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1477 - accuracy: 0.9653 - val_loss: 1.2521 - val_accuracy: 0.6475\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1659 - accuracy: 0.9634 - val_loss: 1.2619 - val_accuracy: 0.6288\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1347 - accuracy: 0.9696 - val_loss: 1.1120 - val_accuracy: 0.6775\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1184 - accuracy: 0.9730 - val_loss: 1.2679 - val_accuracy: 0.6388\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0919 - accuracy: 0.9850 - val_loss: 2.5975 - val_accuracy: 0.4938\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1924 - accuracy: 0.9552 - val_loss: 1.2050 - val_accuracy: 0.6538\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1002 - accuracy: 0.9812 - val_loss: 1.1234 - val_accuracy: 0.7013\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0674 - accuracy: 0.9884 - val_loss: 1.1799 - val_accuracy: 0.6637\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0654 - accuracy: 0.9899 - val_loss: 1.2261 - val_accuracy: 0.6575\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3611 - accuracy: 0.9140 - val_loss: 1.1252 - val_accuracy: 0.6587\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1140 - accuracy: 0.9785 - val_loss: 1.1924 - val_accuracy: 0.6612\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0951 - accuracy: 0.9788 - val_loss: 1.1922 - val_accuracy: 0.6612\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0700 - accuracy: 0.9916 - val_loss: 1.2426 - val_accuracy: 0.6400\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0842 - accuracy: 0.9810 - val_loss: 1.1707 - val_accuracy: 0.6550\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0628 - accuracy: 0.9893 - val_loss: 1.2662 - val_accuracy: 0.6550\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1714 - accuracy: 0.9444 - val_loss: 1.5202 - val_accuracy: 0.6263\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0592 - accuracy: 0.9940 - val_loss: 1.2505 - val_accuracy: 0.6587\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0505 - accuracy: 0.9938 - val_loss: 1.3389 - val_accuracy: 0.6388\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0431 - accuracy: 0.9962 - val_loss: 1.2083 - val_accuracy: 0.6637\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0596 - accuracy: 0.9929 - val_loss: 1.2307 - val_accuracy: 0.6562\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0444 - accuracy: 0.9932 - val_loss: 1.2324 - val_accuracy: 0.6750\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0409 - accuracy: 0.9946 - val_loss: 1.4200 - val_accuracy: 0.6313\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0418 - accuracy: 0.9940 - val_loss: 1.2748 - val_accuracy: 0.6612\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0314 - accuracy: 0.9979 - val_loss: 1.2937 - val_accuracy: 0.6388\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0422 - accuracy: 0.9945 - val_loss: 1.2799 - val_accuracy: 0.6600\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0353 - accuracy: 0.9968 - val_loss: 1.2556 - val_accuracy: 0.6650\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0292 - accuracy: 0.9980 - val_loss: 1.2613 - val_accuracy: 0.6650\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0218 - accuracy: 0.9995 - val_loss: 1.2569 - val_accuracy: 0.6675\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0236 - accuracy: 0.9980 - val_loss: 1.3192 - val_accuracy: 0.6650\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0313 - accuracy: 0.9969 - val_loss: 1.2655 - val_accuracy: 0.6662\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0320 - accuracy: 0.9937 - val_loss: 1.2847 - val_accuracy: 0.6700\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0203 - accuracy: 0.9995 - val_loss: 1.2697 - val_accuracy: 0.6737\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0224 - accuracy: 0.9973 - val_loss: 1.2850 - val_accuracy: 0.6700\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0145 - accuracy: 0.9998 - val_loss: 1.2886 - val_accuracy: 0.6662\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0226 - accuracy: 0.9981 - val_loss: 1.3102 - val_accuracy: 0.6700\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0195 - accuracy: 0.9987 - val_loss: 1.3539 - val_accuracy: 0.6675\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0201 - accuracy: 0.9989 - val_loss: 1.2967 - val_accuracy: 0.6712\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0208 - accuracy: 0.9976 - val_loss: 1.3097 - val_accuracy: 0.6775\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0155 - accuracy: 0.9994 - val_loss: 1.3042 - val_accuracy: 0.6762\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3189 - accuracy: 0.9370 - val_loss: 1.2107 - val_accuracy: 0.6762\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0262 - accuracy: 0.9992 - val_loss: 1.2603 - val_accuracy: 0.6575\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0277 - accuracy: 0.9970 - val_loss: 1.2940 - val_accuracy: 0.6700\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0174 - accuracy: 0.9997 - val_loss: 1.2899 - val_accuracy: 0.6725\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0157 - accuracy: 0.9998 - val_loss: 1.3329 - val_accuracy: 0.6538\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0148 - accuracy: 0.9995 - val_loss: 1.3360 - val_accuracy: 0.6600\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 1.3054 - val_accuracy: 0.6737\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0109 - accuracy: 0.9998 - val_loss: 1.3059 - val_accuracy: 0.6662\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0125 - accuracy: 0.9996 - val_loss: 1.3310 - val_accuracy: 0.6650\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.6662\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0138 - accuracy: 0.9989 - val_loss: 1.3256 - val_accuracy: 0.6787\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_34 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 2048)              25167872  \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 8)                 16392     \n",
      "=================================================================\n",
      "Total params: 25,184,264\n",
      "Trainable params: 25,184,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 2.5217 - accuracy: 0.2409 - val_loss: 1.7032 - val_accuracy: 0.3450\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.6280 - accuracy: 0.3836 - val_loss: 1.5359 - val_accuracy: 0.4563\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.4839 - accuracy: 0.4632 - val_loss: 1.4350 - val_accuracy: 0.4800\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.4207 - accuracy: 0.4992 - val_loss: 1.3350 - val_accuracy: 0.5437\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.3134 - accuracy: 0.5392 - val_loss: 1.3056 - val_accuracy: 0.5325\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.2408 - accuracy: 0.5548 - val_loss: 1.4597 - val_accuracy: 0.4437\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.1878 - accuracy: 0.5775 - val_loss: 1.2687 - val_accuracy: 0.5638\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1558 - accuracy: 0.5906 - val_loss: 1.2928 - val_accuracy: 0.5738\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0921 - accuracy: 0.6406 - val_loss: 1.3277 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0787 - accuracy: 0.6329 - val_loss: 1.1958 - val_accuracy: 0.5900\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0285 - accuracy: 0.6601 - val_loss: 1.1967 - val_accuracy: 0.5788\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9951 - accuracy: 0.6665 - val_loss: 1.2860 - val_accuracy: 0.5412\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9645 - accuracy: 0.6987 - val_loss: 1.1510 - val_accuracy: 0.5925\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9220 - accuracy: 0.6817 - val_loss: 1.1689 - val_accuracy: 0.5675\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9218 - accuracy: 0.6931 - val_loss: 1.2213 - val_accuracy: 0.5788\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8495 - accuracy: 0.7278 - val_loss: 1.1621 - val_accuracy: 0.6175\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8457 - accuracy: 0.7024 - val_loss: 1.2124 - val_accuracy: 0.5788\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.8001 - accuracy: 0.7240 - val_loss: 1.1063 - val_accuracy: 0.6237\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7980 - accuracy: 0.7373 - val_loss: 1.1672 - val_accuracy: 0.5850\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7674 - accuracy: 0.7478 - val_loss: 1.1890 - val_accuracy: 0.5925\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7243 - accuracy: 0.7630 - val_loss: 1.1184 - val_accuracy: 0.6263\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.6691 - accuracy: 0.7732 - val_loss: 1.1220 - val_accuracy: 0.6112\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.7134 - accuracy: 0.7730 - val_loss: 1.1856 - val_accuracy: 0.6062\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6347 - accuracy: 0.8028 - val_loss: 1.1691 - val_accuracy: 0.6062\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6601 - accuracy: 0.7933 - val_loss: 1.1660 - val_accuracy: 0.5863\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.6319 - accuracy: 0.8028 - val_loss: 1.2622 - val_accuracy: 0.5850\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5706 - accuracy: 0.8081 - val_loss: 1.2235 - val_accuracy: 0.5825\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5931 - accuracy: 0.8090 - val_loss: 1.2035 - val_accuracy: 0.6037\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5676 - accuracy: 0.8173 - val_loss: 1.0812 - val_accuracy: 0.6413\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5194 - accuracy: 0.8442 - val_loss: 1.2162 - val_accuracy: 0.5925\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5381 - accuracy: 0.8167 - val_loss: 1.0370 - val_accuracy: 0.6562\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5012 - accuracy: 0.8466 - val_loss: 1.0847 - val_accuracy: 0.6375\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4616 - accuracy: 0.8528 - val_loss: 1.1115 - val_accuracy: 0.5975\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4263 - accuracy: 0.8844 - val_loss: 1.2511 - val_accuracy: 0.6087\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.4376 - accuracy: 0.8531 - val_loss: 1.1733 - val_accuracy: 0.6200\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.4261 - accuracy: 0.8772 - val_loss: 1.2255 - val_accuracy: 0.5962\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3702 - accuracy: 0.9016 - val_loss: 1.1890 - val_accuracy: 0.6112\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3642 - accuracy: 0.8893 - val_loss: 1.1015 - val_accuracy: 0.6513\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3795 - accuracy: 0.8961 - val_loss: 1.0527 - val_accuracy: 0.6525\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3549 - accuracy: 0.8977 - val_loss: 1.1522 - val_accuracy: 0.6150\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3673 - accuracy: 0.8986 - val_loss: 1.0737 - val_accuracy: 0.6338\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3052 - accuracy: 0.9240 - val_loss: 1.0496 - val_accuracy: 0.6525\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2827 - accuracy: 0.9151 - val_loss: 1.0985 - val_accuracy: 0.6338\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2938 - accuracy: 0.9234 - val_loss: 1.0442 - val_accuracy: 0.6550\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3177 - accuracy: 0.9149 - val_loss: 1.1646 - val_accuracy: 0.6375\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3090 - accuracy: 0.9033 - val_loss: 1.0706 - val_accuracy: 0.6525\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2499 - accuracy: 0.9377 - val_loss: 1.1517 - val_accuracy: 0.6300\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2611 - accuracy: 0.9305 - val_loss: 1.0960 - val_accuracy: 0.6562\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2262 - accuracy: 0.9503 - val_loss: 1.1403 - val_accuracy: 0.6288\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2280 - accuracy: 0.9360 - val_loss: 1.1619 - val_accuracy: 0.6500\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2040 - accuracy: 0.9514 - val_loss: 1.1994 - val_accuracy: 0.6125\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2091 - accuracy: 0.9471 - val_loss: 1.0946 - val_accuracy: 0.6538\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2176 - accuracy: 0.9404 - val_loss: 1.1588 - val_accuracy: 0.6400\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2105 - accuracy: 0.9517 - val_loss: 1.0609 - val_accuracy: 0.6575\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1788 - accuracy: 0.9674 - val_loss: 1.1569 - val_accuracy: 0.6425\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1816 - accuracy: 0.9536 - val_loss: 1.1489 - val_accuracy: 0.6388\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1483 - accuracy: 0.9681 - val_loss: 1.2138 - val_accuracy: 0.6200\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1796 - accuracy: 0.9498 - val_loss: 1.1129 - val_accuracy: 0.6600\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1575 - accuracy: 0.9703 - val_loss: 1.1309 - val_accuracy: 0.6513\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1449 - accuracy: 0.9721 - val_loss: 1.1133 - val_accuracy: 0.6587\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1429 - accuracy: 0.9685 - val_loss: 1.2186 - val_accuracy: 0.6263\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1526 - accuracy: 0.9655 - val_loss: 1.1035 - val_accuracy: 0.6488\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1348 - accuracy: 0.9738 - val_loss: 1.1411 - val_accuracy: 0.6488\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1460 - accuracy: 0.9666 - val_loss: 1.1922 - val_accuracy: 0.6200\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1207 - accuracy: 0.9839 - val_loss: 1.1161 - val_accuracy: 0.6438\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1064 - accuracy: 0.9818 - val_loss: 1.1178 - val_accuracy: 0.6625\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0954 - accuracy: 0.9849 - val_loss: 1.5863 - val_accuracy: 0.5612\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1024 - accuracy: 0.9831 - val_loss: 1.0983 - val_accuracy: 0.6612\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0901 - accuracy: 0.9810 - val_loss: 1.1583 - val_accuracy: 0.6463\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0932 - accuracy: 0.9854 - val_loss: 1.1868 - val_accuracy: 0.6562\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0949 - accuracy: 0.9840 - val_loss: 1.2838 - val_accuracy: 0.6025\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.1043 - accuracy: 0.9814 - val_loss: 1.1775 - val_accuracy: 0.6550\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0849 - accuracy: 0.9872 - val_loss: 1.2232 - val_accuracy: 0.6438\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0858 - accuracy: 0.9886 - val_loss: 1.1895 - val_accuracy: 0.6375\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0762 - accuracy: 0.9911 - val_loss: 1.2320 - val_accuracy: 0.6413\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0762 - accuracy: 0.9883 - val_loss: 1.1419 - val_accuracy: 0.6538\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0733 - accuracy: 0.9871 - val_loss: 1.1450 - val_accuracy: 0.6700\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0896 - accuracy: 0.9797 - val_loss: 1.1199 - val_accuracy: 0.6700\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0863 - accuracy: 0.9851 - val_loss: 1.1270 - val_accuracy: 0.6600\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0688 - accuracy: 0.9913 - val_loss: 1.1413 - val_accuracy: 0.6612\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0590 - accuracy: 0.9923 - val_loss: 1.1461 - val_accuracy: 0.6650\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0613 - accuracy: 0.9893 - val_loss: 1.1730 - val_accuracy: 0.6525\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0629 - accuracy: 0.9902 - val_loss: 1.2115 - val_accuracy: 0.6413\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0603 - accuracy: 0.9916 - val_loss: 1.1692 - val_accuracy: 0.6612\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0788 - accuracy: 0.9781 - val_loss: 1.1862 - val_accuracy: 0.6600\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0465 - accuracy: 0.9949 - val_loss: 1.1647 - val_accuracy: 0.6687\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0495 - accuracy: 0.9954 - val_loss: 1.1996 - val_accuracy: 0.6488\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0550 - accuracy: 0.9945 - val_loss: 1.1481 - val_accuracy: 0.6562\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0428 - accuracy: 0.9972 - val_loss: 1.1755 - val_accuracy: 0.6687\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0609 - accuracy: 0.9855 - val_loss: 1.1814 - val_accuracy: 0.6675\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0372 - accuracy: 0.9974 - val_loss: 1.1653 - val_accuracy: 0.6800\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0412 - accuracy: 0.9972 - val_loss: 1.2226 - val_accuracy: 0.6562\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0414 - accuracy: 0.9981 - val_loss: 1.1728 - val_accuracy: 0.6750\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0403 - accuracy: 0.9959 - val_loss: 1.1875 - val_accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0336 - accuracy: 0.9987 - val_loss: 1.1838 - val_accuracy: 0.6662\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0460 - accuracy: 0.9921 - val_loss: 1.1716 - val_accuracy: 0.6637\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0353 - accuracy: 0.9975 - val_loss: 1.1918 - val_accuracy: 0.6637\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0354 - accuracy: 0.9953 - val_loss: 1.1902 - val_accuracy: 0.6725\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0387 - accuracy: 0.9945 - val_loss: 1.1985 - val_accuracy: 0.6737\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0276 - accuracy: 0.9984 - val_loss: 1.1990 - val_accuracy: 0.6737\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_35 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 3072)              37751808  \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 8)                 24584     \n",
      "=================================================================\n",
      "Total params: 37,776,392\n",
      "Trainable params: 37,776,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 2.7385 - accuracy: 0.2493 - val_loss: 1.7540 - val_accuracy: 0.3187\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.6214 - accuracy: 0.4155 - val_loss: 1.4667 - val_accuracy: 0.4875\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.4577 - accuracy: 0.4684 - val_loss: 1.3548 - val_accuracy: 0.5437\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.4010 - accuracy: 0.4842 - val_loss: 1.3567 - val_accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3014 - accuracy: 0.5471 - val_loss: 1.3667 - val_accuracy: 0.4988\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.2501 - accuracy: 0.5523 - val_loss: 1.2953 - val_accuracy: 0.5487\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1692 - accuracy: 0.5952 - val_loss: 1.3291 - val_accuracy: 0.5288\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0763 - accuracy: 0.6390 - val_loss: 1.3956 - val_accuracy: 0.5350\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1214 - accuracy: 0.6055 - val_loss: 1.2503 - val_accuracy: 0.5412\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9777 - accuracy: 0.6765 - val_loss: 1.2632 - val_accuracy: 0.5325\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9794 - accuracy: 0.6777 - val_loss: 1.3357 - val_accuracy: 0.5337\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9840 - accuracy: 0.6641 - val_loss: 1.1951 - val_accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9177 - accuracy: 0.6887 - val_loss: 1.2281 - val_accuracy: 0.5788\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9424 - accuracy: 0.6722 - val_loss: 1.2565 - val_accuracy: 0.5587\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9138 - accuracy: 0.6837 - val_loss: 1.1471 - val_accuracy: 0.5913\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8358 - accuracy: 0.7304 - val_loss: 1.2196 - val_accuracy: 0.5800\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8096 - accuracy: 0.7436 - val_loss: 1.1469 - val_accuracy: 0.6012\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8023 - accuracy: 0.7218 - val_loss: 1.3757 - val_accuracy: 0.5350\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7665 - accuracy: 0.7335 - val_loss: 1.0891 - val_accuracy: 0.6187\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7106 - accuracy: 0.7824 - val_loss: 1.2938 - val_accuracy: 0.5713\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7649 - accuracy: 0.7446 - val_loss: 1.1328 - val_accuracy: 0.6037\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7405 - accuracy: 0.7515 - val_loss: 1.1267 - val_accuracy: 0.6125\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6434 - accuracy: 0.7950 - val_loss: 1.4233 - val_accuracy: 0.5300\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6576 - accuracy: 0.8014 - val_loss: 1.0499 - val_accuracy: 0.6488\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5875 - accuracy: 0.8233 - val_loss: 1.1374 - val_accuracy: 0.6275\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5856 - accuracy: 0.8131 - val_loss: 1.2908 - val_accuracy: 0.5525\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5936 - accuracy: 0.7975 - val_loss: 1.1261 - val_accuracy: 0.6275\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5392 - accuracy: 0.8278 - val_loss: 1.1630 - val_accuracy: 0.5863\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5269 - accuracy: 0.8401 - val_loss: 1.0688 - val_accuracy: 0.6313\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4831 - accuracy: 0.8471 - val_loss: 1.0445 - val_accuracy: 0.6425\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4402 - accuracy: 0.8759 - val_loss: 1.1261 - val_accuracy: 0.6037\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4367 - accuracy: 0.8749 - val_loss: 1.0849 - val_accuracy: 0.6225\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4262 - accuracy: 0.8839 - val_loss: 1.1408 - val_accuracy: 0.6125\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4261 - accuracy: 0.8774 - val_loss: 1.0976 - val_accuracy: 0.6313\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3877 - accuracy: 0.8828 - val_loss: 1.1229 - val_accuracy: 0.6025\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4152 - accuracy: 0.8798 - val_loss: 1.1003 - val_accuracy: 0.6413\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3441 - accuracy: 0.8993 - val_loss: 1.2393 - val_accuracy: 0.5900\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3823 - accuracy: 0.8899 - val_loss: 1.0425 - val_accuracy: 0.6637\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3877 - accuracy: 0.8701 - val_loss: 1.0982 - val_accuracy: 0.6413\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3824 - accuracy: 0.9014 - val_loss: 1.1496 - val_accuracy: 0.6062\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3317 - accuracy: 0.9094 - val_loss: 1.0646 - val_accuracy: 0.6525\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2587 - accuracy: 0.9423 - val_loss: 1.0909 - val_accuracy: 0.6338\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2612 - accuracy: 0.9285 - val_loss: 1.1942 - val_accuracy: 0.6150\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2601 - accuracy: 0.9357 - val_loss: 1.3405 - val_accuracy: 0.5713\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2886 - accuracy: 0.9217 - val_loss: 1.2213 - val_accuracy: 0.6162\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3494 - accuracy: 0.8882 - val_loss: 1.2425 - val_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2535 - accuracy: 0.9335 - val_loss: 1.0639 - val_accuracy: 0.6700\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2221 - accuracy: 0.9421 - val_loss: 1.2755 - val_accuracy: 0.5975\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2187 - accuracy: 0.9352 - val_loss: 1.0811 - val_accuracy: 0.6550\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2136 - accuracy: 0.9381 - val_loss: 1.2834 - val_accuracy: 0.5875\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2083 - accuracy: 0.9494 - val_loss: 1.1259 - val_accuracy: 0.6600\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2191 - accuracy: 0.9412 - val_loss: 1.1224 - val_accuracy: 0.6425\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2048 - accuracy: 0.9540 - val_loss: 1.1571 - val_accuracy: 0.6350\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1836 - accuracy: 0.9561 - val_loss: 1.1610 - val_accuracy: 0.6350\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1734 - accuracy: 0.9590 - val_loss: 1.0834 - val_accuracy: 0.6625\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1709 - accuracy: 0.9654 - val_loss: 1.1342 - val_accuracy: 0.6475\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1569 - accuracy: 0.9687 - val_loss: 1.2903 - val_accuracy: 0.6075\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2076 - accuracy: 0.9458 - val_loss: 1.2262 - val_accuracy: 0.6087\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1614 - accuracy: 0.9660 - val_loss: 1.0886 - val_accuracy: 0.6575\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1389 - accuracy: 0.9736 - val_loss: 1.1256 - val_accuracy: 0.6450\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1230 - accuracy: 0.9694 - val_loss: 1.1012 - val_accuracy: 0.6375\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1343 - accuracy: 0.9694 - val_loss: 1.1913 - val_accuracy: 0.6375\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1415 - accuracy: 0.9694 - val_loss: 1.2135 - val_accuracy: 0.6475\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1255 - accuracy: 0.9807 - val_loss: 1.1386 - val_accuracy: 0.6625\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1179 - accuracy: 0.9755 - val_loss: 1.1568 - val_accuracy: 0.6625\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0971 - accuracy: 0.9873 - val_loss: 1.1729 - val_accuracy: 0.6575\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0896 - accuracy: 0.9899 - val_loss: 1.2008 - val_accuracy: 0.6450\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0998 - accuracy: 0.9826 - val_loss: 1.2200 - val_accuracy: 0.6463\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1079 - accuracy: 0.9776 - val_loss: 1.1165 - val_accuracy: 0.6662\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1328 - accuracy: 0.9754 - val_loss: 1.1399 - val_accuracy: 0.6625\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0825 - accuracy: 0.9913 - val_loss: 1.1528 - val_accuracy: 0.6475\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0850 - accuracy: 0.9923 - val_loss: 1.1119 - val_accuracy: 0.6725\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0840 - accuracy: 0.9905 - val_loss: 1.1087 - val_accuracy: 0.6687\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0787 - accuracy: 0.9885 - val_loss: 1.1272 - val_accuracy: 0.6587\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0710 - accuracy: 0.9923 - val_loss: 1.2474 - val_accuracy: 0.6438\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0640 - accuracy: 0.9936 - val_loss: 1.2329 - val_accuracy: 0.6200\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0644 - accuracy: 0.9934 - val_loss: 1.2039 - val_accuracy: 0.6450\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0772 - accuracy: 0.9857 - val_loss: 1.1483 - val_accuracy: 0.6687\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0633 - accuracy: 0.9943 - val_loss: 1.1579 - val_accuracy: 0.6575\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0633 - accuracy: 0.9940 - val_loss: 1.3416 - val_accuracy: 0.6225\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1117 - accuracy: 0.9759 - val_loss: 1.1404 - val_accuracy: 0.6662\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0720 - accuracy: 0.9878 - val_loss: 1.1792 - val_accuracy: 0.6600\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0534 - accuracy: 0.9961 - val_loss: 1.1576 - val_accuracy: 0.6637\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0548 - accuracy: 0.9944 - val_loss: 1.1383 - val_accuracy: 0.6737\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0477 - accuracy: 0.9965 - val_loss: 1.1805 - val_accuracy: 0.6625\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0616 - accuracy: 0.9907 - val_loss: 1.1793 - val_accuracy: 0.6562\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0511 - accuracy: 0.9913 - val_loss: 1.1921 - val_accuracy: 0.6538\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0432 - accuracy: 0.9971 - val_loss: 1.1891 - val_accuracy: 0.6687\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0438 - accuracy: 0.9957 - val_loss: 1.1875 - val_accuracy: 0.6737\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0378 - accuracy: 0.9968 - val_loss: 1.2979 - val_accuracy: 0.6413\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0390 - accuracy: 0.9988 - val_loss: 1.1640 - val_accuracy: 0.6637\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0398 - accuracy: 0.9989 - val_loss: 1.2256 - val_accuracy: 0.6600\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0431 - accuracy: 0.9945 - val_loss: 1.2067 - val_accuracy: 0.6737\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0634 - accuracy: 0.9873 - val_loss: 1.1798 - val_accuracy: 0.6662\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.0432 - accuracy: 0.9954 - val_loss: 1.2634 - val_accuracy: 0.6575\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0426 - accuracy: 0.9932 - val_loss: 1.1894 - val_accuracy: 0.6687\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0364 - accuracy: 0.9973 - val_loss: 1.1904 - val_accuracy: 0.6800\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0404 - accuracy: 0.9936 - val_loss: 1.1754 - val_accuracy: 0.6762\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0345 - accuracy: 0.9978 - val_loss: 1.1920 - val_accuracy: 0.6675\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0300 - accuracy: 0.9987 - val_loss: 1.2232 - val_accuracy: 0.6575\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_36 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 2048)              25167872  \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 27,274,248\n",
      "Trainable params: 27,274,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 2.1082 - accuracy: 0.2160 - val_loss: 1.6829 - val_accuracy: 0.3425\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.6189 - accuracy: 0.4151 - val_loss: 1.6283 - val_accuracy: 0.3800\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.5138 - accuracy: 0.4478 - val_loss: 1.4269 - val_accuracy: 0.5088\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.4253 - accuracy: 0.4798 - val_loss: 1.5499 - val_accuracy: 0.4087\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3651 - accuracy: 0.5247 - val_loss: 1.4032 - val_accuracy: 0.4900\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3133 - accuracy: 0.5605 - val_loss: 1.3029 - val_accuracy: 0.5400\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1903 - accuracy: 0.5798 - val_loss: 1.3441 - val_accuracy: 0.5375\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1088 - accuracy: 0.6138 - val_loss: 1.3906 - val_accuracy: 0.4787\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1348 - accuracy: 0.6001 - val_loss: 1.3261 - val_accuracy: 0.5362\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.0734 - accuracy: 0.6306 - val_loss: 1.2138 - val_accuracy: 0.5688\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.9871 - accuracy: 0.6686 - val_loss: 1.3607 - val_accuracy: 0.5013\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9677 - accuracy: 0.6643 - val_loss: 1.2157 - val_accuracy: 0.5863\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9736 - accuracy: 0.6779 - val_loss: 1.1894 - val_accuracy: 0.5813\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9429 - accuracy: 0.6746 - val_loss: 1.1498 - val_accuracy: 0.5925\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9134 - accuracy: 0.6960 - val_loss: 1.1426 - val_accuracy: 0.5850\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8655 - accuracy: 0.7099 - val_loss: 1.2038 - val_accuracy: 0.5850\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8021 - accuracy: 0.7260 - val_loss: 1.1929 - val_accuracy: 0.5575\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7794 - accuracy: 0.7382 - val_loss: 1.1164 - val_accuracy: 0.6263\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7358 - accuracy: 0.7639 - val_loss: 1.1862 - val_accuracy: 0.5713\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7112 - accuracy: 0.7608 - val_loss: 1.0982 - val_accuracy: 0.6125\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7120 - accuracy: 0.7521 - val_loss: 1.3101 - val_accuracy: 0.5337\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7222 - accuracy: 0.7733 - val_loss: 1.1557 - val_accuracy: 0.6313\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6575 - accuracy: 0.7749 - val_loss: 1.3507 - val_accuracy: 0.5700\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6055 - accuracy: 0.8023 - val_loss: 1.3066 - val_accuracy: 0.5688\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6224 - accuracy: 0.7989 - val_loss: 1.5759 - val_accuracy: 0.5050\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5446 - accuracy: 0.8255 - val_loss: 1.1805 - val_accuracy: 0.5962\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5214 - accuracy: 0.8291 - val_loss: 1.1828 - val_accuracy: 0.6100\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4799 - accuracy: 0.8628 - val_loss: 1.1459 - val_accuracy: 0.6237\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4786 - accuracy: 0.8440 - val_loss: 1.0434 - val_accuracy: 0.6413\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5027 - accuracy: 0.8258 - val_loss: 1.1347 - val_accuracy: 0.6112\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4500 - accuracy: 0.8579 - val_loss: 1.6671 - val_accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4637 - accuracy: 0.8551 - val_loss: 1.1282 - val_accuracy: 0.6288\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4378 - accuracy: 0.8588 - val_loss: 1.1413 - val_accuracy: 0.6212\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3824 - accuracy: 0.8846 - val_loss: 1.0911 - val_accuracy: 0.6275\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3954 - accuracy: 0.8758 - val_loss: 1.0796 - val_accuracy: 0.6500\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3841 - accuracy: 0.8771 - val_loss: 1.2846 - val_accuracy: 0.5913\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2837 - accuracy: 0.9215 - val_loss: 1.0306 - val_accuracy: 0.6513\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3262 - accuracy: 0.9053 - val_loss: 1.0779 - val_accuracy: 0.6575\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3004 - accuracy: 0.9122 - val_loss: 1.1243 - val_accuracy: 0.6288\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3647 - accuracy: 0.8817 - val_loss: 1.1227 - val_accuracy: 0.6237\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2641 - accuracy: 0.9250 - val_loss: 1.0720 - val_accuracy: 0.6475\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2204 - accuracy: 0.9376 - val_loss: 1.0693 - val_accuracy: 0.6625\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2204 - accuracy: 0.9311 - val_loss: 1.1080 - val_accuracy: 0.6375\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2263 - accuracy: 0.9383 - val_loss: 1.0745 - val_accuracy: 0.6600\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2349 - accuracy: 0.9266 - val_loss: 1.0575 - val_accuracy: 0.6800\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2070 - accuracy: 0.9401 - val_loss: 1.2835 - val_accuracy: 0.6012\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2346 - accuracy: 0.9350 - val_loss: 1.3063 - val_accuracy: 0.6137\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1984 - accuracy: 0.9440 - val_loss: 1.0959 - val_accuracy: 0.6388\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2495 - accuracy: 0.9387 - val_loss: 1.1246 - val_accuracy: 0.6413\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1669 - accuracy: 0.9641 - val_loss: 1.1685 - val_accuracy: 0.6363\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1419 - accuracy: 0.9663 - val_loss: 1.1784 - val_accuracy: 0.6388\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1518 - accuracy: 0.9529 - val_loss: 1.1360 - val_accuracy: 0.6562\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1488 - accuracy: 0.9608 - val_loss: 1.0845 - val_accuracy: 0.6825\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1023 - accuracy: 0.9778 - val_loss: 1.2917 - val_accuracy: 0.6087\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0915 - accuracy: 0.9811 - val_loss: 1.1450 - val_accuracy: 0.6550\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0913 - accuracy: 0.9822 - val_loss: 1.1373 - val_accuracy: 0.6513\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1111 - accuracy: 0.9743 - val_loss: 1.1563 - val_accuracy: 0.6575\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1004 - accuracy: 0.9755 - val_loss: 1.4986 - val_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1290 - accuracy: 0.9619 - val_loss: 1.1672 - val_accuracy: 0.6637\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1171 - accuracy: 0.9713 - val_loss: 1.1289 - val_accuracy: 0.6700\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0863 - accuracy: 0.9786 - val_loss: 1.1890 - val_accuracy: 0.6637\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1253 - accuracy: 0.9764 - val_loss: 1.1111 - val_accuracy: 0.6237\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2267 - accuracy: 0.9358 - val_loss: 1.1650 - val_accuracy: 0.6438\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1110 - accuracy: 0.9778 - val_loss: 1.1348 - val_accuracy: 0.6488\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0782 - accuracy: 0.9892 - val_loss: 1.1510 - val_accuracy: 0.6637\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1606 - accuracy: 0.9576 - val_loss: 1.1815 - val_accuracy: 0.6438\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0717 - accuracy: 0.9909 - val_loss: 1.2173 - val_accuracy: 0.6488\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0619 - accuracy: 0.9927 - val_loss: 1.4985 - val_accuracy: 0.6037\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0658 - accuracy: 0.9877 - val_loss: 1.2236 - val_accuracy: 0.6612\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0568 - accuracy: 0.9906 - val_loss: 1.2012 - val_accuracy: 0.6662\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0456 - accuracy: 0.9942 - val_loss: 1.2943 - val_accuracy: 0.6463\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0545 - accuracy: 0.9914 - val_loss: 1.3049 - val_accuracy: 0.6350\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0826 - accuracy: 0.9809 - val_loss: 1.1996 - val_accuracy: 0.6712\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0375 - accuracy: 0.9970 - val_loss: 1.2307 - val_accuracy: 0.6550\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0464 - accuracy: 0.9925 - val_loss: 1.2578 - val_accuracy: 0.6400\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0355 - accuracy: 0.9972 - val_loss: 1.2427 - val_accuracy: 0.6587\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0311 - accuracy: 0.9973 - val_loss: 1.2678 - val_accuracy: 0.6550\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0317 - accuracy: 0.9968 - val_loss: 1.2598 - val_accuracy: 0.6725\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0290 - accuracy: 0.9964 - val_loss: 1.2773 - val_accuracy: 0.6587\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0292 - accuracy: 0.9978 - val_loss: 1.2621 - val_accuracy: 0.6538\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0243 - accuracy: 0.9987 - val_loss: 1.3248 - val_accuracy: 0.6575\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0296 - accuracy: 0.9974 - val_loss: 1.2545 - val_accuracy: 0.6625\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0234 - accuracy: 0.9965 - val_loss: 1.2904 - val_accuracy: 0.6637\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0293 - accuracy: 0.9977 - val_loss: 1.2538 - val_accuracy: 0.6650\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0190 - accuracy: 0.9976 - val_loss: 1.2819 - val_accuracy: 0.6612\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2284 - accuracy: 0.9546 - val_loss: 1.2231 - val_accuracy: 0.6488\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0368 - accuracy: 0.9975 - val_loss: 1.2384 - val_accuracy: 0.6600\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0257 - accuracy: 0.9972 - val_loss: 1.3687 - val_accuracy: 0.6413\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0425 - accuracy: 0.9961 - val_loss: 1.3113 - val_accuracy: 0.6562\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0158 - accuracy: 0.9997 - val_loss: 1.2907 - val_accuracy: 0.6625\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0164 - accuracy: 0.9987 - val_loss: 1.3026 - val_accuracy: 0.6562\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0158 - accuracy: 0.9990 - val_loss: 1.2916 - val_accuracy: 0.6637\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0135 - accuracy: 0.9996 - val_loss: 1.3102 - val_accuracy: 0.6612\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0206 - accuracy: 0.9967 - val_loss: 1.2798 - val_accuracy: 0.6712\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0128 - accuracy: 0.9998 - val_loss: 1.4602 - val_accuracy: 0.6438\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0162 - accuracy: 0.9998 - val_loss: 1.3046 - val_accuracy: 0.6637\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0110 - accuracy: 0.9999 - val_loss: 1.3073 - val_accuracy: 0.6625\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.3203 - val_accuracy: 0.6538\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0196 - accuracy: 0.9979 - val_loss: 1.3238 - val_accuracy: 0.6575\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0126 - accuracy: 0.9987 - val_loss: 1.3313 - val_accuracy: 0.6575\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_37 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 3072)              37751808  \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 768)               2360064   \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 8)                 6152      \n",
      "=================================================================\n",
      "Total params: 40,118,024\n",
      "Trainable params: 40,118,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 6s 45ms/step - loss: 2.1308 - accuracy: 0.2334 - val_loss: 1.7748 - val_accuracy: 0.3725\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.6466 - accuracy: 0.3785 - val_loss: 1.6057 - val_accuracy: 0.4125\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.5061 - accuracy: 0.4425 - val_loss: 1.6782 - val_accuracy: 0.3550\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.4787 - accuracy: 0.4527 - val_loss: 1.5787 - val_accuracy: 0.4100\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.3648 - accuracy: 0.5248 - val_loss: 1.4087 - val_accuracy: 0.4575\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.2263 - accuracy: 0.5701 - val_loss: 1.3730 - val_accuracy: 0.4988\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1907 - accuracy: 0.6024 - val_loss: 1.3956 - val_accuracy: 0.4950\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1219 - accuracy: 0.6065 - val_loss: 1.2408 - val_accuracy: 0.5675\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.0528 - accuracy: 0.6411 - val_loss: 1.1880 - val_accuracy: 0.6025\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0266 - accuracy: 0.6514 - val_loss: 1.3306 - val_accuracy: 0.5238\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0141 - accuracy: 0.6492 - val_loss: 1.4829 - val_accuracy: 0.4450\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0118 - accuracy: 0.6541 - val_loss: 1.3847 - val_accuracy: 0.5288\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9560 - accuracy: 0.6847 - val_loss: 1.2927 - val_accuracy: 0.5163\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8875 - accuracy: 0.7103 - val_loss: 1.3202 - val_accuracy: 0.5425\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8934 - accuracy: 0.6995 - val_loss: 1.1612 - val_accuracy: 0.5900\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8115 - accuracy: 0.7382 - val_loss: 1.1526 - val_accuracy: 0.5825\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7709 - accuracy: 0.7412 - val_loss: 1.1631 - val_accuracy: 0.5838\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7261 - accuracy: 0.7508 - val_loss: 1.1347 - val_accuracy: 0.6137\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7404 - accuracy: 0.7468 - val_loss: 1.1088 - val_accuracy: 0.6037\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6695 - accuracy: 0.7859 - val_loss: 1.2065 - val_accuracy: 0.5900\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6826 - accuracy: 0.7720 - val_loss: 1.1052 - val_accuracy: 0.6350\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.6341 - accuracy: 0.7884 - val_loss: 1.1827 - val_accuracy: 0.6000\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6374 - accuracy: 0.7908 - val_loss: 1.1961 - val_accuracy: 0.5800\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6523 - accuracy: 0.7832 - val_loss: 1.3898 - val_accuracy: 0.5387\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5718 - accuracy: 0.8079 - val_loss: 1.5650 - val_accuracy: 0.5200\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5712 - accuracy: 0.8140 - val_loss: 1.1688 - val_accuracy: 0.6037\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6377 - accuracy: 0.7903 - val_loss: 1.0615 - val_accuracy: 0.6550\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5022 - accuracy: 0.8390 - val_loss: 1.2065 - val_accuracy: 0.6162\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5008 - accuracy: 0.8327 - val_loss: 1.1534 - val_accuracy: 0.6112\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4245 - accuracy: 0.8687 - val_loss: 1.3490 - val_accuracy: 0.5800\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4113 - accuracy: 0.8674 - val_loss: 1.1329 - val_accuracy: 0.6438\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4477 - accuracy: 0.8609 - val_loss: 1.0541 - val_accuracy: 0.6375\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3990 - accuracy: 0.8795 - val_loss: 1.1896 - val_accuracy: 0.5938\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3508 - accuracy: 0.8929 - val_loss: 1.1636 - val_accuracy: 0.6137\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3482 - accuracy: 0.8910 - val_loss: 1.1198 - val_accuracy: 0.6187\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3461 - accuracy: 0.8970 - val_loss: 1.1182 - val_accuracy: 0.6612\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2830 - accuracy: 0.9213 - val_loss: 1.5346 - val_accuracy: 0.5487\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3384 - accuracy: 0.8953 - val_loss: 1.1421 - val_accuracy: 0.6062\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2759 - accuracy: 0.9182 - val_loss: 1.1734 - val_accuracy: 0.6162\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3022 - accuracy: 0.9005 - val_loss: 1.1508 - val_accuracy: 0.6500\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2901 - accuracy: 0.9018 - val_loss: 1.5185 - val_accuracy: 0.5938\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2818 - accuracy: 0.9102 - val_loss: 1.1547 - val_accuracy: 0.6325\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2723 - accuracy: 0.9181 - val_loss: 1.2060 - val_accuracy: 0.6325\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2018 - accuracy: 0.9479 - val_loss: 1.2464 - val_accuracy: 0.6200\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1979 - accuracy: 0.9434 - val_loss: 1.0918 - val_accuracy: 0.6737\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.1754 - accuracy: 0.9596 - val_loss: 1.1417 - val_accuracy: 0.6288\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.1621 - accuracy: 0.9638 - val_loss: 1.1569 - val_accuracy: 0.6550\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1402 - accuracy: 0.9680 - val_loss: 1.1579 - val_accuracy: 0.6375\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1441 - accuracy: 0.9666 - val_loss: 1.1311 - val_accuracy: 0.6750\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1779 - accuracy: 0.9437 - val_loss: 1.2032 - val_accuracy: 0.6388\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2046 - accuracy: 0.9378 - val_loss: 1.1310 - val_accuracy: 0.6775\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1099 - accuracy: 0.9792 - val_loss: 1.1685 - val_accuracy: 0.6538\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1070 - accuracy: 0.9773 - val_loss: 1.1660 - val_accuracy: 0.6612\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1412 - accuracy: 0.9613 - val_loss: 1.3345 - val_accuracy: 0.6037\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1957 - accuracy: 0.9469 - val_loss: 1.1290 - val_accuracy: 0.6388\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1414 - accuracy: 0.9662 - val_loss: 1.2722 - val_accuracy: 0.6200\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0962 - accuracy: 0.9801 - val_loss: 1.1940 - val_accuracy: 0.6450\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0986 - accuracy: 0.9779 - val_loss: 1.1797 - val_accuracy: 0.6525\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0743 - accuracy: 0.9876 - val_loss: 1.1983 - val_accuracy: 0.6463\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0898 - accuracy: 0.9713 - val_loss: 1.1384 - val_accuracy: 0.6762\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1387 - accuracy: 0.9705 - val_loss: 1.1651 - val_accuracy: 0.6425\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0965 - accuracy: 0.9801 - val_loss: 1.1448 - val_accuracy: 0.6637\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0721 - accuracy: 0.9893 - val_loss: 1.1913 - val_accuracy: 0.6488\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0566 - accuracy: 0.9909 - val_loss: 1.2104 - val_accuracy: 0.6637\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0525 - accuracy: 0.9927 - val_loss: 1.2284 - val_accuracy: 0.6700\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0439 - accuracy: 0.9942 - val_loss: 1.3382 - val_accuracy: 0.6250\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0471 - accuracy: 0.9937 - val_loss: 1.2240 - val_accuracy: 0.6587\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0374 - accuracy: 0.9976 - val_loss: 1.2535 - val_accuracy: 0.6550\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0504 - accuracy: 0.9925 - val_loss: 1.2001 - val_accuracy: 0.6787\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0381 - accuracy: 0.9922 - val_loss: 1.3201 - val_accuracy: 0.6525\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0382 - accuracy: 0.9961 - val_loss: 1.2270 - val_accuracy: 0.6562\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0326 - accuracy: 0.9965 - val_loss: 1.2727 - val_accuracy: 0.6587\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0571 - accuracy: 0.9895 - val_loss: 1.2636 - val_accuracy: 0.6325\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0469 - accuracy: 0.9927 - val_loss: 1.2265 - val_accuracy: 0.6675\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0346 - accuracy: 0.9947 - val_loss: 1.3845 - val_accuracy: 0.6275\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0853 - accuracy: 0.9766 - val_loss: 1.1904 - val_accuracy: 0.6637\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0292 - accuracy: 0.9982 - val_loss: 1.2474 - val_accuracy: 0.6750\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0222 - accuracy: 0.9984 - val_loss: 1.3036 - val_accuracy: 0.6525\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0229 - accuracy: 0.9997 - val_loss: 1.2559 - val_accuracy: 0.6725\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0180 - accuracy: 0.9992 - val_loss: 1.3850 - val_accuracy: 0.6662\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 1.2616 - val_accuracy: 0.6587\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.0178 - accuracy: 0.9992 - val_loss: 1.3216 - val_accuracy: 0.6587\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0368 - accuracy: 0.9935 - val_loss: 1.2646 - val_accuracy: 0.6700\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0262 - accuracy: 0.9991 - val_loss: 1.3086 - val_accuracy: 0.6463\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0192 - accuracy: 0.9992 - val_loss: 1.2675 - val_accuracy: 0.6650\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0207 - accuracy: 0.9968 - val_loss: 1.3006 - val_accuracy: 0.6600\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0129 - accuracy: 0.9996 - val_loss: 1.2999 - val_accuracy: 0.6700\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3126 - val_accuracy: 0.6687\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.2983 - val_accuracy: 0.6775\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0130 - accuracy: 0.9997 - val_loss: 1.3145 - val_accuracy: 0.6750\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0137 - accuracy: 0.9997 - val_loss: 1.3117 - val_accuracy: 0.6687\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.3303 - val_accuracy: 0.6675\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 1.3169 - val_accuracy: 0.6687\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.6675\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0177 - accuracy: 0.9979 - val_loss: 1.3250 - val_accuracy: 0.6737\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 1.3224 - val_accuracy: 0.6775\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0091 - accuracy: 0.9997 - val_loss: 1.3489 - val_accuracy: 0.6737\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 1.3232 - val_accuracy: 0.6600\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3148 - val_accuracy: 0.6750\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 1.3582 - val_accuracy: 0.6612\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_38 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 2048)              25167872  \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 8)                 16392     \n",
      "=================================================================\n",
      "Total params: 25,184,264\n",
      "Trainable params: 25,184,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 2.5288 - accuracy: 0.2243 - val_loss: 1.8085 - val_accuracy: 0.2850\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.6598 - accuracy: 0.3873 - val_loss: 1.5415 - val_accuracy: 0.4550\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.4779 - accuracy: 0.4581 - val_loss: 1.5619 - val_accuracy: 0.4350\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.4014 - accuracy: 0.4991 - val_loss: 1.4103 - val_accuracy: 0.4963\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.2986 - accuracy: 0.5542 - val_loss: 1.5391 - val_accuracy: 0.4412\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.2285 - accuracy: 0.5794 - val_loss: 1.3797 - val_accuracy: 0.5063\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 1.2209 - accuracy: 0.5897 - val_loss: 1.3251 - val_accuracy: 0.5038\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1600 - accuracy: 0.6004 - val_loss: 1.2745 - val_accuracy: 0.5838\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1416 - accuracy: 0.5984 - val_loss: 1.2295 - val_accuracy: 0.5638\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0820 - accuracy: 0.6294 - val_loss: 1.2765 - val_accuracy: 0.5788\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9662 - accuracy: 0.6677 - val_loss: 1.3120 - val_accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9839 - accuracy: 0.6623 - val_loss: 1.1706 - val_accuracy: 0.5975\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9686 - accuracy: 0.6795 - val_loss: 1.1879 - val_accuracy: 0.5950\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9268 - accuracy: 0.6789 - val_loss: 1.2199 - val_accuracy: 0.5525\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9342 - accuracy: 0.6918 - val_loss: 1.1773 - val_accuracy: 0.5775\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8963 - accuracy: 0.6847 - val_loss: 1.1870 - val_accuracy: 0.6050\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8387 - accuracy: 0.7331 - val_loss: 1.1738 - val_accuracy: 0.5813\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8418 - accuracy: 0.7177 - val_loss: 1.1344 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7665 - accuracy: 0.7434 - val_loss: 1.2413 - val_accuracy: 0.5638\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8045 - accuracy: 0.7377 - val_loss: 1.3136 - val_accuracy: 0.5412\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7281 - accuracy: 0.7554 - val_loss: 1.0936 - val_accuracy: 0.6313\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6889 - accuracy: 0.7701 - val_loss: 1.2449 - val_accuracy: 0.5750\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6596 - accuracy: 0.7907 - val_loss: 1.2650 - val_accuracy: 0.5838\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6648 - accuracy: 0.7872 - val_loss: 1.1436 - val_accuracy: 0.6087\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6152 - accuracy: 0.7970 - val_loss: 1.1264 - val_accuracy: 0.6237\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6243 - accuracy: 0.7920 - val_loss: 1.0851 - val_accuracy: 0.6350\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6102 - accuracy: 0.8127 - val_loss: 1.2261 - val_accuracy: 0.6025\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5874 - accuracy: 0.8188 - val_loss: 1.2480 - val_accuracy: 0.5913\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5553 - accuracy: 0.8206 - val_loss: 1.1000 - val_accuracy: 0.6313\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5026 - accuracy: 0.8408 - val_loss: 1.1072 - val_accuracy: 0.6288\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5037 - accuracy: 0.8360 - val_loss: 1.0520 - val_accuracy: 0.6562\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5189 - accuracy: 0.8499 - val_loss: 1.0400 - val_accuracy: 0.6525\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4496 - accuracy: 0.8592 - val_loss: 1.1975 - val_accuracy: 0.6137\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4783 - accuracy: 0.8509 - val_loss: 1.1115 - val_accuracy: 0.5987\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4275 - accuracy: 0.8661 - val_loss: 1.1220 - val_accuracy: 0.6363\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4071 - accuracy: 0.8756 - val_loss: 1.0319 - val_accuracy: 0.6587\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3708 - accuracy: 0.8858 - val_loss: 1.1615 - val_accuracy: 0.6075\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3704 - accuracy: 0.8934 - val_loss: 1.1478 - val_accuracy: 0.6325\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3745 - accuracy: 0.8775 - val_loss: 1.2252 - val_accuracy: 0.6025\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3870 - accuracy: 0.8877 - val_loss: 1.1448 - val_accuracy: 0.6263\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3360 - accuracy: 0.9024 - val_loss: 1.0352 - val_accuracy: 0.6550\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3445 - accuracy: 0.9064 - val_loss: 1.3887 - val_accuracy: 0.5600\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3588 - accuracy: 0.8890 - val_loss: 1.1888 - val_accuracy: 0.6112\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3371 - accuracy: 0.8848 - val_loss: 1.1682 - val_accuracy: 0.6400\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2718 - accuracy: 0.9272 - val_loss: 1.1966 - val_accuracy: 0.6012\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2703 - accuracy: 0.9237 - val_loss: 1.0530 - val_accuracy: 0.6413\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2652 - accuracy: 0.9241 - val_loss: 1.0777 - val_accuracy: 0.6712\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2382 - accuracy: 0.9454 - val_loss: 1.6357 - val_accuracy: 0.5075\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2443 - accuracy: 0.9385 - val_loss: 1.1875 - val_accuracy: 0.6062\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2134 - accuracy: 0.9549 - val_loss: 1.2808 - val_accuracy: 0.6137\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2432 - accuracy: 0.9366 - val_loss: 1.0575 - val_accuracy: 0.6625\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2328 - accuracy: 0.9371 - val_loss: 1.1974 - val_accuracy: 0.6338\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2780 - accuracy: 0.9259 - val_loss: 1.3069 - val_accuracy: 0.5938\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2022 - accuracy: 0.9502 - val_loss: 1.1690 - val_accuracy: 0.6475\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1931 - accuracy: 0.9594 - val_loss: 1.0888 - val_accuracy: 0.6612\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1905 - accuracy: 0.9503 - val_loss: 1.0882 - val_accuracy: 0.6637\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1883 - accuracy: 0.9572 - val_loss: 1.1767 - val_accuracy: 0.6250\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1579 - accuracy: 0.9715 - val_loss: 1.1025 - val_accuracy: 0.6550\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1810 - accuracy: 0.9574 - val_loss: 1.1892 - val_accuracy: 0.6150\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1546 - accuracy: 0.9618 - val_loss: 1.3496 - val_accuracy: 0.5987\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1503 - accuracy: 0.9645 - val_loss: 1.0947 - val_accuracy: 0.6700\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.1271 - accuracy: 0.9766 - val_loss: 1.1867 - val_accuracy: 0.6488\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1427 - accuracy: 0.9681 - val_loss: 1.1669 - val_accuracy: 0.6425\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1199 - accuracy: 0.9731 - val_loss: 1.3265 - val_accuracy: 0.6250\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1374 - accuracy: 0.9668 - val_loss: 1.1134 - val_accuracy: 0.6538\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1255 - accuracy: 0.9777 - val_loss: 1.2151 - val_accuracy: 0.6488\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1127 - accuracy: 0.9813 - val_loss: 1.1118 - val_accuracy: 0.6650\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1136 - accuracy: 0.9782 - val_loss: 1.1724 - val_accuracy: 0.6575\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1190 - accuracy: 0.9666 - val_loss: 1.1836 - val_accuracy: 0.6425\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0926 - accuracy: 0.9820 - val_loss: 2.2979 - val_accuracy: 0.4988\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1241 - accuracy: 0.9687 - val_loss: 1.3311 - val_accuracy: 0.6212\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0946 - accuracy: 0.9857 - val_loss: 1.1343 - val_accuracy: 0.6687\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0854 - accuracy: 0.9867 - val_loss: 1.1868 - val_accuracy: 0.6488\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0735 - accuracy: 0.9913 - val_loss: 1.1903 - val_accuracy: 0.6488\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0691 - accuracy: 0.9932 - val_loss: 1.2009 - val_accuracy: 0.6550\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1117 - accuracy: 0.9751 - val_loss: 1.1771 - val_accuracy: 0.6488\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0687 - accuracy: 0.9905 - val_loss: 1.2152 - val_accuracy: 0.6463\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1087 - accuracy: 0.9688 - val_loss: 1.1277 - val_accuracy: 0.6800\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0659 - accuracy: 0.9925 - val_loss: 1.1798 - val_accuracy: 0.6463\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0728 - accuracy: 0.9900 - val_loss: 1.1428 - val_accuracy: 0.6750\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0587 - accuracy: 0.9913 - val_loss: 1.1359 - val_accuracy: 0.6800\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0502 - accuracy: 0.9959 - val_loss: 1.3350 - val_accuracy: 0.6288\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0801 - accuracy: 0.9841 - val_loss: 1.1790 - val_accuracy: 0.6550\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0622 - accuracy: 0.9902 - val_loss: 1.2169 - val_accuracy: 0.6575\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0532 - accuracy: 0.9953 - val_loss: 1.1826 - val_accuracy: 0.6675\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0498 - accuracy: 0.9952 - val_loss: 1.1906 - val_accuracy: 0.6650\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0462 - accuracy: 0.9934 - val_loss: 1.1608 - val_accuracy: 0.6675\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0513 - accuracy: 0.9924 - val_loss: 1.2253 - val_accuracy: 0.6500\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0492 - accuracy: 0.9952 - val_loss: 1.1922 - val_accuracy: 0.6675\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0463 - accuracy: 0.9944 - val_loss: 1.1897 - val_accuracy: 0.6612\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0430 - accuracy: 0.9979 - val_loss: 1.1886 - val_accuracy: 0.6625\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0449 - accuracy: 0.9929 - val_loss: 1.1904 - val_accuracy: 0.6625\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0504 - accuracy: 0.9945 - val_loss: 1.2074 - val_accuracy: 0.6550\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0379 - accuracy: 0.9963 - val_loss: 1.2911 - val_accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0410 - accuracy: 0.9964 - val_loss: 1.4853 - val_accuracy: 0.5975\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0517 - accuracy: 0.9942 - val_loss: 1.1779 - val_accuracy: 0.6700\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0362 - accuracy: 0.9967 - val_loss: 1.1733 - val_accuracy: 0.6712\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0320 - accuracy: 0.9968 - val_loss: 1.1949 - val_accuracy: 0.6637\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0787 - accuracy: 0.9869 - val_loss: 1.1995 - val_accuracy: 0.6725\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0421 - accuracy: 0.9924 - val_loss: 1.2206 - val_accuracy: 0.6562\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_39 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 3072)              37751808  \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 8)                 24584     \n",
      "=================================================================\n",
      "Total params: 37,776,392\n",
      "Trainable params: 37,776,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 6s 45ms/step - loss: 2.5567 - accuracy: 0.2212 - val_loss: 1.5832 - val_accuracy: 0.4300\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.5800 - accuracy: 0.4112 - val_loss: 1.4755 - val_accuracy: 0.4812\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.4949 - accuracy: 0.4508 - val_loss: 1.4332 - val_accuracy: 0.4850\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.3458 - accuracy: 0.5323 - val_loss: 1.5133 - val_accuracy: 0.4350\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 1.3027 - accuracy: 0.5384 - val_loss: 1.3159 - val_accuracy: 0.5387\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 1.2311 - accuracy: 0.5762 - val_loss: 1.3753 - val_accuracy: 0.5150\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 1.1530 - accuracy: 0.6196 - val_loss: 1.4073 - val_accuracy: 0.4762\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1339 - accuracy: 0.5967 - val_loss: 1.2818 - val_accuracy: 0.5500\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0540 - accuracy: 0.6128 - val_loss: 1.2313 - val_accuracy: 0.5938\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0262 - accuracy: 0.6545 - val_loss: 1.5058 - val_accuracy: 0.4825\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0324 - accuracy: 0.6465 - val_loss: 1.2229 - val_accuracy: 0.5775\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8952 - accuracy: 0.7097 - val_loss: 1.3755 - val_accuracy: 0.5125\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9392 - accuracy: 0.6817 - val_loss: 1.2324 - val_accuracy: 0.5713\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8525 - accuracy: 0.7179 - val_loss: 1.2975 - val_accuracy: 0.5437\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8812 - accuracy: 0.7035 - val_loss: 1.1795 - val_accuracy: 0.5775\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8053 - accuracy: 0.7295 - val_loss: 1.1234 - val_accuracy: 0.6050\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8067 - accuracy: 0.7381 - val_loss: 1.1259 - val_accuracy: 0.6112\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7606 - accuracy: 0.7399 - val_loss: 1.3617 - val_accuracy: 0.5113\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.7901 - accuracy: 0.7301 - val_loss: 1.0924 - val_accuracy: 0.6225\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7338 - accuracy: 0.7661 - val_loss: 1.0799 - val_accuracy: 0.6275\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6950 - accuracy: 0.7724 - val_loss: 1.1672 - val_accuracy: 0.5900\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7005 - accuracy: 0.7754 - val_loss: 1.1061 - val_accuracy: 0.6087\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6593 - accuracy: 0.7865 - val_loss: 1.1829 - val_accuracy: 0.5750\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6110 - accuracy: 0.8011 - val_loss: 1.4981 - val_accuracy: 0.5025\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6048 - accuracy: 0.8107 - val_loss: 1.0894 - val_accuracy: 0.6288\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5540 - accuracy: 0.8251 - val_loss: 1.2100 - val_accuracy: 0.6100\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6049 - accuracy: 0.8075 - val_loss: 1.0759 - val_accuracy: 0.6275\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5301 - accuracy: 0.8375 - val_loss: 1.1835 - val_accuracy: 0.6050\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4851 - accuracy: 0.8590 - val_loss: 1.0852 - val_accuracy: 0.6237\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.4790 - accuracy: 0.8570 - val_loss: 1.1015 - val_accuracy: 0.6275\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4884 - accuracy: 0.8502 - val_loss: 1.1582 - val_accuracy: 0.6225\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4697 - accuracy: 0.8599 - val_loss: 1.2793 - val_accuracy: 0.5813\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4566 - accuracy: 0.8680 - val_loss: 1.0253 - val_accuracy: 0.6325\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4124 - accuracy: 0.8794 - val_loss: 1.2569 - val_accuracy: 0.5775\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3843 - accuracy: 0.8831 - val_loss: 1.1394 - val_accuracy: 0.6175\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.3742 - accuracy: 0.8753 - val_loss: 1.0960 - val_accuracy: 0.6288\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.3806 - accuracy: 0.8871 - val_loss: 1.2145 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4126 - accuracy: 0.8714 - val_loss: 1.2287 - val_accuracy: 0.6025\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.3687 - accuracy: 0.8886 - val_loss: 1.0440 - val_accuracy: 0.6413\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.2990 - accuracy: 0.9198 - val_loss: 1.0562 - val_accuracy: 0.6388\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.3238 - accuracy: 0.9060 - val_loss: 1.6755 - val_accuracy: 0.5537\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.2959 - accuracy: 0.9235 - val_loss: 1.0566 - val_accuracy: 0.6500\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2722 - accuracy: 0.9254 - val_loss: 1.1648 - val_accuracy: 0.6275\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.2548 - accuracy: 0.9373 - val_loss: 1.1775 - val_accuracy: 0.6212\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.2805 - accuracy: 0.9149 - val_loss: 1.0726 - val_accuracy: 0.6675\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.2385 - accuracy: 0.9423 - val_loss: 1.0197 - val_accuracy: 0.6637\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.2129 - accuracy: 0.9493 - val_loss: 1.1397 - val_accuracy: 0.6363\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.2882 - accuracy: 0.9309 - val_loss: 1.1297 - val_accuracy: 0.6400\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.2170 - accuracy: 0.9486 - val_loss: 1.0751 - val_accuracy: 0.6425\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1902 - accuracy: 0.9574 - val_loss: 1.0735 - val_accuracy: 0.6425\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1741 - accuracy: 0.9613 - val_loss: 1.2263 - val_accuracy: 0.6300\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2244 - accuracy: 0.9416 - val_loss: 1.0766 - val_accuracy: 0.6538\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.1632 - accuracy: 0.9704 - val_loss: 1.0851 - val_accuracy: 0.6525\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2061 - accuracy: 0.9428 - val_loss: 1.0603 - val_accuracy: 0.6662\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.1474 - accuracy: 0.9703 - val_loss: 1.1653 - val_accuracy: 0.6550\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.2061 - accuracy: 0.9567 - val_loss: 1.1143 - val_accuracy: 0.6338\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.1493 - accuracy: 0.9698 - val_loss: 1.0660 - val_accuracy: 0.6687\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1648 - accuracy: 0.9696 - val_loss: 1.4101 - val_accuracy: 0.5838\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1881 - accuracy: 0.9582 - val_loss: 1.1534 - val_accuracy: 0.6463\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1585 - accuracy: 0.9683 - val_loss: 1.1379 - val_accuracy: 0.6400\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1270 - accuracy: 0.9713 - val_loss: 1.1266 - val_accuracy: 0.6625\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1508 - accuracy: 0.9568 - val_loss: 1.1062 - val_accuracy: 0.6625\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1299 - accuracy: 0.9718 - val_loss: 1.0895 - val_accuracy: 0.6525\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.1197 - accuracy: 0.9742 - val_loss: 1.1994 - val_accuracy: 0.6438\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1161 - accuracy: 0.9795 - val_loss: 1.1249 - val_accuracy: 0.6538\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1108 - accuracy: 0.9758 - val_loss: 1.1959 - val_accuracy: 0.6400\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1247 - accuracy: 0.9744 - val_loss: 1.1001 - val_accuracy: 0.6600\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1027 - accuracy: 0.9798 - val_loss: 1.1051 - val_accuracy: 0.6562\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0872 - accuracy: 0.9893 - val_loss: 1.0878 - val_accuracy: 0.6750\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0781 - accuracy: 0.9882 - val_loss: 1.1300 - val_accuracy: 0.6587\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0694 - accuracy: 0.9940 - val_loss: 1.1468 - val_accuracy: 0.6500\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0690 - accuracy: 0.9900 - val_loss: 1.1863 - val_accuracy: 0.6375\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0839 - accuracy: 0.9873 - val_loss: 1.1258 - val_accuracy: 0.6550\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0819 - accuracy: 0.9880 - val_loss: 1.1427 - val_accuracy: 0.6488\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0701 - accuracy: 0.9867 - val_loss: 1.1698 - val_accuracy: 0.6513\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0798 - accuracy: 0.9811 - val_loss: 1.1259 - val_accuracy: 0.6488\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0728 - accuracy: 0.9908 - val_loss: 1.2008 - val_accuracy: 0.6325\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0924 - accuracy: 0.9812 - val_loss: 1.1427 - val_accuracy: 0.6575\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0600 - accuracy: 0.9916 - val_loss: 1.1533 - val_accuracy: 0.6612\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0500 - accuracy: 0.9944 - val_loss: 1.1400 - val_accuracy: 0.6637\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0549 - accuracy: 0.9968 - val_loss: 1.2360 - val_accuracy: 0.6350\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0675 - accuracy: 0.9880 - val_loss: 1.1512 - val_accuracy: 0.6600\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0524 - accuracy: 0.9940 - val_loss: 1.1285 - val_accuracy: 0.6737\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0482 - accuracy: 0.9963 - val_loss: 1.1608 - val_accuracy: 0.6612\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0474 - accuracy: 0.9958 - val_loss: 1.1396 - val_accuracy: 0.6700\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0420 - accuracy: 0.9960 - val_loss: 1.1362 - val_accuracy: 0.6600\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0469 - accuracy: 0.9939 - val_loss: 1.2197 - val_accuracy: 0.6463\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0599 - accuracy: 0.9919 - val_loss: 1.1603 - val_accuracy: 0.6587\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0418 - accuracy: 0.9959 - val_loss: 1.1541 - val_accuracy: 0.6575\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0339 - accuracy: 0.9982 - val_loss: 1.1659 - val_accuracy: 0.6662\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0395 - accuracy: 0.9977 - val_loss: 1.2040 - val_accuracy: 0.6662\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0442 - accuracy: 0.9958 - val_loss: 1.1791 - val_accuracy: 0.6637\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0372 - accuracy: 0.9961 - val_loss: 1.1744 - val_accuracy: 0.6538\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0377 - accuracy: 0.9962 - val_loss: 1.1665 - val_accuracy: 0.6750\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0286 - accuracy: 0.9983 - val_loss: 1.1612 - val_accuracy: 0.6600\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0368 - accuracy: 0.9976 - val_loss: 1.1603 - val_accuracy: 0.6725\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 45ms/step - loss: 0.0368 - accuracy: 0.9957 - val_loss: 1.1821 - val_accuracy: 0.6675\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0313 - accuracy: 0.9991 - val_loss: 1.1606 - val_accuracy: 0.6737\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0285 - accuracy: 0.9980 - val_loss: 1.2183 - val_accuracy: 0.6513\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0367 - accuracy: 0.9948 - val_loss: 1.1758 - val_accuracy: 0.6700\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_40 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 2048)              25167872  \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 27,274,248\n",
      "Trainable params: 27,274,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 6s 45ms/step - loss: 2.0980 - accuracy: 0.2409 - val_loss: 1.6784 - val_accuracy: 0.3725\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.6415 - accuracy: 0.4004 - val_loss: 1.4781 - val_accuracy: 0.4913\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.4910 - accuracy: 0.4581 - val_loss: 1.4465 - val_accuracy: 0.4925\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.4690 - accuracy: 0.4712 - val_loss: 1.4287 - val_accuracy: 0.4925\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.3085 - accuracy: 0.5272 - val_loss: 1.3652 - val_accuracy: 0.5225\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.2073 - accuracy: 0.5722 - val_loss: 1.2748 - val_accuracy: 0.5600\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.2334 - accuracy: 0.5626 - val_loss: 1.3193 - val_accuracy: 0.5175\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1925 - accuracy: 0.6014 - val_loss: 1.1957 - val_accuracy: 0.5925\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1231 - accuracy: 0.6228 - val_loss: 1.2519 - val_accuracy: 0.5537\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0415 - accuracy: 0.6451 - val_loss: 1.2073 - val_accuracy: 0.5900\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.0347 - accuracy: 0.6386 - val_loss: 1.2876 - val_accuracy: 0.5437\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9368 - accuracy: 0.6808 - val_loss: 1.2101 - val_accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9505 - accuracy: 0.6666 - val_loss: 1.1712 - val_accuracy: 0.5863\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9148 - accuracy: 0.6852 - val_loss: 1.2282 - val_accuracy: 0.5462\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9059 - accuracy: 0.6896 - val_loss: 1.2656 - val_accuracy: 0.5638\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.8765 - accuracy: 0.7080 - val_loss: 1.0934 - val_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.8143 - accuracy: 0.7292 - val_loss: 1.2655 - val_accuracy: 0.5537\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.6934 - accuracy: 0.7813 - val_loss: 1.1511 - val_accuracy: 0.5863\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7419 - accuracy: 0.7584 - val_loss: 1.0972 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7444 - accuracy: 0.7573 - val_loss: 1.1021 - val_accuracy: 0.6100\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7038 - accuracy: 0.7619 - val_loss: 1.0662 - val_accuracy: 0.6425\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.6428 - accuracy: 0.7898 - val_loss: 1.1376 - val_accuracy: 0.6037\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6218 - accuracy: 0.8112 - val_loss: 1.1180 - val_accuracy: 0.6150\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.6202 - accuracy: 0.7917 - val_loss: 1.1762 - val_accuracy: 0.6075\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.5711 - accuracy: 0.8059 - val_loss: 1.1495 - val_accuracy: 0.6087\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5543 - accuracy: 0.8122 - val_loss: 1.0830 - val_accuracy: 0.6400\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.5462 - accuracy: 0.8258 - val_loss: 1.1736 - val_accuracy: 0.6012\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5145 - accuracy: 0.8281 - val_loss: 1.6725 - val_accuracy: 0.4988\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5285 - accuracy: 0.8349 - val_loss: 1.1727 - val_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4551 - accuracy: 0.8632 - val_loss: 1.1393 - val_accuracy: 0.6413\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4716 - accuracy: 0.8456 - val_loss: 1.0532 - val_accuracy: 0.6388\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4778 - accuracy: 0.8471 - val_loss: 1.0890 - val_accuracy: 0.6388\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3989 - accuracy: 0.8689 - val_loss: 1.1002 - val_accuracy: 0.6212\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3522 - accuracy: 0.8895 - val_loss: 1.0991 - val_accuracy: 0.6350\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3677 - accuracy: 0.8894 - val_loss: 1.2400 - val_accuracy: 0.6125\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.3732 - accuracy: 0.8763 - val_loss: 1.0382 - val_accuracy: 0.6625\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3010 - accuracy: 0.9101 - val_loss: 1.1754 - val_accuracy: 0.6175\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3743 - accuracy: 0.8791 - val_loss: 1.1579 - val_accuracy: 0.6425\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2953 - accuracy: 0.9121 - val_loss: 1.0839 - val_accuracy: 0.6750\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2797 - accuracy: 0.9130 - val_loss: 1.1683 - val_accuracy: 0.6200\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2937 - accuracy: 0.9192 - val_loss: 1.1253 - val_accuracy: 0.6513\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2365 - accuracy: 0.9325 - val_loss: 1.0804 - val_accuracy: 0.6712\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2140 - accuracy: 0.9445 - val_loss: 1.1262 - val_accuracy: 0.6425\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2650 - accuracy: 0.9204 - val_loss: 1.1868 - val_accuracy: 0.6288\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2193 - accuracy: 0.9339 - val_loss: 1.2476 - val_accuracy: 0.6313\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.2047 - accuracy: 0.9398 - val_loss: 1.1794 - val_accuracy: 0.6200\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2062 - accuracy: 0.9484 - val_loss: 1.1298 - val_accuracy: 0.6475\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1881 - accuracy: 0.9518 - val_loss: 1.1973 - val_accuracy: 0.6425\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1588 - accuracy: 0.9546 - val_loss: 1.1369 - val_accuracy: 0.6737\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1506 - accuracy: 0.9575 - val_loss: 1.1535 - val_accuracy: 0.6450\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1380 - accuracy: 0.9707 - val_loss: 1.2577 - val_accuracy: 0.6325\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1351 - accuracy: 0.9714 - val_loss: 1.1535 - val_accuracy: 0.6612\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1535 - accuracy: 0.9574 - val_loss: 1.0903 - val_accuracy: 0.6725\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1356 - accuracy: 0.9703 - val_loss: 1.1840 - val_accuracy: 0.6488\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1114 - accuracy: 0.9740 - val_loss: 1.1253 - val_accuracy: 0.6650\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1056 - accuracy: 0.9731 - val_loss: 1.1776 - val_accuracy: 0.6650\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1007 - accuracy: 0.9781 - val_loss: 1.2404 - val_accuracy: 0.6450\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1061 - accuracy: 0.9806 - val_loss: 1.2961 - val_accuracy: 0.6525\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1134 - accuracy: 0.9801 - val_loss: 1.1875 - val_accuracy: 0.6675\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1014 - accuracy: 0.9788 - val_loss: 1.2066 - val_accuracy: 0.6650\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0939 - accuracy: 0.9814 - val_loss: 1.1911 - val_accuracy: 0.6700\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0726 - accuracy: 0.9873 - val_loss: 1.2962 - val_accuracy: 0.6500\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0743 - accuracy: 0.9878 - val_loss: 1.1885 - val_accuracy: 0.6700\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0598 - accuracy: 0.9905 - val_loss: 1.2029 - val_accuracy: 0.6625\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0843 - accuracy: 0.9792 - val_loss: 1.1469 - val_accuracy: 0.6837\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0704 - accuracy: 0.9870 - val_loss: 1.2652 - val_accuracy: 0.6538\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0567 - accuracy: 0.9927 - val_loss: 1.1762 - val_accuracy: 0.6737\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0475 - accuracy: 0.9939 - val_loss: 1.2221 - val_accuracy: 0.6637\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0419 - accuracy: 0.9936 - val_loss: 1.2503 - val_accuracy: 0.6425\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.0485 - accuracy: 0.9931 - val_loss: 1.2063 - val_accuracy: 0.6675\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0519 - accuracy: 0.9887 - val_loss: 1.2366 - val_accuracy: 0.6700\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0407 - accuracy: 0.9933 - val_loss: 1.2621 - val_accuracy: 0.6500\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0390 - accuracy: 0.9942 - val_loss: 1.2633 - val_accuracy: 0.6725\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0296 - accuracy: 0.9977 - val_loss: 1.2538 - val_accuracy: 0.6750\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0255 - accuracy: 0.9981 - val_loss: 1.2640 - val_accuracy: 0.6787\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3072 - accuracy: 0.9320 - val_loss: 1.1817 - val_accuracy: 0.6737\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0548 - accuracy: 0.9946 - val_loss: 1.2387 - val_accuracy: 0.6712\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0348 - accuracy: 0.9968 - val_loss: 1.2383 - val_accuracy: 0.6825\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0296 - accuracy: 0.9998 - val_loss: 1.2623 - val_accuracy: 0.6712\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0290 - accuracy: 0.9963 - val_loss: 1.2798 - val_accuracy: 0.6675\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0507 - accuracy: 0.9899 - val_loss: 1.2791 - val_accuracy: 0.6400\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0418 - accuracy: 0.9956 - val_loss: 1.2557 - val_accuracy: 0.6800\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0262 - accuracy: 0.9989 - val_loss: 1.2821 - val_accuracy: 0.6700\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.3503 - val_accuracy: 0.6625\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0206 - accuracy: 0.9992 - val_loss: 1.2784 - val_accuracy: 0.6762\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0147 - accuracy: 0.9999 - val_loss: 1.2587 - val_accuracy: 0.6800\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0196 - accuracy: 0.9993 - val_loss: 1.3346 - val_accuracy: 0.6800\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0214 - accuracy: 0.9977 - val_loss: 1.2836 - val_accuracy: 0.6787\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0143 - accuracy: 0.9999 - val_loss: 1.3045 - val_accuracy: 0.6712\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0176 - accuracy: 0.9991 - val_loss: 1.3154 - val_accuracy: 0.6762\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0200 - accuracy: 0.9963 - val_loss: 1.2831 - val_accuracy: 0.6775\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0215 - accuracy: 0.9970 - val_loss: 1.3055 - val_accuracy: 0.6825\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0144 - accuracy: 0.9983 - val_loss: 1.3236 - val_accuracy: 0.6812\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0125 - accuracy: 0.9999 - val_loss: 1.3044 - val_accuracy: 0.6837\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0124 - accuracy: 0.9994 - val_loss: 1.3418 - val_accuracy: 0.6750\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0138 - accuracy: 0.9994 - val_loss: 1.3121 - val_accuracy: 0.6837\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0119 - accuracy: 0.9990 - val_loss: 1.3078 - val_accuracy: 0.6862\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0123 - accuracy: 0.9997 - val_loss: 1.3422 - val_accuracy: 0.6725\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0136 - accuracy: 0.9995 - val_loss: 1.3317 - val_accuracy: 0.6762\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0133 - accuracy: 0.9996 - val_loss: 1.3334 - val_accuracy: 0.6775\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_41 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 3072)              37751808  \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 768)               2360064   \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 8)                 6152      \n",
      "=================================================================\n",
      "Total params: 40,118,024\n",
      "Trainable params: 40,118,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 2.2739 - accuracy: 0.2276 - val_loss: 1.6430 - val_accuracy: 0.3875\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.6386 - accuracy: 0.3925 - val_loss: 1.4937 - val_accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.4731 - accuracy: 0.4589 - val_loss: 1.6155 - val_accuracy: 0.4013\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3919 - accuracy: 0.4937 - val_loss: 1.3400 - val_accuracy: 0.5225\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3338 - accuracy: 0.5461 - val_loss: 1.3951 - val_accuracy: 0.5100\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.3067 - accuracy: 0.5430 - val_loss: 1.3508 - val_accuracy: 0.5163\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.2158 - accuracy: 0.5742 - val_loss: 1.3415 - val_accuracy: 0.4938\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1339 - accuracy: 0.6210 - val_loss: 1.3275 - val_accuracy: 0.5362\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 1.1068 - accuracy: 0.6224 - val_loss: 1.2889 - val_accuracy: 0.5437\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.1130 - accuracy: 0.6157 - val_loss: 1.2337 - val_accuracy: 0.5587\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 1.0386 - accuracy: 0.6429 - val_loss: 1.1753 - val_accuracy: 0.5838\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.9804 - accuracy: 0.6562 - val_loss: 1.2892 - val_accuracy: 0.5138\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9501 - accuracy: 0.6828 - val_loss: 1.4207 - val_accuracy: 0.4913\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.9257 - accuracy: 0.6941 - val_loss: 1.1480 - val_accuracy: 0.6087\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8655 - accuracy: 0.7133 - val_loss: 1.2037 - val_accuracy: 0.5725\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.8739 - accuracy: 0.7048 - val_loss: 1.1247 - val_accuracy: 0.5962\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7756 - accuracy: 0.7328 - val_loss: 1.1633 - val_accuracy: 0.5925\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7677 - accuracy: 0.7454 - val_loss: 1.1280 - val_accuracy: 0.5975\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.7284 - accuracy: 0.7637 - val_loss: 1.1777 - val_accuracy: 0.5838\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6892 - accuracy: 0.7645 - val_loss: 1.1883 - val_accuracy: 0.5612\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.7027 - accuracy: 0.7620 - val_loss: 1.1917 - val_accuracy: 0.6012\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6292 - accuracy: 0.7836 - val_loss: 1.1379 - val_accuracy: 0.6000\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6159 - accuracy: 0.7919 - val_loss: 1.0741 - val_accuracy: 0.6175\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.6040 - accuracy: 0.7908 - val_loss: 1.1853 - val_accuracy: 0.5938\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5597 - accuracy: 0.8052 - val_loss: 1.1839 - val_accuracy: 0.6062\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.5318 - accuracy: 0.8208 - val_loss: 1.1204 - val_accuracy: 0.6263\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.4866 - accuracy: 0.8496 - val_loss: 1.0690 - val_accuracy: 0.6388\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4781 - accuracy: 0.8522 - val_loss: 1.1274 - val_accuracy: 0.6125\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.4874 - accuracy: 0.8442 - val_loss: 1.1096 - val_accuracy: 0.6150\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4721 - accuracy: 0.8387 - val_loss: 1.1495 - val_accuracy: 0.6075\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4288 - accuracy: 0.8644 - val_loss: 1.0651 - val_accuracy: 0.6425\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4087 - accuracy: 0.8686 - val_loss: 1.2754 - val_accuracy: 0.5888\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3868 - accuracy: 0.8851 - val_loss: 1.1953 - val_accuracy: 0.6137\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3582 - accuracy: 0.9028 - val_loss: 1.1994 - val_accuracy: 0.6313\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3480 - accuracy: 0.8923 - val_loss: 1.0964 - val_accuracy: 0.6538\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3209 - accuracy: 0.8997 - val_loss: 1.0724 - val_accuracy: 0.6350\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.3308 - accuracy: 0.8998 - val_loss: 1.0339 - val_accuracy: 0.6475\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2719 - accuracy: 0.9243 - val_loss: 1.0694 - val_accuracy: 0.6438\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2710 - accuracy: 0.9182 - val_loss: 1.0869 - val_accuracy: 0.6463\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2685 - accuracy: 0.9183 - val_loss: 1.0541 - val_accuracy: 0.6562\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2561 - accuracy: 0.9235 - val_loss: 1.2263 - val_accuracy: 0.6175\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2275 - accuracy: 0.9306 - val_loss: 1.1377 - val_accuracy: 0.6425\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2571 - accuracy: 0.9236 - val_loss: 1.1200 - val_accuracy: 0.6587\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2161 - accuracy: 0.9417 - val_loss: 1.3111 - val_accuracy: 0.5725\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2333 - accuracy: 0.9364 - val_loss: 1.1327 - val_accuracy: 0.6525\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2879 - accuracy: 0.9103 - val_loss: 1.1344 - val_accuracy: 0.6363\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1891 - accuracy: 0.9513 - val_loss: 1.5556 - val_accuracy: 0.5587\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.2404 - accuracy: 0.9260 - val_loss: 1.1979 - val_accuracy: 0.6413\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1703 - accuracy: 0.9558 - val_loss: 1.1602 - val_accuracy: 0.6488\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1628 - accuracy: 0.9617 - val_loss: 1.1534 - val_accuracy: 0.6438\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1694 - accuracy: 0.9484 - val_loss: 1.2226 - val_accuracy: 0.6413\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1335 - accuracy: 0.9721 - val_loss: 1.2492 - val_accuracy: 0.6288\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1032 - accuracy: 0.9812 - val_loss: 1.1151 - val_accuracy: 0.6662\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0914 - accuracy: 0.9852 - val_loss: 1.3058 - val_accuracy: 0.6300\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1271 - accuracy: 0.9714 - val_loss: 1.4162 - val_accuracy: 0.5888\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1318 - accuracy: 0.9664 - val_loss: 1.1106 - val_accuracy: 0.6650\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0824 - accuracy: 0.9855 - val_loss: 1.2233 - val_accuracy: 0.6275\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0793 - accuracy: 0.9851 - val_loss: 1.1337 - val_accuracy: 0.6562\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0915 - accuracy: 0.9844 - val_loss: 1.3205 - val_accuracy: 0.6237\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0667 - accuracy: 0.9893 - val_loss: 2.0003 - val_accuracy: 0.5437\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.2913 - accuracy: 0.9202 - val_loss: 1.1435 - val_accuracy: 0.6575\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0863 - accuracy: 0.9773 - val_loss: 1.3348 - val_accuracy: 0.6388\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.1005 - accuracy: 0.9760 - val_loss: 1.1783 - val_accuracy: 0.6600\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0603 - accuracy: 0.9914 - val_loss: 1.1783 - val_accuracy: 0.6675\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0539 - accuracy: 0.9901 - val_loss: 1.1962 - val_accuracy: 0.6587\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0514 - accuracy: 0.9893 - val_loss: 1.8317 - val_accuracy: 0.5525\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.4680 - accuracy: 0.9058 - val_loss: 1.2406 - val_accuracy: 0.6600\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.1133 - accuracy: 0.9696 - val_loss: 1.2276 - val_accuracy: 0.6562\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0479 - accuracy: 0.9938 - val_loss: 1.2128 - val_accuracy: 0.6637\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0459 - accuracy: 0.9979 - val_loss: 1.2036 - val_accuracy: 0.6675\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0434 - accuracy: 0.9941 - val_loss: 1.2119 - val_accuracy: 0.6587\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0349 - accuracy: 0.9973 - val_loss: 1.2467 - val_accuracy: 0.6550\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0469 - accuracy: 0.9901 - val_loss: 1.5024 - val_accuracy: 0.6212\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0704 - accuracy: 0.9837 - val_loss: 1.2332 - val_accuracy: 0.6637\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0251 - accuracy: 0.9985 - val_loss: 1.2242 - val_accuracy: 0.6650\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0333 - accuracy: 0.9956 - val_loss: 1.2530 - val_accuracy: 0.6600\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 44ms/step - loss: 0.0278 - accuracy: 0.9958 - val_loss: 1.2635 - val_accuracy: 0.6612\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0281 - accuracy: 0.9981 - val_loss: 1.4707 - val_accuracy: 0.6350\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0488 - accuracy: 0.9911 - val_loss: 1.2583 - val_accuracy: 0.6687\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0263 - accuracy: 0.9983 - val_loss: 1.2711 - val_accuracy: 0.6675\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 43ms/step - loss: 0.0345 - accuracy: 0.9913 - val_loss: 1.2566 - val_accuracy: 0.6650\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 42ms/step - loss: 0.0208 - accuracy: 0.9986 - val_loss: 1.2513 - val_accuracy: 0.6725\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0179 - accuracy: 0.9988 - val_loss: 1.2856 - val_accuracy: 0.6737\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0255 - accuracy: 0.9959 - val_loss: 1.2875 - val_accuracy: 0.6600\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0259 - accuracy: 0.9968 - val_loss: 1.2866 - val_accuracy: 0.6550\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 4s 39ms/step - loss: 0.0159 - accuracy: 0.9994 - val_loss: 1.3984 - val_accuracy: 0.6425\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0438 - accuracy: 0.9926 - val_loss: 1.2768 - val_accuracy: 0.6525\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0244 - accuracy: 0.9992 - val_loss: 1.3217 - val_accuracy: 0.6488\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0188 - accuracy: 0.9993 - val_loss: 1.2465 - val_accuracy: 0.6700\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.0126 - accuracy: 0.9992 - val_loss: 1.2921 - val_accuracy: 0.6687\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0217 - accuracy: 0.9973 - val_loss: 1.3153 - val_accuracy: 0.6712\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0218 - accuracy: 0.9970 - val_loss: 1.2945 - val_accuracy: 0.6687\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0237 - accuracy: 0.9956 - val_loss: 1.3189 - val_accuracy: 0.6600\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0143 - accuracy: 0.9987 - val_loss: 1.3175 - val_accuracy: 0.6662\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0130 - accuracy: 0.9989 - val_loss: 1.3061 - val_accuracy: 0.6750\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0097 - accuracy: 0.9998 - val_loss: 1.3298 - val_accuracy: 0.6612\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0123 - accuracy: 0.9993 - val_loss: 1.3223 - val_accuracy: 0.6750\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0202 - accuracy: 0.9974 - val_loss: 1.3493 - val_accuracy: 0.6662\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 1.3351 - val_accuracy: 0.6562\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0099 - accuracy: 0.9994 - val_loss: 1.3853 - val_accuracy: 0.6550\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_42 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 2048)              25167872  \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 8)                 16392     \n",
      "=================================================================\n",
      "Total params: 25,184,264\n",
      "Trainable params: 25,184,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 2.6484 - accuracy: 0.2372 - val_loss: 1.6836 - val_accuracy: 0.3825\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.6522 - accuracy: 0.3867 - val_loss: 1.5290 - val_accuracy: 0.4563\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.4754 - accuracy: 0.4616 - val_loss: 1.4361 - val_accuracy: 0.5088\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.3755 - accuracy: 0.4997 - val_loss: 1.4223 - val_accuracy: 0.4875\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.3515 - accuracy: 0.5365 - val_loss: 1.4175 - val_accuracy: 0.4762\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.2773 - accuracy: 0.5493 - val_loss: 1.4095 - val_accuracy: 0.4737\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.2204 - accuracy: 0.5670 - val_loss: 1.3144 - val_accuracy: 0.5375\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.1841 - accuracy: 0.5842 - val_loss: 1.2722 - val_accuracy: 0.5663\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.1375 - accuracy: 0.5970 - val_loss: 1.2708 - val_accuracy: 0.5550\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.1272 - accuracy: 0.6133 - val_loss: 1.3460 - val_accuracy: 0.5175\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.0822 - accuracy: 0.6270 - val_loss: 1.2181 - val_accuracy: 0.5900\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.9764 - accuracy: 0.6730 - val_loss: 1.2286 - val_accuracy: 0.5700\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.9811 - accuracy: 0.6517 - val_loss: 1.1725 - val_accuracy: 0.5987\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.9934 - accuracy: 0.6759 - val_loss: 1.2355 - val_accuracy: 0.5525\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.9049 - accuracy: 0.6862 - val_loss: 1.2045 - val_accuracy: 0.5962\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.9191 - accuracy: 0.7000 - val_loss: 1.2404 - val_accuracy: 0.5600\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.8005 - accuracy: 0.7446 - val_loss: 1.1270 - val_accuracy: 0.6137\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.8098 - accuracy: 0.7197 - val_loss: 1.2083 - val_accuracy: 0.5900\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.8046 - accuracy: 0.7260 - val_loss: 1.1680 - val_accuracy: 0.6212\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.7786 - accuracy: 0.7432 - val_loss: 1.1747 - val_accuracy: 0.5675\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.7496 - accuracy: 0.7405 - val_loss: 1.1735 - val_accuracy: 0.5913\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.7015 - accuracy: 0.7712 - val_loss: 1.3118 - val_accuracy: 0.5412\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.7142 - accuracy: 0.7578 - val_loss: 1.0949 - val_accuracy: 0.6288\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.6628 - accuracy: 0.7754 - val_loss: 1.1065 - val_accuracy: 0.6237\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.6511 - accuracy: 0.7922 - val_loss: 1.1534 - val_accuracy: 0.5925\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.6299 - accuracy: 0.8017 - val_loss: 1.1620 - val_accuracy: 0.6037\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5908 - accuracy: 0.8076 - val_loss: 1.2198 - val_accuracy: 0.5788\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.6270 - accuracy: 0.7958 - val_loss: 1.1693 - val_accuracy: 0.5938\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5642 - accuracy: 0.8135 - val_loss: 1.1431 - val_accuracy: 0.6200\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5704 - accuracy: 0.8063 - val_loss: 1.0493 - val_accuracy: 0.6300\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.5237 - accuracy: 0.8285 - val_loss: 1.1541 - val_accuracy: 0.5913\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5207 - accuracy: 0.8438 - val_loss: 1.1117 - val_accuracy: 0.6500\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 0.5045 - accuracy: 0.8467 - val_loss: 1.2402 - val_accuracy: 0.5863\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4554 - accuracy: 0.8644 - val_loss: 1.1951 - val_accuracy: 0.5775\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4114 - accuracy: 0.8843 - val_loss: 1.1785 - val_accuracy: 0.6025\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4388 - accuracy: 0.8580 - val_loss: 1.6786 - val_accuracy: 0.4875\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4546 - accuracy: 0.8630 - val_loss: 1.0760 - val_accuracy: 0.6225\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.4501 - accuracy: 0.8582 - val_loss: 1.2088 - val_accuracy: 0.6087\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3907 - accuracy: 0.8837 - val_loss: 1.3830 - val_accuracy: 0.5625\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3811 - accuracy: 0.8878 - val_loss: 1.1729 - val_accuracy: 0.6162\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3985 - accuracy: 0.8714 - val_loss: 1.0612 - val_accuracy: 0.6587\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3591 - accuracy: 0.8936 - val_loss: 1.1056 - val_accuracy: 0.6350\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3400 - accuracy: 0.8924 - val_loss: 1.1293 - val_accuracy: 0.6212\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3091 - accuracy: 0.9060 - val_loss: 1.1260 - val_accuracy: 0.6363\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.2921 - accuracy: 0.9183 - val_loss: 1.2284 - val_accuracy: 0.6263\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3136 - accuracy: 0.8974 - val_loss: 1.1024 - val_accuracy: 0.6525\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3087 - accuracy: 0.9168 - val_loss: 1.0459 - val_accuracy: 0.6625\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2849 - accuracy: 0.9258 - val_loss: 1.1728 - val_accuracy: 0.6313\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.2235 - accuracy: 0.9465 - val_loss: 1.1730 - val_accuracy: 0.6275\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2330 - accuracy: 0.9396 - val_loss: 1.1675 - val_accuracy: 0.6250\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3023 - accuracy: 0.9158 - val_loss: 1.1379 - val_accuracy: 0.6488\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2461 - accuracy: 0.9320 - val_loss: 1.1950 - val_accuracy: 0.6313\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2415 - accuracy: 0.9395 - val_loss: 1.0906 - val_accuracy: 0.6550\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1949 - accuracy: 0.9549 - val_loss: 1.1509 - val_accuracy: 0.6350\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2048 - accuracy: 0.9486 - val_loss: 1.1081 - val_accuracy: 0.6712\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1586 - accuracy: 0.9663 - val_loss: 1.3061 - val_accuracy: 0.5938\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1773 - accuracy: 0.9567 - val_loss: 1.0825 - val_accuracy: 0.6550\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1832 - accuracy: 0.9525 - val_loss: 1.1806 - val_accuracy: 0.6250\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1508 - accuracy: 0.9714 - val_loss: 1.2571 - val_accuracy: 0.5987\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1580 - accuracy: 0.9672 - val_loss: 1.3617 - val_accuracy: 0.6212\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1614 - accuracy: 0.9622 - val_loss: 1.1068 - val_accuracy: 0.6662\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1464 - accuracy: 0.9687 - val_loss: 1.1370 - val_accuracy: 0.6400\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1566 - accuracy: 0.9670 - val_loss: 1.1043 - val_accuracy: 0.6675\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1329 - accuracy: 0.9758 - val_loss: 1.1214 - val_accuracy: 0.6513\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1276 - accuracy: 0.9737 - val_loss: 1.1872 - val_accuracy: 0.6275\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1164 - accuracy: 0.9743 - val_loss: 1.1867 - val_accuracy: 0.6488\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1157 - accuracy: 0.9775 - val_loss: 1.0867 - val_accuracy: 0.6700\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.1051 - accuracy: 0.9826 - val_loss: 1.1765 - val_accuracy: 0.6413\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.1100 - accuracy: 0.9813 - val_loss: 1.2109 - val_accuracy: 0.6513\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0909 - accuracy: 0.9889 - val_loss: 1.1834 - val_accuracy: 0.6400\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0950 - accuracy: 0.9801 - val_loss: 1.1655 - val_accuracy: 0.6500\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0850 - accuracy: 0.9897 - val_loss: 1.1688 - val_accuracy: 0.6650\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0811 - accuracy: 0.9907 - val_loss: 1.3351 - val_accuracy: 0.6325\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0912 - accuracy: 0.9835 - val_loss: 1.2183 - val_accuracy: 0.6375\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0908 - accuracy: 0.9867 - val_loss: 1.1189 - val_accuracy: 0.6725\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0738 - accuracy: 0.9904 - val_loss: 1.1809 - val_accuracy: 0.6475\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0808 - accuracy: 0.9862 - val_loss: 1.2426 - val_accuracy: 0.6363\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0833 - accuracy: 0.9856 - val_loss: 1.1995 - val_accuracy: 0.6538\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0904 - accuracy: 0.9795 - val_loss: 1.1967 - val_accuracy: 0.6450\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0564 - accuracy: 0.9966 - val_loss: 1.1693 - val_accuracy: 0.6587\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0706 - accuracy: 0.9913 - val_loss: 1.2103 - val_accuracy: 0.6500\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0692 - accuracy: 0.9861 - val_loss: 1.1613 - val_accuracy: 0.6612\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0567 - accuracy: 0.9942 - val_loss: 1.1720 - val_accuracy: 0.6700\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0526 - accuracy: 0.9956 - val_loss: 1.1889 - val_accuracy: 0.6637\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.0584 - accuracy: 0.9932 - val_loss: 1.1946 - val_accuracy: 0.6525\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0527 - accuracy: 0.9960 - val_loss: 1.2047 - val_accuracy: 0.6562\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0855 - accuracy: 0.9796 - val_loss: 1.1979 - val_accuracy: 0.6612\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0487 - accuracy: 0.9960 - val_loss: 1.3498 - val_accuracy: 0.6325\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0542 - accuracy: 0.9921 - val_loss: 1.1693 - val_accuracy: 0.6712\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0449 - accuracy: 0.9962 - val_loss: 1.1856 - val_accuracy: 0.6450\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0431 - accuracy: 0.9955 - val_loss: 1.2098 - val_accuracy: 0.6637\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0609 - accuracy: 0.9927 - val_loss: 1.1914 - val_accuracy: 0.6488\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0459 - accuracy: 0.9946 - val_loss: 1.2019 - val_accuracy: 0.6637\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0359 - accuracy: 0.9985 - val_loss: 1.2089 - val_accuracy: 0.6587\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0412 - accuracy: 0.9939 - val_loss: 1.3182 - val_accuracy: 0.6338\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1832 - accuracy: 0.9489 - val_loss: 1.2116 - val_accuracy: 0.6575\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0410 - accuracy: 0.9972 - val_loss: 1.2192 - val_accuracy: 0.6637\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0415 - accuracy: 0.9916 - val_loss: 1.2127 - val_accuracy: 0.6575\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0380 - accuracy: 0.9960 - val_loss: 1.2628 - val_accuracy: 0.6475\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0314 - accuracy: 0.9977 - val_loss: 1.2543 - val_accuracy: 0.6550\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_43 (Reshape)         (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense0 (Dense)               (None, 3072)              37751808  \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 8)                 24584     \n",
      "=================================================================\n",
      "Total params: 37,776,392\n",
      "Trainable params: 37,776,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done\n",
      "\n",
      "Loading Data...\n",
      "train_generator\n",
      "Found 1881 images belonging to 8 classes.\n",
      "validation_generator\n",
      "Found 807 images belonging to 8 classes.\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 2.5451 - accuracy: 0.2490 - val_loss: 1.8504 - val_accuracy: 0.2700\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.6307 - accuracy: 0.3921 - val_loss: 1.4983 - val_accuracy: 0.4725\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.4301 - accuracy: 0.4795 - val_loss: 1.5752 - val_accuracy: 0.4112\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.4029 - accuracy: 0.4968 - val_loss: 1.4051 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.2657 - accuracy: 0.5653 - val_loss: 1.4116 - val_accuracy: 0.4725\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.2077 - accuracy: 0.5762 - val_loss: 1.2719 - val_accuracy: 0.5600\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.2137 - accuracy: 0.5664 - val_loss: 1.3023 - val_accuracy: 0.5100\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.1077 - accuracy: 0.6201 - val_loss: 1.2897 - val_accuracy: 0.5275\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 1.1161 - accuracy: 0.6096 - val_loss: 1.2018 - val_accuracy: 0.5900\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 1.0853 - accuracy: 0.6383 - val_loss: 1.3078 - val_accuracy: 0.5188\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.9763 - accuracy: 0.6580 - val_loss: 1.3561 - val_accuracy: 0.5013\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 5s 41ms/step - loss: 1.0169 - accuracy: 0.6532 - val_loss: 1.2524 - val_accuracy: 0.5625\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.9868 - accuracy: 0.6456 - val_loss: 1.1956 - val_accuracy: 0.5863\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.9265 - accuracy: 0.6880 - val_loss: 1.2660 - val_accuracy: 0.5500\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.8427 - accuracy: 0.7263 - val_loss: 1.1813 - val_accuracy: 0.5763\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.8071 - accuracy: 0.7351 - val_loss: 1.1693 - val_accuracy: 0.5825\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.7726 - accuracy: 0.7401 - val_loss: 1.1834 - val_accuracy: 0.5975\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.7984 - accuracy: 0.7304 - val_loss: 1.1454 - val_accuracy: 0.6075\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.7895 - accuracy: 0.7457 - val_loss: 1.1116 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.7167 - accuracy: 0.7786 - val_loss: 1.2621 - val_accuracy: 0.5350\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.7175 - accuracy: 0.7613 - val_loss: 1.2185 - val_accuracy: 0.5725\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.6816 - accuracy: 0.7742 - val_loss: 1.1866 - val_accuracy: 0.5900\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.6986 - accuracy: 0.7689 - val_loss: 1.1572 - val_accuracy: 0.6025\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.6797 - accuracy: 0.7678 - val_loss: 1.1581 - val_accuracy: 0.6037\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5933 - accuracy: 0.8053 - val_loss: 1.1486 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5920 - accuracy: 0.8130 - val_loss: 1.1042 - val_accuracy: 0.6125\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5646 - accuracy: 0.8147 - val_loss: 1.0800 - val_accuracy: 0.6488\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.5227 - accuracy: 0.8464 - val_loss: 1.0900 - val_accuracy: 0.6187\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5283 - accuracy: 0.8298 - val_loss: 1.2381 - val_accuracy: 0.5962\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.5051 - accuracy: 0.8429 - val_loss: 1.1702 - val_accuracy: 0.5938\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4632 - accuracy: 0.8705 - val_loss: 1.1507 - val_accuracy: 0.6087\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4914 - accuracy: 0.8473 - val_loss: 1.1656 - val_accuracy: 0.5925\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4812 - accuracy: 0.8531 - val_loss: 1.0248 - val_accuracy: 0.6587\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4110 - accuracy: 0.8836 - val_loss: 1.1666 - val_accuracy: 0.6112\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.4038 - accuracy: 0.8832 - val_loss: 1.0913 - val_accuracy: 0.6212\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.4340 - accuracy: 0.8523 - val_loss: 1.2340 - val_accuracy: 0.5838\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3902 - accuracy: 0.8830 - val_loss: 1.1222 - val_accuracy: 0.6388\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3900 - accuracy: 0.8858 - val_loss: 1.0340 - val_accuracy: 0.6712\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3294 - accuracy: 0.9089 - val_loss: 1.0617 - val_accuracy: 0.6587\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3644 - accuracy: 0.8887 - val_loss: 1.1043 - val_accuracy: 0.6363\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3147 - accuracy: 0.9184 - val_loss: 1.1793 - val_accuracy: 0.6125\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3397 - accuracy: 0.9055 - val_loss: 1.0889 - val_accuracy: 0.6263\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2702 - accuracy: 0.9304 - val_loss: 1.1328 - val_accuracy: 0.6175\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2836 - accuracy: 0.9248 - val_loss: 1.0268 - val_accuracy: 0.6587\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2753 - accuracy: 0.9345 - val_loss: 1.0297 - val_accuracy: 0.6675\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2467 - accuracy: 0.9414 - val_loss: 1.5301 - val_accuracy: 0.6037\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.2809 - accuracy: 0.9162 - val_loss: 1.0903 - val_accuracy: 0.6338\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1946 - accuracy: 0.9561 - val_loss: 1.2110 - val_accuracy: 0.6075\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.2187 - accuracy: 0.9411 - val_loss: 1.1908 - val_accuracy: 0.6288\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2063 - accuracy: 0.9466 - val_loss: 1.1299 - val_accuracy: 0.6550\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2031 - accuracy: 0.9477 - val_loss: 1.0893 - val_accuracy: 0.6450\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1748 - accuracy: 0.9638 - val_loss: 1.0711 - val_accuracy: 0.6650\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.1622 - accuracy: 0.9682 - val_loss: 1.1512 - val_accuracy: 0.6263\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1785 - accuracy: 0.9567 - val_loss: 1.2752 - val_accuracy: 0.6112\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1678 - accuracy: 0.9615 - val_loss: 1.1761 - val_accuracy: 0.6350\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1856 - accuracy: 0.9531 - val_loss: 1.1301 - val_accuracy: 0.6475\n",
      "Epoch 57/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1591 - accuracy: 0.9650 - val_loss: 1.1171 - val_accuracy: 0.6438\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1601 - accuracy: 0.9661 - val_loss: 1.0784 - val_accuracy: 0.6513\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1614 - accuracy: 0.9620 - val_loss: 1.1358 - val_accuracy: 0.6637\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1317 - accuracy: 0.9731 - val_loss: 2.1190 - val_accuracy: 0.4913\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.3412 - accuracy: 0.9088 - val_loss: 1.8142 - val_accuracy: 0.5600\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1816 - accuracy: 0.9514 - val_loss: 1.1057 - val_accuracy: 0.6725\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1036 - accuracy: 0.9858 - val_loss: 1.1766 - val_accuracy: 0.6300\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1416 - accuracy: 0.9652 - val_loss: 1.1343 - val_accuracy: 0.6488\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1052 - accuracy: 0.9888 - val_loss: 1.0900 - val_accuracy: 0.6637\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1154 - accuracy: 0.9785 - val_loss: 1.0969 - val_accuracy: 0.6775\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0955 - accuracy: 0.9841 - val_loss: 1.1073 - val_accuracy: 0.6725\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0928 - accuracy: 0.9831 - val_loss: 1.1065 - val_accuracy: 0.6587\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0911 - accuracy: 0.9866 - val_loss: 1.1430 - val_accuracy: 0.6687\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0862 - accuracy: 0.9814 - val_loss: 1.1267 - val_accuracy: 0.6687\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0861 - accuracy: 0.9853 - val_loss: 1.1099 - val_accuracy: 0.6687\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0750 - accuracy: 0.9917 - val_loss: 1.1461 - val_accuracy: 0.6550\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0825 - accuracy: 0.9842 - val_loss: 1.1820 - val_accuracy: 0.6463\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.1037 - accuracy: 0.9768 - val_loss: 1.0719 - val_accuracy: 0.6712\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0708 - accuracy: 0.9905 - val_loss: 1.1021 - val_accuracy: 0.6775\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0851 - accuracy: 0.9842 - val_loss: 1.1625 - val_accuracy: 0.6662\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0629 - accuracy: 0.9950 - val_loss: 1.1396 - val_accuracy: 0.6700\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.1282 - accuracy: 0.9639 - val_loss: 1.1591 - val_accuracy: 0.6650\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0606 - accuracy: 0.9917 - val_loss: 1.1569 - val_accuracy: 0.6675\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0521 - accuracy: 0.9939 - val_loss: 1.2017 - val_accuracy: 0.6388\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0588 - accuracy: 0.9905 - val_loss: 1.1879 - val_accuracy: 0.6538\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0458 - accuracy: 0.9972 - val_loss: 1.1534 - val_accuracy: 0.6625\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0569 - accuracy: 0.9930 - val_loss: 1.1574 - val_accuracy: 0.6625\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0480 - accuracy: 0.9956 - val_loss: 1.1562 - val_accuracy: 0.6637\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0441 - accuracy: 0.9979 - val_loss: 1.1743 - val_accuracy: 0.6550\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0645 - accuracy: 0.9882 - val_loss: 1.1707 - val_accuracy: 0.6625\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0450 - accuracy: 0.9964 - val_loss: 1.2558 - val_accuracy: 0.6525\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0504 - accuracy: 0.9933 - val_loss: 1.1722 - val_accuracy: 0.6575\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0378 - accuracy: 0.9975 - val_loss: 1.1682 - val_accuracy: 0.6625\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0352 - accuracy: 0.9992 - val_loss: 1.1605 - val_accuracy: 0.6712\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0410 - accuracy: 0.9968 - val_loss: 1.1991 - val_accuracy: 0.6600\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0446 - accuracy: 0.9954 - val_loss: 1.2525 - val_accuracy: 0.6350\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0387 - accuracy: 0.9976 - val_loss: 1.1886 - val_accuracy: 0.6587\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.0362 - accuracy: 0.9968 - val_loss: 1.1808 - val_accuracy: 0.6725\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0366 - accuracy: 0.9981 - val_loss: 1.1999 - val_accuracy: 0.6637\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0320 - accuracy: 0.9992 - val_loss: 1.1841 - val_accuracy: 0.6687\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0350 - accuracy: 0.9965 - val_loss: 1.1963 - val_accuracy: 0.6637\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.0327 - accuracy: 0.9980 - val_loss: 1.1744 - val_accuracy: 0.6762\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0360 - accuracy: 0.9970 - val_loss: 1.1803 - val_accuracy: 0.6700\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.0316 - accuracy: 0.9977 - val_loss: 1.1830 - val_accuracy: 0.6700\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -- CONSTANTS -- #\n",
    "EPOCHS = 100\n",
    "PATCH_SIZE  = 64\n",
    "PATCHES_DIR = path1\n",
    "SAVEPATH = os.getcwd() + '/' + 'Week3'\n",
    "\n",
    "\n",
    "\n",
    "#os.makedirs(SAVEPATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.isdir(SAVEPATH):\n",
    "        os.mkdir(SAVEPATH)\n",
    "    # -- DEFINE MODEL COMBINATIONS -- #\n",
    "    model_comps = [\n",
    "        {'layers':[{'units':2048,'activation':'relu'},{'units':1024,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':3072,'activation':'relu'},{'units':768,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':2048,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':3072,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':2048,'activation':'relu'},{'units':1024,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':3072,'activation':'relu'},{'units':768,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':2048,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':3072,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':2048,'activation':'relu'},{'units':1024,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':3072,'activation':'relu'},{'units':768,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':2048,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "        {'layers':[{'units':3072,'activation':'relu'}],'img_size':PATCH_SIZE,'batch_size':16},\n",
    "    ]\n",
    "    \n",
    "    for ind, config_dict in enumerate(model_comps):\n",
    "        # -- DEFINE CONSTANTS -- #\n",
    "        MODEL_NAME = 'model'+str(ind)\n",
    "        MODEL_FNAME = SAVEPATH+'/'+MODEL_NAME+'.h5'\n",
    "        BATCH_SIZE = config_dict['batch_size']\n",
    "\n",
    "        # -- CREATE MODEL -- #\n",
    "        mlp_patches = Model_MLPatches(config_dict, phase='train', trained=False)\n",
    "        mlp_patches.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='sgd',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(mlp_patches.model.summary())\n",
    "        plot_model(mlp_patches.model, to_file=SAVEPATH+'/'+MODEL_NAME+'_structure.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "        print('Done\\n')\n",
    "\n",
    "        print('Loading Data...')\n",
    "        train_datagen = ImageDataGenerator(\n",
    "          rescale=1./255,\n",
    "          horizontal_flip=True)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        print('train_generator')\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            PATCHES_DIR+'/train',  # this is the target directory\n",
    "            target_size=(PATCH_SIZE, PATCH_SIZE),  # all images will be resized to PATCH_SIZExPATCH_SIZE\n",
    "            batch_size=BATCH_SIZE,\n",
    "            classes = ['coast','forest','highway','inside_city','mountain','Opencountry','street','tallbuilding'],\n",
    "            class_mode='categorical')  # since we use binary_crossentropy loss, we need categorical labels\n",
    "\n",
    "        print('validation_generator')\n",
    "        validation_generator = test_datagen.flow_from_directory(\n",
    "            PATCHES_DIR+'/test',\n",
    "            target_size=(PATCH_SIZE, PATCH_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            classes = ['coast','forest','highway','inside_city','mountain','Opencountry','street','tallbuilding'],\n",
    "            class_mode='categorical')\n",
    "  \n",
    "        history = mlp_patches.model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=(1881) // BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=(807) // BATCH_SIZE)\n",
    "\n",
    "        mlp_patches.model.save_weights(MODEL_FNAME)  # always save your weights after training or during training\n",
    "\n",
    "        \n",
    "        # summarize history for accuracy\n",
    "        '''\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.savefig(SAVEPATH+'/'+MODEL_NAME+'_accuracy.png')\n",
    "        plt.close()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.savefig(SAVEPATH+'/'+MODEL_NAME+'_loss.png')\n",
    "        plt.close()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-60Cdb-ewSZY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUfRHx487GFn",
    "outputId": "162a84e2-572b-4da4-ecdf-31e464024b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model\n",
      "/content/model0.h5\n",
      "Loaded\n",
      "Loading train data...\n",
      "Loaded.\n",
      "Predicting train data...\n",
      "Image [0] Predicted.\n",
      "Image [1] Predicted.\n",
      "Image [2] Predicted.\n",
      "Image [3] Predicted.\n",
      "Image [4] Predicted.\n",
      "Image [5] Predicted.\n",
      "Image [6] Predicted.\n",
      "Image [7] Predicted.\n",
      "Image [8] Predicted.\n",
      "Image [9] Predicted.\n",
      "Image [10] Predicted.\n",
      "Image [11] Predicted.\n",
      "Image [12] Predicted.\n",
      "Image [13] Predicted.\n",
      "Image [14] Predicted.\n",
      "Image [15] Predicted.\n",
      "Image [16] Predicted.\n",
      "Image [17] Predicted.\n",
      "Image [18] Predicted.\n",
      "Image [19] Predicted.\n",
      "Image [20] Predicted.\n",
      "Image [21] Predicted.\n",
      "Image [22] Predicted.\n",
      "Image [23] Predicted.\n",
      "Image [24] Predicted.\n",
      "Image [25] Predicted.\n",
      "Image [26] Predicted.\n",
      "Image [27] Predicted.\n",
      "Image [28] Predicted.\n",
      "Image [29] Predicted.\n",
      "Image [30] Predicted.\n",
      "Image [31] Predicted.\n",
      "Image [32] Predicted.\n",
      "Image [33] Predicted.\n",
      "Image [34] Predicted.\n",
      "Image [35] Predicted.\n",
      "Image [36] Predicted.\n",
      "Image [37] Predicted.\n",
      "Image [38] Predicted.\n",
      "Image [39] Predicted.\n",
      "Image [40] Predicted.\n",
      "Image [41] Predicted.\n",
      "Image [42] Predicted.\n",
      "Image [43] Predicted.\n",
      "Image [44] Predicted.\n",
      "Image [45] Predicted.\n",
      "Image [46] Predicted.\n",
      "Image [47] Predicted.\n",
      "Image [48] Predicted.\n",
      "Image [49] Predicted.\n",
      "Image [50] Predicted.\n",
      "Image [51] Predicted.\n",
      "Image [52] Predicted.\n",
      "Image [53] Predicted.\n",
      "Image [54] Predicted.\n",
      "Image [55] Predicted.\n",
      "Image [56] Predicted.\n",
      "Image [57] Predicted.\n",
      "Image [58] Predicted.\n",
      "Image [59] Predicted.\n",
      "Image [60] Predicted.\n",
      "Image [61] Predicted.\n",
      "Image [62] Predicted.\n",
      "Image [63] Predicted.\n",
      "Image [64] Predicted.\n",
      "Image [65] Predicted.\n",
      "Image [66] Predicted.\n",
      "Image [67] Predicted.\n",
      "Image [68] Predicted.\n",
      "Image [69] Predicted.\n",
      "Image [70] Predicted.\n",
      "Image [71] Predicted.\n",
      "Image [72] Predicted.\n",
      "Image [73] Predicted.\n",
      "Image [74] Predicted.\n",
      "Image [75] Predicted.\n",
      "Image [76] Predicted.\n",
      "Image [77] Predicted.\n",
      "Image [78] Predicted.\n",
      "Image [79] Predicted.\n",
      "Image [80] Predicted.\n",
      "Image [81] Predicted.\n",
      "Image [82] Predicted.\n",
      "Image [83] Predicted.\n",
      "Image [84] Predicted.\n",
      "Image [85] Predicted.\n",
      "Image [86] Predicted.\n",
      "Image [87] Predicted.\n",
      "Image [88] Predicted.\n",
      "Image [89] Predicted.\n",
      "Image [90] Predicted.\n",
      "Image [91] Predicted.\n",
      "Image [92] Predicted.\n",
      "Image [93] Predicted.\n",
      "Image [94] Predicted.\n",
      "Image [95] Predicted.\n",
      "Image [96] Predicted.\n",
      "Image [97] Predicted.\n",
      "Image [98] Predicted.\n",
      "Image [99] Predicted.\n",
      "Image [100] Predicted.\n",
      "Image [101] Predicted.\n",
      "Image [102] Predicted.\n",
      "Image [103] Predicted.\n",
      "Image [104] Predicted.\n",
      "Image [105] Predicted.\n",
      "Image [106] Predicted.\n",
      "Image [107] Predicted.\n",
      "Image [108] Predicted.\n",
      "Image [109] Predicted.\n",
      "Image [110] Predicted.\n",
      "Image [111] Predicted.\n",
      "Image [112] Predicted.\n",
      "Image [113] Predicted.\n",
      "Image [114] Predicted.\n",
      "Image [115] Predicted.\n",
      "Image [116] Predicted.\n",
      "Image [117] Predicted.\n",
      "Image [118] Predicted.\n",
      "Image [119] Predicted.\n",
      "Image [120] Predicted.\n",
      "Image [121] Predicted.\n",
      "Image [122] Predicted.\n",
      "Image [123] Predicted.\n",
      "Image [124] Predicted.\n",
      "Image [125] Predicted.\n",
      "Image [126] Predicted.\n",
      "Image [127] Predicted.\n",
      "Image [128] Predicted.\n",
      "Image [129] Predicted.\n",
      "Image [130] Predicted.\n",
      "Image [131] Predicted.\n",
      "Image [132] Predicted.\n",
      "Image [133] Predicted.\n",
      "Image [134] Predicted.\n",
      "Image [135] Predicted.\n",
      "Image [136] Predicted.\n",
      "Image [137] Predicted.\n",
      "Image [138] Predicted.\n",
      "Image [139] Predicted.\n",
      "Image [140] Predicted.\n",
      "Image [141] Predicted.\n",
      "Image [142] Predicted.\n",
      "Image [143] Predicted.\n",
      "Image [144] Predicted.\n",
      "Image [145] Predicted.\n",
      "Image [146] Predicted.\n",
      "Image [147] Predicted.\n",
      "Image [148] Predicted.\n",
      "Image [149] Predicted.\n",
      "Image [150] Predicted.\n",
      "Image [151] Predicted.\n",
      "Image [152] Predicted.\n",
      "Image [153] Predicted.\n",
      "Image [154] Predicted.\n",
      "Image [155] Predicted.\n",
      "Image [156] Predicted.\n",
      "Image [157] Predicted.\n",
      "Image [158] Predicted.\n",
      "Image [159] Predicted.\n",
      "Image [160] Predicted.\n",
      "Image [161] Predicted.\n",
      "Image [162] Predicted.\n",
      "Image [163] Predicted.\n",
      "Image [164] Predicted.\n",
      "Image [165] Predicted.\n",
      "Image [166] Predicted.\n",
      "Image [167] Predicted.\n",
      "Image [168] Predicted.\n",
      "Image [169] Predicted.\n",
      "Image [170] Predicted.\n",
      "Image [171] Predicted.\n",
      "Image [172] Predicted.\n",
      "Image [173] Predicted.\n",
      "Image [174] Predicted.\n",
      "Image [175] Predicted.\n",
      "Image [176] Predicted.\n",
      "Image [177] Predicted.\n",
      "Image [178] Predicted.\n",
      "Image [179] Predicted.\n",
      "Image [180] Predicted.\n",
      "Image [181] Predicted.\n",
      "Image [182] Predicted.\n",
      "Image [183] Predicted.\n",
      "Image [184] Predicted.\n",
      "Image [185] Predicted.\n",
      "Image [186] Predicted.\n",
      "Image [187] Predicted.\n",
      "Image [188] Predicted.\n",
      "Image [189] Predicted.\n",
      "Image [190] Predicted.\n",
      "Image [191] Predicted.\n",
      "Image [192] Predicted.\n",
      "Image [193] Predicted.\n",
      "Image [194] Predicted.\n",
      "Image [195] Predicted.\n",
      "Image [196] Predicted.\n",
      "Image [197] Predicted.\n",
      "Image [198] Predicted.\n",
      "Image [199] Predicted.\n",
      "Image [200] Predicted.\n",
      "Image [201] Predicted.\n",
      "Image [202] Predicted.\n",
      "Image [203] Predicted.\n",
      "Image [204] Predicted.\n",
      "Image [205] Predicted.\n",
      "Image [206] Predicted.\n",
      "Image [207] Predicted.\n",
      "Image [208] Predicted.\n",
      "Image [209] Predicted.\n",
      "Image [210] Predicted.\n",
      "Image [211] Predicted.\n",
      "Image [212] Predicted.\n",
      "Image [213] Predicted.\n",
      "Image [214] Predicted.\n",
      "Image [215] Predicted.\n",
      "Image [216] Predicted.\n",
      "Image [217] Predicted.\n",
      "Image [218] Predicted.\n",
      "Image [219] Predicted.\n",
      "Image [220] Predicted.\n",
      "Image [221] Predicted.\n",
      "Image [222] Predicted.\n",
      "Image [223] Predicted.\n",
      "Image [224] Predicted.\n",
      "Image [225] Predicted.\n",
      "Image [226] Predicted.\n",
      "Image [227] Predicted.\n",
      "Image [228] Predicted.\n",
      "Image [229] Predicted.\n",
      "Image [230] Predicted.\n",
      "Image [231] Predicted.\n",
      "Image [232] Predicted.\n",
      "Image [233] Predicted.\n",
      "Image [234] Predicted.\n",
      "Image [235] Predicted.\n",
      "Image [236] Predicted.\n",
      "Image [237] Predicted.\n",
      "Image [238] Predicted.\n",
      "Image [239] Predicted.\n",
      "Image [240] Predicted.\n",
      "Image [241] Predicted.\n",
      "Image [242] Predicted.\n",
      "Image [243] Predicted.\n",
      "Image [244] Predicted.\n",
      "Image [245] Predicted.\n",
      "Image [246] Predicted.\n",
      "Image [247] Predicted.\n",
      "Image [248] Predicted.\n",
      "Image [249] Predicted.\n",
      "Image [250] Predicted.\n",
      "Image [251] Predicted.\n",
      "Image [252] Predicted.\n",
      "Image [253] Predicted.\n",
      "Image [254] Predicted.\n",
      "Image [255] Predicted.\n",
      "Image [256] Predicted.\n",
      "Image [257] Predicted.\n",
      "Image [258] Predicted.\n",
      "Image [259] Predicted.\n",
      "Image [260] Predicted.\n",
      "Image [261] Predicted.\n",
      "Image [262] Predicted.\n",
      "Image [263] Predicted.\n",
      "Image [264] Predicted.\n",
      "Image [265] Predicted.\n",
      "Image [266] Predicted.\n",
      "Image [267] Predicted.\n",
      "Image [268] Predicted.\n",
      "Image [269] Predicted.\n",
      "Image [270] Predicted.\n",
      "Image [271] Predicted.\n",
      "Image [272] Predicted.\n",
      "Image [273] Predicted.\n",
      "Image [274] Predicted.\n",
      "Image [275] Predicted.\n",
      "Image [276] Predicted.\n",
      "Image [277] Predicted.\n",
      "Image [278] Predicted.\n",
      "Image [279] Predicted.\n",
      "Image [280] Predicted.\n",
      "Image [281] Predicted.\n",
      "Image [282] Predicted.\n",
      "Image [283] Predicted.\n",
      "Image [284] Predicted.\n",
      "Image [285] Predicted.\n",
      "Image [286] Predicted.\n",
      "Image [287] Predicted.\n",
      "Image [288] Predicted.\n",
      "Image [289] Predicted.\n",
      "Image [290] Predicted.\n",
      "Image [291] Predicted.\n",
      "Image [292] Predicted.\n",
      "Image [293] Predicted.\n",
      "Image [294] Predicted.\n",
      "Image [295] Predicted.\n",
      "Image [296] Predicted.\n",
      "Image [297] Predicted.\n",
      "Image [298] Predicted.\n",
      "Image [299] Predicted.\n",
      "Image [300] Predicted.\n",
      "Image [301] Predicted.\n",
      "Image [302] Predicted.\n",
      "Image [303] Predicted.\n",
      "Image [304] Predicted.\n",
      "Image [305] Predicted.\n",
      "Image [306] Predicted.\n",
      "Image [307] Predicted.\n",
      "Image [308] Predicted.\n",
      "Image [309] Predicted.\n",
      "Image [310] Predicted.\n",
      "Image [311] Predicted.\n",
      "Image [312] Predicted.\n",
      "Image [313] Predicted.\n",
      "Image [314] Predicted.\n",
      "Image [315] Predicted.\n",
      "Image [316] Predicted.\n",
      "Image [317] Predicted.\n",
      "Image [318] Predicted.\n",
      "Image [319] Predicted.\n",
      "Image [320] Predicted.\n",
      "Image [321] Predicted.\n",
      "Image [322] Predicted.\n",
      "Image [323] Predicted.\n",
      "Image [324] Predicted.\n",
      "Image [325] Predicted.\n",
      "Image [326] Predicted.\n",
      "Image [327] Predicted.\n",
      "Image [328] Predicted.\n",
      "Image [329] Predicted.\n",
      "Image [330] Predicted.\n",
      "Image [331] Predicted.\n",
      "Image [332] Predicted.\n",
      "Image [333] Predicted.\n",
      "Image [334] Predicted.\n",
      "Image [335] Predicted.\n",
      "Image [336] Predicted.\n",
      "Image [337] Predicted.\n",
      "Image [338] Predicted.\n",
      "Image [339] Predicted.\n",
      "Image [340] Predicted.\n",
      "Image [341] Predicted.\n",
      "Image [342] Predicted.\n",
      "Image [343] Predicted.\n",
      "Image [344] Predicted.\n",
      "Image [345] Predicted.\n",
      "Image [346] Predicted.\n",
      "Image [347] Predicted.\n",
      "Image [348] Predicted.\n",
      "Image [349] Predicted.\n",
      "Image [350] Predicted.\n",
      "Image [351] Predicted.\n",
      "Image [352] Predicted.\n",
      "Image [353] Predicted.\n",
      "Image [354] Predicted.\n",
      "Image [355] Predicted.\n",
      "Image [356] Predicted.\n",
      "Image [357] Predicted.\n",
      "Image [358] Predicted.\n",
      "Image [359] Predicted.\n",
      "Image [360] Predicted.\n",
      "Image [361] Predicted.\n",
      "Image [362] Predicted.\n",
      "Image [363] Predicted.\n",
      "Image [364] Predicted.\n",
      "Image [365] Predicted.\n",
      "Image [366] Predicted.\n",
      "Image [367] Predicted.\n",
      "Image [368] Predicted.\n",
      "Image [369] Predicted.\n",
      "Image [370] Predicted.\n",
      "Image [371] Predicted.\n",
      "Image [372] Predicted.\n",
      "Image [373] Predicted.\n",
      "Image [374] Predicted.\n",
      "Image [375] Predicted.\n",
      "Image [376] Predicted.\n",
      "Image [377] Predicted.\n",
      "Image [378] Predicted.\n",
      "Image [379] Predicted.\n",
      "Image [380] Predicted.\n",
      "Image [381] Predicted.\n",
      "Image [382] Predicted.\n",
      "Image [383] Predicted.\n",
      "Image [384] Predicted.\n",
      "Image [385] Predicted.\n",
      "Image [386] Predicted.\n",
      "Image [387] Predicted.\n",
      "Image [388] Predicted.\n",
      "Image [389] Predicted.\n",
      "Image [390] Predicted.\n",
      "Image [391] Predicted.\n",
      "Image [392] Predicted.\n",
      "Image [393] Predicted.\n",
      "Image [394] Predicted.\n",
      "Image [395] Predicted.\n",
      "Image [396] Predicted.\n",
      "Image [397] Predicted.\n",
      "Image [398] Predicted.\n",
      "Image [399] Predicted.\n",
      "Image [400] Predicted.\n",
      "Image [401] Predicted.\n",
      "Image [402] Predicted.\n",
      "Image [403] Predicted.\n",
      "Image [404] Predicted.\n",
      "Image [405] Predicted.\n",
      "Image [406] Predicted.\n",
      "Image [407] Predicted.\n",
      "Image [408] Predicted.\n",
      "Image [409] Predicted.\n",
      "Image [410] Predicted.\n",
      "Image [411] Predicted.\n",
      "Image [412] Predicted.\n",
      "Image [413] Predicted.\n",
      "Image [414] Predicted.\n",
      "Image [415] Predicted.\n",
      "Image [416] Predicted.\n",
      "Image [417] Predicted.\n",
      "Image [418] Predicted.\n",
      "Image [419] Predicted.\n",
      "Image [420] Predicted.\n",
      "Image [421] Predicted.\n",
      "Image [422] Predicted.\n",
      "Image [423] Predicted.\n",
      "Image [424] Predicted.\n",
      "Image [425] Predicted.\n",
      "Image [426] Predicted.\n",
      "Image [427] Predicted.\n",
      "Image [428] Predicted.\n",
      "Image [429] Predicted.\n",
      "Image [430] Predicted.\n",
      "Image [431] Predicted.\n",
      "Image [432] Predicted.\n",
      "Image [433] Predicted.\n",
      "Image [434] Predicted.\n",
      "Image [435] Predicted.\n",
      "Image [436] Predicted.\n",
      "Image [437] Predicted.\n",
      "Image [438] Predicted.\n",
      "Image [439] Predicted.\n",
      "Image [440] Predicted.\n",
      "Image [441] Predicted.\n",
      "Image [442] Predicted.\n",
      "Image [443] Predicted.\n",
      "Image [444] Predicted.\n",
      "Image [445] Predicted.\n",
      "Image [446] Predicted.\n",
      "Image [447] Predicted.\n",
      "Image [448] Predicted.\n",
      "Image [449] Predicted.\n",
      "Image [450] Predicted.\n",
      "Image [451] Predicted.\n",
      "Image [452] Predicted.\n",
      "Image [453] Predicted.\n",
      "Image [454] Predicted.\n",
      "Image [455] Predicted.\n",
      "Image [456] Predicted.\n",
      "Image [457] Predicted.\n",
      "Image [458] Predicted.\n",
      "Image [459] Predicted.\n",
      "Image [460] Predicted.\n",
      "Image [461] Predicted.\n",
      "Image [462] Predicted.\n",
      "Image [463] Predicted.\n",
      "Image [464] Predicted.\n",
      "Image [465] Predicted.\n",
      "Image [466] Predicted.\n",
      "Image [467] Predicted.\n",
      "Image [468] Predicted.\n",
      "Image [469] Predicted.\n",
      "Image [470] Predicted.\n",
      "Image [471] Predicted.\n",
      "Image [472] Predicted.\n",
      "Image [473] Predicted.\n",
      "Image [474] Predicted.\n",
      "Image [475] Predicted.\n",
      "Image [476] Predicted.\n",
      "Image [477] Predicted.\n",
      "Image [478] Predicted.\n",
      "Image [479] Predicted.\n",
      "Image [480] Predicted.\n",
      "Image [481] Predicted.\n",
      "Image [482] Predicted.\n",
      "Image [483] Predicted.\n",
      "Image [484] Predicted.\n",
      "Image [485] Predicted.\n",
      "Image [486] Predicted.\n",
      "Image [487] Predicted.\n",
      "Image [488] Predicted.\n",
      "Image [489] Predicted.\n",
      "Image [490] Predicted.\n",
      "Image [491] Predicted.\n",
      "Image [492] Predicted.\n",
      "Image [493] Predicted.\n",
      "Image [494] Predicted.\n",
      "Image [495] Predicted.\n",
      "Image [496] Predicted.\n",
      "Image [497] Predicted.\n",
      "Image [498] Predicted.\n",
      "Image [499] Predicted.\n",
      "Image [500] Predicted.\n",
      "Image [501] Predicted.\n",
      "Image [502] Predicted.\n",
      "Image [503] Predicted.\n",
      "Image [504] Predicted.\n",
      "Image [505] Predicted.\n",
      "Image [506] Predicted.\n",
      "Image [507] Predicted.\n",
      "Image [508] Predicted.\n",
      "Image [509] Predicted.\n",
      "Image [510] Predicted.\n",
      "Image [511] Predicted.\n",
      "Image [512] Predicted.\n",
      "Image [513] Predicted.\n",
      "Image [514] Predicted.\n",
      "Image [515] Predicted.\n",
      "Image [516] Predicted.\n",
      "Image [517] Predicted.\n",
      "Image [518] Predicted.\n",
      "Image [519] Predicted.\n",
      "Image [520] Predicted.\n",
      "Image [521] Predicted.\n",
      "Image [522] Predicted.\n",
      "Image [523] Predicted.\n",
      "Image [524] Predicted.\n",
      "Image [525] Predicted.\n",
      "Image [526] Predicted.\n",
      "Image [527] Predicted.\n",
      "Image [528] Predicted.\n",
      "Image [529] Predicted.\n",
      "Image [530] Predicted.\n",
      "Image [531] Predicted.\n",
      "Image [532] Predicted.\n",
      "Image [533] Predicted.\n",
      "Image [534] Predicted.\n",
      "Image [535] Predicted.\n",
      "Image [536] Predicted.\n",
      "Image [537] Predicted.\n",
      "Image [538] Predicted.\n",
      "Image [539] Predicted.\n",
      "Image [540] Predicted.\n",
      "Image [541] Predicted.\n",
      "Image [542] Predicted.\n",
      "Image [543] Predicted.\n",
      "Image [544] Predicted.\n",
      "Image [545] Predicted.\n",
      "Image [546] Predicted.\n",
      "Image [547] Predicted.\n",
      "Image [548] Predicted.\n",
      "Image [549] Predicted.\n",
      "Image [550] Predicted.\n",
      "Image [551] Predicted.\n",
      "Image [552] Predicted.\n",
      "Image [553] Predicted.\n",
      "Image [554] Predicted.\n",
      "Image [555] Predicted.\n",
      "Image [556] Predicted.\n",
      "Image [557] Predicted.\n",
      "Image [558] Predicted.\n",
      "Image [559] Predicted.\n",
      "Image [560] Predicted.\n",
      "Image [561] Predicted.\n",
      "Image [562] Predicted.\n",
      "Image [563] Predicted.\n",
      "Image [564] Predicted.\n",
      "Image [565] Predicted.\n",
      "Image [566] Predicted.\n",
      "Image [567] Predicted.\n",
      "Image [568] Predicted.\n",
      "Image [569] Predicted.\n",
      "Image [570] Predicted.\n",
      "Image [571] Predicted.\n",
      "Image [572] Predicted.\n",
      "Image [573] Predicted.\n",
      "Image [574] Predicted.\n",
      "Image [575] Predicted.\n",
      "Image [576] Predicted.\n",
      "Image [577] Predicted.\n",
      "Image [578] Predicted.\n",
      "Image [579] Predicted.\n",
      "Image [580] Predicted.\n",
      "Image [581] Predicted.\n",
      "Image [582] Predicted.\n",
      "Image [583] Predicted.\n",
      "Image [584] Predicted.\n",
      "Image [585] Predicted.\n",
      "Image [586] Predicted.\n",
      "Image [587] Predicted.\n",
      "Image [588] Predicted.\n",
      "Image [589] Predicted.\n",
      "Image [590] Predicted.\n",
      "Image [591] Predicted.\n",
      "Image [592] Predicted.\n",
      "Image [593] Predicted.\n",
      "Image [594] Predicted.\n",
      "Image [595] Predicted.\n",
      "Image [596] Predicted.\n",
      "Image [597] Predicted.\n",
      "Image [598] Predicted.\n",
      "Image [599] Predicted.\n",
      "Image [600] Predicted.\n",
      "Image [601] Predicted.\n",
      "Image [602] Predicted.\n",
      "Image [603] Predicted.\n",
      "Image [604] Predicted.\n",
      "Image [605] Predicted.\n",
      "Image [606] Predicted.\n",
      "Image [607] Predicted.\n",
      "Image [608] Predicted.\n",
      "Image [609] Predicted.\n",
      "Image [610] Predicted.\n",
      "Image [611] Predicted.\n",
      "Image [612] Predicted.\n",
      "Image [613] Predicted.\n",
      "Image [614] Predicted.\n",
      "Image [615] Predicted.\n",
      "Image [616] Predicted.\n",
      "Image [617] Predicted.\n",
      "Image [618] Predicted.\n",
      "Image [619] Predicted.\n",
      "Image [620] Predicted.\n",
      "Image [621] Predicted.\n",
      "Image [622] Predicted.\n",
      "Image [623] Predicted.\n",
      "Image [624] Predicted.\n",
      "Image [625] Predicted.\n",
      "Image [626] Predicted.\n",
      "Image [627] Predicted.\n",
      "Image [628] Predicted.\n",
      "Image [629] Predicted.\n",
      "Image [630] Predicted.\n",
      "Image [631] Predicted.\n",
      "Image [632] Predicted.\n",
      "Image [633] Predicted.\n",
      "Image [634] Predicted.\n",
      "Image [635] Predicted.\n",
      "Image [636] Predicted.\n",
      "Image [637] Predicted.\n",
      "Image [638] Predicted.\n",
      "Image [639] Predicted.\n",
      "Image [640] Predicted.\n",
      "Image [641] Predicted.\n",
      "Image [642] Predicted.\n",
      "Image [643] Predicted.\n",
      "Image [644] Predicted.\n",
      "Image [645] Predicted.\n",
      "Image [646] Predicted.\n",
      "Image [647] Predicted.\n",
      "Image [648] Predicted.\n",
      "Image [649] Predicted.\n",
      "Image [650] Predicted.\n",
      "Image [651] Predicted.\n",
      "Image [652] Predicted.\n",
      "Image [653] Predicted.\n",
      "Image [654] Predicted.\n",
      "Image [655] Predicted.\n",
      "Image [656] Predicted.\n",
      "Image [657] Predicted.\n",
      "Image [658] Predicted.\n",
      "Image [659] Predicted.\n",
      "Image [660] Predicted.\n",
      "Image [661] Predicted.\n",
      "Image [662] Predicted.\n",
      "Image [663] Predicted.\n",
      "Image [664] Predicted.\n",
      "Image [665] Predicted.\n",
      "Image [666] Predicted.\n",
      "Image [667] Predicted.\n",
      "Image [668] Predicted.\n",
      "Image [669] Predicted.\n",
      "Image [670] Predicted.\n",
      "Image [671] Predicted.\n",
      "Image [672] Predicted.\n",
      "Image [673] Predicted.\n",
      "Image [674] Predicted.\n",
      "Image [675] Predicted.\n",
      "Image [676] Predicted.\n",
      "Image [677] Predicted.\n",
      "Image [678] Predicted.\n",
      "Image [679] Predicted.\n",
      "Image [680] Predicted.\n",
      "Image [681] Predicted.\n",
      "Image [682] Predicted.\n",
      "Image [683] Predicted.\n",
      "Image [684] Predicted.\n",
      "Image [685] Predicted.\n",
      "Image [686] Predicted.\n",
      "Image [687] Predicted.\n",
      "Image [688] Predicted.\n",
      "Image [689] Predicted.\n",
      "Image [690] Predicted.\n",
      "Image [691] Predicted.\n",
      "Image [692] Predicted.\n",
      "Image [693] Predicted.\n",
      "Image [694] Predicted.\n",
      "Image [695] Predicted.\n",
      "Image [696] Predicted.\n",
      "Image [697] Predicted.\n",
      "Image [698] Predicted.\n",
      "Image [699] Predicted.\n",
      "Image [700] Predicted.\n",
      "Image [701] Predicted.\n",
      "Image [702] Predicted.\n",
      "Image [703] Predicted.\n",
      "Image [704] Predicted.\n",
      "Image [705] Predicted.\n",
      "Image [706] Predicted.\n",
      "Image [707] Predicted.\n",
      "Image [708] Predicted.\n",
      "Image [709] Predicted.\n",
      "Image [710] Predicted.\n",
      "Image [711] Predicted.\n",
      "Image [712] Predicted.\n",
      "Image [713] Predicted.\n",
      "Image [714] Predicted.\n",
      "Image [715] Predicted.\n",
      "Image [716] Predicted.\n",
      "Image [717] Predicted.\n",
      "Image [718] Predicted.\n",
      "Image [719] Predicted.\n",
      "Image [720] Predicted.\n",
      "Image [721] Predicted.\n",
      "Image [722] Predicted.\n",
      "Image [723] Predicted.\n",
      "Image [724] Predicted.\n",
      "Image [725] Predicted.\n",
      "Image [726] Predicted.\n",
      "Image [727] Predicted.\n",
      "Image [728] Predicted.\n",
      "Image [729] Predicted.\n",
      "Image [730] Predicted.\n",
      "Image [731] Predicted.\n",
      "Image [732] Predicted.\n",
      "Image [733] Predicted.\n",
      "Image [734] Predicted.\n",
      "Image [735] Predicted.\n",
      "Image [736] Predicted.\n",
      "Image [737] Predicted.\n",
      "Image [738] Predicted.\n",
      "Image [739] Predicted.\n",
      "Image [740] Predicted.\n",
      "Image [741] Predicted.\n",
      "Image [742] Predicted.\n",
      "Image [743] Predicted.\n",
      "Image [744] Predicted.\n",
      "Image [745] Predicted.\n",
      "Image [746] Predicted.\n",
      "Image [747] Predicted.\n",
      "Image [748] Predicted.\n",
      "Image [749] Predicted.\n",
      "Image [750] Predicted.\n",
      "Image [751] Predicted.\n",
      "Image [752] Predicted.\n",
      "Image [753] Predicted.\n",
      "Image [754] Predicted.\n",
      "Image [755] Predicted.\n",
      "Image [756] Predicted.\n",
      "Image [757] Predicted.\n",
      "Image [758] Predicted.\n",
      "Image [759] Predicted.\n",
      "Image [760] Predicted.\n",
      "Image [761] Predicted.\n",
      "Image [762] Predicted.\n",
      "Image [763] Predicted.\n",
      "Image [764] Predicted.\n",
      "Image [765] Predicted.\n",
      "Image [766] Predicted.\n",
      "Image [767] Predicted.\n",
      "Image [768] Predicted.\n",
      "Image [769] Predicted.\n",
      "Image [770] Predicted.\n",
      "Image [771] Predicted.\n",
      "Image [772] Predicted.\n",
      "Image [773] Predicted.\n",
      "Image [774] Predicted.\n",
      "Image [775] Predicted.\n",
      "Image [776] Predicted.\n",
      "Image [777] Predicted.\n",
      "Image [778] Predicted.\n",
      "Image [779] Predicted.\n",
      "Image [780] Predicted.\n",
      "Image [781] Predicted.\n",
      "Image [782] Predicted.\n",
      "Image [783] Predicted.\n",
      "Image [784] Predicted.\n",
      "Image [785] Predicted.\n",
      "Image [786] Predicted.\n",
      "Image [787] Predicted.\n",
      "Image [788] Predicted.\n",
      "Image [789] Predicted.\n",
      "Image [790] Predicted.\n",
      "Image [791] Predicted.\n",
      "Image [792] Predicted.\n",
      "Image [793] Predicted.\n",
      "Image [794] Predicted.\n",
      "Image [795] Predicted.\n",
      "Image [796] Predicted.\n",
      "Image [797] Predicted.\n",
      "Image [798] Predicted.\n",
      "Image [799] Predicted.\n",
      "Image [800] Predicted.\n",
      "Image [801] Predicted.\n",
      "Image [802] Predicted.\n",
      "Image [803] Predicted.\n",
      "Image [804] Predicted.\n",
      "Image [805] Predicted.\n",
      "Image [806] Predicted.\n",
      "Image [807] Predicted.\n",
      "Image [808] Predicted.\n",
      "Image [809] Predicted.\n",
      "Image [810] Predicted.\n",
      "Image [811] Predicted.\n",
      "Image [812] Predicted.\n",
      "Image [813] Predicted.\n",
      "Image [814] Predicted.\n",
      "Image [815] Predicted.\n",
      "Image [816] Predicted.\n",
      "Image [817] Predicted.\n",
      "Image [818] Predicted.\n",
      "Image [819] Predicted.\n",
      "Image [820] Predicted.\n",
      "Image [821] Predicted.\n",
      "Image [822] Predicted.\n",
      "Image [823] Predicted.\n",
      "Image [824] Predicted.\n",
      "Image [825] Predicted.\n",
      "Image [826] Predicted.\n",
      "Image [827] Predicted.\n",
      "Image [828] Predicted.\n",
      "Image [829] Predicted.\n",
      "Image [830] Predicted.\n",
      "Image [831] Predicted.\n",
      "Image [832] Predicted.\n",
      "Image [833] Predicted.\n",
      "Image [834] Predicted.\n",
      "Image [835] Predicted.\n",
      "Image [836] Predicted.\n",
      "Image [837] Predicted.\n",
      "Image [838] Predicted.\n",
      "Image [839] Predicted.\n",
      "Image [840] Predicted.\n",
      "Image [841] Predicted.\n",
      "Image [842] Predicted.\n",
      "Image [843] Predicted.\n",
      "Image [844] Predicted.\n",
      "Image [845] Predicted.\n",
      "Image [846] Predicted.\n",
      "Image [847] Predicted.\n",
      "Image [848] Predicted.\n",
      "Image [849] Predicted.\n",
      "Image [850] Predicted.\n",
      "Image [851] Predicted.\n",
      "Image [852] Predicted.\n",
      "Image [853] Predicted.\n",
      "Image [854] Predicted.\n",
      "Image [855] Predicted.\n",
      "Image [856] Predicted.\n",
      "Image [857] Predicted.\n",
      "Image [858] Predicted.\n",
      "Image [859] Predicted.\n",
      "Image [860] Predicted.\n",
      "Image [861] Predicted.\n",
      "Image [862] Predicted.\n",
      "Image [863] Predicted.\n",
      "Image [864] Predicted.\n",
      "Image [865] Predicted.\n",
      "Image [866] Predicted.\n",
      "Image [867] Predicted.\n",
      "Image [868] Predicted.\n",
      "Image [869] Predicted.\n",
      "Image [870] Predicted.\n",
      "Image [871] Predicted.\n",
      "Image [872] Predicted.\n",
      "Image [873] Predicted.\n",
      "Image [874] Predicted.\n",
      "Image [875] Predicted.\n",
      "Image [876] Predicted.\n",
      "Image [877] Predicted.\n",
      "Image [878] Predicted.\n",
      "Image [879] Predicted.\n",
      "Image [880] Predicted.\n",
      "Image [881] Predicted.\n",
      "Image [882] Predicted.\n",
      "Image [883] Predicted.\n",
      "Image [884] Predicted.\n",
      "Image [885] Predicted.\n",
      "Image [886] Predicted.\n",
      "Image [887] Predicted.\n",
      "Image [888] Predicted.\n",
      "Image [889] Predicted.\n",
      "Image [890] Predicted.\n",
      "Image [891] Predicted.\n",
      "Image [892] Predicted.\n",
      "Image [893] Predicted.\n",
      "Image [894] Predicted.\n",
      "Image [895] Predicted.\n",
      "Image [896] Predicted.\n",
      "Image [897] Predicted.\n",
      "Image [898] Predicted.\n",
      "Image [899] Predicted.\n",
      "Image [900] Predicted.\n",
      "Image [901] Predicted.\n",
      "Image [902] Predicted.\n",
      "Image [903] Predicted.\n",
      "Image [904] Predicted.\n",
      "Image [905] Predicted.\n",
      "Image [906] Predicted.\n",
      "Image [907] Predicted.\n",
      "Image [908] Predicted.\n",
      "Image [909] Predicted.\n",
      "Image [910] Predicted.\n",
      "Image [911] Predicted.\n",
      "Image [912] Predicted.\n",
      "Image [913] Predicted.\n",
      "Image [914] Predicted.\n",
      "Image [915] Predicted.\n",
      "Image [916] Predicted.\n",
      "Image [917] Predicted.\n",
      "Image [918] Predicted.\n",
      "Image [919] Predicted.\n",
      "Image [920] Predicted.\n",
      "Image [921] Predicted.\n",
      "Image [922] Predicted.\n",
      "Image [923] Predicted.\n",
      "Image [924] Predicted.\n",
      "Image [925] Predicted.\n",
      "Image [926] Predicted.\n",
      "Image [927] Predicted.\n",
      "Image [928] Predicted.\n",
      "Image [929] Predicted.\n",
      "Image [930] Predicted.\n",
      "Image [931] Predicted.\n",
      "Image [932] Predicted.\n",
      "Image [933] Predicted.\n",
      "Image [934] Predicted.\n",
      "Image [935] Predicted.\n",
      "Image [936] Predicted.\n",
      "Image [937] Predicted.\n",
      "Image [938] Predicted.\n",
      "Image [939] Predicted.\n",
      "Image [940] Predicted.\n",
      "Image [941] Predicted.\n",
      "Image [942] Predicted.\n",
      "Image [943] Predicted.\n",
      "Image [944] Predicted.\n",
      "Image [945] Predicted.\n",
      "Image [946] Predicted.\n",
      "Image [947] Predicted.\n",
      "Image [948] Predicted.\n",
      "Image [949] Predicted.\n",
      "Image [950] Predicted.\n",
      "Image [951] Predicted.\n",
      "Image [952] Predicted.\n",
      "Image [953] Predicted.\n",
      "Image [954] Predicted.\n",
      "Image [955] Predicted.\n",
      "Image [956] Predicted.\n",
      "Image [957] Predicted.\n",
      "Image [958] Predicted.\n",
      "Image [959] Predicted.\n",
      "Image [960] Predicted.\n",
      "Image [961] Predicted.\n",
      "Image [962] Predicted.\n",
      "Image [963] Predicted.\n",
      "Image [964] Predicted.\n",
      "Image [965] Predicted.\n",
      "Image [966] Predicted.\n",
      "Image [967] Predicted.\n",
      "Image [968] Predicted.\n",
      "Image [969] Predicted.\n",
      "Image [970] Predicted.\n",
      "Image [971] Predicted.\n",
      "Image [972] Predicted.\n",
      "Image [973] Predicted.\n",
      "Image [974] Predicted.\n",
      "Image [975] Predicted.\n",
      "Image [976] Predicted.\n",
      "Image [977] Predicted.\n",
      "Image [978] Predicted.\n",
      "Image [979] Predicted.\n",
      "Image [980] Predicted.\n",
      "Image [981] Predicted.\n",
      "Image [982] Predicted.\n",
      "Image [983] Predicted.\n",
      "Image [984] Predicted.\n",
      "Image [985] Predicted.\n",
      "Image [986] Predicted.\n",
      "Image [987] Predicted.\n",
      "Image [988] Predicted.\n",
      "Image [989] Predicted.\n",
      "Image [990] Predicted.\n",
      "Image [991] Predicted.\n",
      "Image [992] Predicted.\n",
      "Image [993] Predicted.\n",
      "Image [994] Predicted.\n",
      "Image [995] Predicted.\n",
      "Image [996] Predicted.\n",
      "Image [997] Predicted.\n",
      "Image [998] Predicted.\n",
      "Image [999] Predicted.\n",
      "Image [1000] Predicted.\n",
      "Image [1001] Predicted.\n",
      "Image [1002] Predicted.\n",
      "Image [1003] Predicted.\n",
      "Image [1004] Predicted.\n",
      "Image [1005] Predicted.\n",
      "Image [1006] Predicted.\n",
      "Image [1007] Predicted.\n",
      "Image [1008] Predicted.\n",
      "Image [1009] Predicted.\n",
      "Image [1010] Predicted.\n",
      "Image [1011] Predicted.\n",
      "Image [1012] Predicted.\n",
      "Image [1013] Predicted.\n",
      "Image [1014] Predicted.\n",
      "Image [1015] Predicted.\n",
      "Image [1016] Predicted.\n",
      "Image [1017] Predicted.\n",
      "Image [1018] Predicted.\n",
      "Image [1019] Predicted.\n",
      "Image [1020] Predicted.\n",
      "Image [1021] Predicted.\n",
      "Image [1022] Predicted.\n",
      "Image [1023] Predicted.\n",
      "Image [1024] Predicted.\n",
      "Image [1025] Predicted.\n",
      "Image [1026] Predicted.\n",
      "Image [1027] Predicted.\n",
      "Image [1028] Predicted.\n",
      "Image [1029] Predicted.\n",
      "Image [1030] Predicted.\n",
      "Image [1031] Predicted.\n",
      "Image [1032] Predicted.\n",
      "Image [1033] Predicted.\n",
      "Image [1034] Predicted.\n",
      "Image [1035] Predicted.\n",
      "Image [1036] Predicted.\n",
      "Image [1037] Predicted.\n",
      "Image [1038] Predicted.\n",
      "Image [1039] Predicted.\n",
      "Image [1040] Predicted.\n",
      "Image [1041] Predicted.\n",
      "Image [1042] Predicted.\n",
      "Image [1043] Predicted.\n",
      "Image [1044] Predicted.\n",
      "Image [1045] Predicted.\n",
      "Image [1046] Predicted.\n",
      "Image [1047] Predicted.\n",
      "Image [1048] Predicted.\n",
      "Image [1049] Predicted.\n",
      "Image [1050] Predicted.\n",
      "Image [1051] Predicted.\n",
      "Image [1052] Predicted.\n",
      "Image [1053] Predicted.\n",
      "Image [1054] Predicted.\n",
      "Image [1055] Predicted.\n",
      "Image [1056] Predicted.\n",
      "Image [1057] Predicted.\n",
      "Image [1058] Predicted.\n",
      "Image [1059] Predicted.\n",
      "Image [1060] Predicted.\n",
      "Image [1061] Predicted.\n",
      "Image [1062] Predicted.\n",
      "Image [1063] Predicted.\n",
      "Image [1064] Predicted.\n",
      "Image [1065] Predicted.\n",
      "Image [1066] Predicted.\n",
      "Image [1067] Predicted.\n",
      "Image [1068] Predicted.\n",
      "Image [1069] Predicted.\n",
      "Image [1070] Predicted.\n",
      "Image [1071] Predicted.\n",
      "Image [1072] Predicted.\n",
      "Image [1073] Predicted.\n",
      "Image [1074] Predicted.\n",
      "Image [1075] Predicted.\n",
      "Image [1076] Predicted.\n",
      "Image [1077] Predicted.\n",
      "Image [1078] Predicted.\n",
      "Image [1079] Predicted.\n",
      "Image [1080] Predicted.\n",
      "Image [1081] Predicted.\n",
      "Image [1082] Predicted.\n",
      "Image [1083] Predicted.\n",
      "Image [1084] Predicted.\n",
      "Image [1085] Predicted.\n",
      "Image [1086] Predicted.\n",
      "Image [1087] Predicted.\n",
      "Image [1088] Predicted.\n",
      "Image [1089] Predicted.\n",
      "Image [1090] Predicted.\n",
      "Image [1091] Predicted.\n",
      "Image [1092] Predicted.\n",
      "Image [1093] Predicted.\n",
      "Image [1094] Predicted.\n",
      "Image [1095] Predicted.\n",
      "Image [1096] Predicted.\n",
      "Image [1097] Predicted.\n",
      "Image [1098] Predicted.\n",
      "Image [1099] Predicted.\n",
      "Image [1100] Predicted.\n",
      "Image [1101] Predicted.\n",
      "Image [1102] Predicted.\n",
      "Image [1103] Predicted.\n",
      "Image [1104] Predicted.\n",
      "Image [1105] Predicted.\n",
      "Image [1106] Predicted.\n",
      "Image [1107] Predicted.\n",
      "Image [1108] Predicted.\n",
      "Image [1109] Predicted.\n",
      "Image [1110] Predicted.\n",
      "Image [1111] Predicted.\n",
      "Image [1112] Predicted.\n",
      "Image [1113] Predicted.\n",
      "Image [1114] Predicted.\n",
      "Image [1115] Predicted.\n",
      "Image [1116] Predicted.\n",
      "Image [1117] Predicted.\n",
      "Image [1118] Predicted.\n",
      "Image [1119] Predicted.\n",
      "Image [1120] Predicted.\n",
      "Image [1121] Predicted.\n",
      "Image [1122] Predicted.\n",
      "Image [1123] Predicted.\n",
      "Image [1124] Predicted.\n",
      "Image [1125] Predicted.\n",
      "Image [1126] Predicted.\n",
      "Image [1127] Predicted.\n",
      "Image [1128] Predicted.\n",
      "Image [1129] Predicted.\n",
      "Image [1130] Predicted.\n",
      "Image [1131] Predicted.\n",
      "Image [1132] Predicted.\n",
      "Image [1133] Predicted.\n",
      "Image [1134] Predicted.\n",
      "Image [1135] Predicted.\n",
      "Image [1136] Predicted.\n",
      "Image [1137] Predicted.\n",
      "Image [1138] Predicted.\n",
      "Image [1139] Predicted.\n",
      "Image [1140] Predicted.\n",
      "Image [1141] Predicted.\n",
      "Image [1142] Predicted.\n",
      "Image [1143] Predicted.\n",
      "Image [1144] Predicted.\n",
      "Image [1145] Predicted.\n",
      "Image [1146] Predicted.\n",
      "Image [1147] Predicted.\n",
      "Image [1148] Predicted.\n",
      "Image [1149] Predicted.\n",
      "Image [1150] Predicted.\n",
      "Image [1151] Predicted.\n",
      "Image [1152] Predicted.\n",
      "Image [1153] Predicted.\n",
      "Image [1154] Predicted.\n",
      "Image [1155] Predicted.\n",
      "Image [1156] Predicted.\n",
      "Image [1157] Predicted.\n",
      "Image [1158] Predicted.\n",
      "Image [1159] Predicted.\n",
      "Image [1160] Predicted.\n",
      "Image [1161] Predicted.\n",
      "Image [1162] Predicted.\n",
      "Image [1163] Predicted.\n",
      "Image [1164] Predicted.\n",
      "Image [1165] Predicted.\n",
      "Image [1166] Predicted.\n",
      "Image [1167] Predicted.\n",
      "Image [1168] Predicted.\n",
      "Image [1169] Predicted.\n",
      "Image [1170] Predicted.\n",
      "Image [1171] Predicted.\n",
      "Image [1172] Predicted.\n",
      "Image [1173] Predicted.\n",
      "Image [1174] Predicted.\n",
      "Image [1175] Predicted.\n",
      "Image [1176] Predicted.\n",
      "Image [1177] Predicted.\n",
      "Image [1178] Predicted.\n",
      "Image [1179] Predicted.\n",
      "Image [1180] Predicted.\n",
      "Image [1181] Predicted.\n",
      "Image [1182] Predicted.\n",
      "Image [1183] Predicted.\n",
      "Image [1184] Predicted.\n",
      "Image [1185] Predicted.\n",
      "Image [1186] Predicted.\n",
      "Image [1187] Predicted.\n",
      "Image [1188] Predicted.\n",
      "Image [1189] Predicted.\n",
      "Image [1190] Predicted.\n",
      "Image [1191] Predicted.\n",
      "Image [1192] Predicted.\n",
      "Image [1193] Predicted.\n",
      "Image [1194] Predicted.\n",
      "Image [1195] Predicted.\n",
      "Image [1196] Predicted.\n",
      "Image [1197] Predicted.\n",
      "Image [1198] Predicted.\n",
      "Image [1199] Predicted.\n",
      "Image [1200] Predicted.\n",
      "Image [1201] Predicted.\n",
      "Image [1202] Predicted.\n",
      "Image [1203] Predicted.\n",
      "Image [1204] Predicted.\n",
      "Image [1205] Predicted.\n",
      "Image [1206] Predicted.\n",
      "Image [1207] Predicted.\n",
      "Image [1208] Predicted.\n",
      "Image [1209] Predicted.\n",
      "Image [1210] Predicted.\n",
      "Image [1211] Predicted.\n",
      "Image [1212] Predicted.\n",
      "Image [1213] Predicted.\n",
      "Image [1214] Predicted.\n",
      "Image [1215] Predicted.\n",
      "Image [1216] Predicted.\n",
      "Image [1217] Predicted.\n",
      "Image [1218] Predicted.\n",
      "Image [1219] Predicted.\n",
      "Image [1220] Predicted.\n",
      "Image [1221] Predicted.\n",
      "Image [1222] Predicted.\n",
      "Image [1223] Predicted.\n",
      "Image [1224] Predicted.\n",
      "Image [1225] Predicted.\n",
      "Image [1226] Predicted.\n",
      "Image [1227] Predicted.\n",
      "Image [1228] Predicted.\n",
      "Image [1229] Predicted.\n",
      "Image [1230] Predicted.\n",
      "Image [1231] Predicted.\n",
      "Image [1232] Predicted.\n",
      "Image [1233] Predicted.\n",
      "Image [1234] Predicted.\n",
      "Image [1235] Predicted.\n",
      "Image [1236] Predicted.\n",
      "Image [1237] Predicted.\n",
      "Image [1238] Predicted.\n",
      "Image [1239] Predicted.\n",
      "Image [1240] Predicted.\n",
      "Image [1241] Predicted.\n",
      "Image [1242] Predicted.\n",
      "Image [1243] Predicted.\n",
      "Image [1244] Predicted.\n",
      "Image [1245] Predicted.\n",
      "Image [1246] Predicted.\n",
      "Image [1247] Predicted.\n",
      "Image [1248] Predicted.\n",
      "Image [1249] Predicted.\n",
      "Image [1250] Predicted.\n",
      "Image [1251] Predicted.\n",
      "Image [1252] Predicted.\n",
      "Image [1253] Predicted.\n",
      "Image [1254] Predicted.\n",
      "Image [1255] Predicted.\n",
      "Image [1256] Predicted.\n",
      "Image [1257] Predicted.\n",
      "Image [1258] Predicted.\n",
      "Image [1259] Predicted.\n",
      "Image [1260] Predicted.\n",
      "Image [1261] Predicted.\n",
      "Image [1262] Predicted.\n",
      "Image [1263] Predicted.\n",
      "Image [1264] Predicted.\n",
      "Image [1265] Predicted.\n",
      "Image [1266] Predicted.\n",
      "Image [1267] Predicted.\n",
      "Image [1268] Predicted.\n",
      "Image [1269] Predicted.\n",
      "Image [1270] Predicted.\n",
      "Image [1271] Predicted.\n",
      "Image [1272] Predicted.\n",
      "Image [1273] Predicted.\n",
      "Image [1274] Predicted.\n",
      "Image [1275] Predicted.\n",
      "Image [1276] Predicted.\n",
      "Image [1277] Predicted.\n",
      "Image [1278] Predicted.\n",
      "Image [1279] Predicted.\n",
      "Image [1280] Predicted.\n",
      "Image [1281] Predicted.\n",
      "Image [1282] Predicted.\n",
      "Image [1283] Predicted.\n",
      "Image [1284] Predicted.\n",
      "Image [1285] Predicted.\n",
      "Image [1286] Predicted.\n",
      "Image [1287] Predicted.\n",
      "Image [1288] Predicted.\n",
      "Image [1289] Predicted.\n",
      "Image [1290] Predicted.\n",
      "Image [1291] Predicted.\n",
      "Image [1292] Predicted.\n",
      "Image [1293] Predicted.\n",
      "Image [1294] Predicted.\n",
      "Image [1295] Predicted.\n",
      "Image [1296] Predicted.\n",
      "Image [1297] Predicted.\n",
      "Image [1298] Predicted.\n",
      "Image [1299] Predicted.\n",
      "Image [1300] Predicted.\n",
      "Image [1301] Predicted.\n",
      "Image [1302] Predicted.\n",
      "Image [1303] Predicted.\n",
      "Image [1304] Predicted.\n",
      "Image [1305] Predicted.\n",
      "Image [1306] Predicted.\n",
      "Image [1307] Predicted.\n",
      "Image [1308] Predicted.\n",
      "Image [1309] Predicted.\n",
      "Image [1310] Predicted.\n",
      "Image [1311] Predicted.\n",
      "Image [1312] Predicted.\n",
      "Image [1313] Predicted.\n",
      "Image [1314] Predicted.\n",
      "Image [1315] Predicted.\n",
      "Image [1316] Predicted.\n",
      "Image [1317] Predicted.\n",
      "Image [1318] Predicted.\n",
      "Image [1319] Predicted.\n",
      "Image [1320] Predicted.\n",
      "Image [1321] Predicted.\n",
      "Image [1322] Predicted.\n",
      "Image [1323] Predicted.\n",
      "Image [1324] Predicted.\n",
      "Image [1325] Predicted.\n",
      "Image [1326] Predicted.\n",
      "Image [1327] Predicted.\n",
      "Image [1328] Predicted.\n",
      "Image [1329] Predicted.\n",
      "Image [1330] Predicted.\n",
      "Image [1331] Predicted.\n",
      "Image [1332] Predicted.\n",
      "Image [1333] Predicted.\n",
      "Image [1334] Predicted.\n",
      "Image [1335] Predicted.\n",
      "Image [1336] Predicted.\n",
      "Image [1337] Predicted.\n",
      "Image [1338] Predicted.\n",
      "Image [1339] Predicted.\n",
      "Image [1340] Predicted.\n",
      "Image [1341] Predicted.\n",
      "Image [1342] Predicted.\n",
      "Image [1343] Predicted.\n",
      "Image [1344] Predicted.\n",
      "Image [1345] Predicted.\n",
      "Image [1346] Predicted.\n",
      "Image [1347] Predicted.\n",
      "Image [1348] Predicted.\n",
      "Image [1349] Predicted.\n",
      "Image [1350] Predicted.\n",
      "Image [1351] Predicted.\n",
      "Image [1352] Predicted.\n",
      "Image [1353] Predicted.\n",
      "Image [1354] Predicted.\n",
      "Image [1355] Predicted.\n",
      "Image [1356] Predicted.\n",
      "Image [1357] Predicted.\n",
      "Image [1358] Predicted.\n",
      "Image [1359] Predicted.\n",
      "Image [1360] Predicted.\n",
      "Image [1361] Predicted.\n",
      "Image [1362] Predicted.\n",
      "Image [1363] Predicted.\n",
      "Image [1364] Predicted.\n",
      "Image [1365] Predicted.\n",
      "Image [1366] Predicted.\n",
      "Image [1367] Predicted.\n",
      "Image [1368] Predicted.\n",
      "Image [1369] Predicted.\n",
      "Image [1370] Predicted.\n",
      "Image [1371] Predicted.\n",
      "Image [1372] Predicted.\n",
      "Image [1373] Predicted.\n",
      "Image [1374] Predicted.\n",
      "Image [1375] Predicted.\n",
      "Image [1376] Predicted.\n",
      "Image [1377] Predicted.\n",
      "Image [1378] Predicted.\n",
      "Image [1379] Predicted.\n",
      "Image [1380] Predicted.\n",
      "Image [1381] Predicted.\n",
      "Image [1382] Predicted.\n",
      "Image [1383] Predicted.\n",
      "Image [1384] Predicted.\n",
      "Image [1385] Predicted.\n",
      "Image [1386] Predicted.\n",
      "Image [1387] Predicted.\n",
      "Image [1388] Predicted.\n",
      "Image [1389] Predicted.\n",
      "Image [1390] Predicted.\n",
      "Image [1391] Predicted.\n",
      "Image [1392] Predicted.\n",
      "Image [1393] Predicted.\n",
      "Image [1394] Predicted.\n",
      "Image [1395] Predicted.\n",
      "Image [1396] Predicted.\n",
      "Image [1397] Predicted.\n",
      "Image [1398] Predicted.\n",
      "Image [1399] Predicted.\n",
      "Image [1400] Predicted.\n",
      "Image [1401] Predicted.\n",
      "Image [1402] Predicted.\n",
      "Image [1403] Predicted.\n",
      "Image [1404] Predicted.\n",
      "Image [1405] Predicted.\n",
      "Image [1406] Predicted.\n",
      "Image [1407] Predicted.\n",
      "Image [1408] Predicted.\n",
      "Image [1409] Predicted.\n",
      "Image [1410] Predicted.\n",
      "Image [1411] Predicted.\n",
      "Image [1412] Predicted.\n",
      "Image [1413] Predicted.\n",
      "Image [1414] Predicted.\n",
      "Image [1415] Predicted.\n",
      "Image [1416] Predicted.\n",
      "Image [1417] Predicted.\n",
      "Image [1418] Predicted.\n",
      "Image [1419] Predicted.\n",
      "Image [1420] Predicted.\n",
      "Image [1421] Predicted.\n",
      "Image [1422] Predicted.\n",
      "Image [1423] Predicted.\n",
      "Image [1424] Predicted.\n",
      "Image [1425] Predicted.\n",
      "Image [1426] Predicted.\n",
      "Image [1427] Predicted.\n",
      "Image [1428] Predicted.\n",
      "Image [1429] Predicted.\n",
      "Image [1430] Predicted.\n",
      "Image [1431] Predicted.\n",
      "Image [1432] Predicted.\n",
      "Image [1433] Predicted.\n",
      "Image [1434] Predicted.\n",
      "Image [1435] Predicted.\n",
      "Image [1436] Predicted.\n",
      "Image [1437] Predicted.\n",
      "Image [1438] Predicted.\n",
      "Image [1439] Predicted.\n",
      "Image [1440] Predicted.\n",
      "Image [1441] Predicted.\n",
      "Image [1442] Predicted.\n",
      "Image [1443] Predicted.\n",
      "Image [1444] Predicted.\n",
      "Image [1445] Predicted.\n",
      "Image [1446] Predicted.\n",
      "Image [1447] Predicted.\n",
      "Image [1448] Predicted.\n",
      "Image [1449] Predicted.\n",
      "Image [1450] Predicted.\n",
      "Image [1451] Predicted.\n",
      "Image [1452] Predicted.\n",
      "Image [1453] Predicted.\n",
      "Image [1454] Predicted.\n",
      "Image [1455] Predicted.\n",
      "Image [1456] Predicted.\n",
      "Image [1457] Predicted.\n",
      "Image [1458] Predicted.\n",
      "Image [1459] Predicted.\n",
      "Image [1460] Predicted.\n",
      "Image [1461] Predicted.\n",
      "Image [1462] Predicted.\n",
      "Image [1463] Predicted.\n",
      "Image [1464] Predicted.\n",
      "Image [1465] Predicted.\n",
      "Image [1466] Predicted.\n",
      "Image [1467] Predicted.\n",
      "Image [1468] Predicted.\n",
      "Image [1469] Predicted.\n",
      "Image [1470] Predicted.\n",
      "Image [1471] Predicted.\n",
      "Image [1472] Predicted.\n",
      "Image [1473] Predicted.\n",
      "Image [1474] Predicted.\n",
      "Image [1475] Predicted.\n",
      "Image [1476] Predicted.\n",
      "Image [1477] Predicted.\n",
      "Image [1478] Predicted.\n",
      "Image [1479] Predicted.\n",
      "Image [1480] Predicted.\n",
      "Image [1481] Predicted.\n",
      "Image [1482] Predicted.\n",
      "Image [1483] Predicted.\n",
      "Image [1484] Predicted.\n",
      "Image [1485] Predicted.\n",
      "Image [1486] Predicted.\n",
      "Image [1487] Predicted.\n",
      "Image [1488] Predicted.\n",
      "Image [1489] Predicted.\n",
      "Image [1490] Predicted.\n",
      "Image [1491] Predicted.\n",
      "Image [1492] Predicted.\n",
      "Image [1493] Predicted.\n",
      "Image [1494] Predicted.\n",
      "Image [1495] Predicted.\n",
      "Image [1496] Predicted.\n",
      "Image [1497] Predicted.\n",
      "Image [1498] Predicted.\n",
      "Image [1499] Predicted.\n",
      "Image [1500] Predicted.\n",
      "Image [1501] Predicted.\n",
      "Image [1502] Predicted.\n",
      "Image [1503] Predicted.\n",
      "Image [1504] Predicted.\n",
      "Image [1505] Predicted.\n",
      "Image [1506] Predicted.\n",
      "Image [1507] Predicted.\n",
      "Image [1508] Predicted.\n",
      "Image [1509] Predicted.\n",
      "Image [1510] Predicted.\n",
      "Image [1511] Predicted.\n",
      "Image [1512] Predicted.\n",
      "Image [1513] Predicted.\n",
      "Image [1514] Predicted.\n",
      "Image [1515] Predicted.\n",
      "Image [1516] Predicted.\n",
      "Image [1517] Predicted.\n",
      "Image [1518] Predicted.\n",
      "Image [1519] Predicted.\n",
      "Image [1520] Predicted.\n",
      "Image [1521] Predicted.\n",
      "Image [1522] Predicted.\n",
      "Image [1523] Predicted.\n",
      "Image [1524] Predicted.\n",
      "Image [1525] Predicted.\n",
      "Image [1526] Predicted.\n",
      "Image [1527] Predicted.\n",
      "Image [1528] Predicted.\n",
      "Image [1529] Predicted.\n",
      "Image [1530] Predicted.\n",
      "Image [1531] Predicted.\n",
      "Image [1532] Predicted.\n",
      "Image [1533] Predicted.\n",
      "Image [1534] Predicted.\n",
      "Image [1535] Predicted.\n",
      "Image [1536] Predicted.\n",
      "Image [1537] Predicted.\n",
      "Image [1538] Predicted.\n",
      "Image [1539] Predicted.\n",
      "Image [1540] Predicted.\n",
      "Image [1541] Predicted.\n",
      "Image [1542] Predicted.\n",
      "Image [1543] Predicted.\n",
      "Image [1544] Predicted.\n",
      "Image [1545] Predicted.\n",
      "Image [1546] Predicted.\n",
      "Image [1547] Predicted.\n",
      "Image [1548] Predicted.\n",
      "Image [1549] Predicted.\n",
      "Image [1550] Predicted.\n",
      "Image [1551] Predicted.\n",
      "Image [1552] Predicted.\n",
      "Image [1553] Predicted.\n",
      "Image [1554] Predicted.\n",
      "Image [1555] Predicted.\n",
      "Image [1556] Predicted.\n",
      "Image [1557] Predicted.\n",
      "Image [1558] Predicted.\n",
      "Image [1559] Predicted.\n",
      "Image [1560] Predicted.\n",
      "Image [1561] Predicted.\n",
      "Image [1562] Predicted.\n",
      "Image [1563] Predicted.\n",
      "Image [1564] Predicted.\n",
      "Image [1565] Predicted.\n",
      "Image [1566] Predicted.\n",
      "Image [1567] Predicted.\n",
      "Image [1568] Predicted.\n",
      "Image [1569] Predicted.\n",
      "Image [1570] Predicted.\n",
      "Image [1571] Predicted.\n",
      "Image [1572] Predicted.\n",
      "Image [1573] Predicted.\n",
      "Image [1574] Predicted.\n",
      "Image [1575] Predicted.\n",
      "Image [1576] Predicted.\n",
      "Image [1577] Predicted.\n",
      "Image [1578] Predicted.\n",
      "Image [1579] Predicted.\n",
      "Image [1580] Predicted.\n",
      "Image [1581] Predicted.\n",
      "Image [1582] Predicted.\n",
      "Image [1583] Predicted.\n",
      "Image [1584] Predicted.\n",
      "Image [1585] Predicted.\n",
      "Image [1586] Predicted.\n",
      "Image [1587] Predicted.\n",
      "Image [1588] Predicted.\n",
      "Image [1589] Predicted.\n",
      "Image [1590] Predicted.\n",
      "Image [1591] Predicted.\n",
      "Image [1592] Predicted.\n",
      "Image [1593] Predicted.\n",
      "Image [1594] Predicted.\n",
      "Image [1595] Predicted.\n",
      "Image [1596] Predicted.\n",
      "Image [1597] Predicted.\n",
      "Image [1598] Predicted.\n",
      "Image [1599] Predicted.\n",
      "Image [1600] Predicted.\n",
      "Image [1601] Predicted.\n",
      "Image [1602] Predicted.\n",
      "Image [1603] Predicted.\n",
      "Image [1604] Predicted.\n",
      "Image [1605] Predicted.\n",
      "Image [1606] Predicted.\n",
      "Image [1607] Predicted.\n",
      "Image [1608] Predicted.\n",
      "Image [1609] Predicted.\n",
      "Image [1610] Predicted.\n",
      "Image [1611] Predicted.\n",
      "Image [1612] Predicted.\n",
      "Image [1613] Predicted.\n",
      "Image [1614] Predicted.\n",
      "Image [1615] Predicted.\n",
      "Image [1616] Predicted.\n",
      "Image [1617] Predicted.\n",
      "Image [1618] Predicted.\n",
      "Image [1619] Predicted.\n",
      "Image [1620] Predicted.\n",
      "Image [1621] Predicted.\n",
      "Image [1622] Predicted.\n",
      "Image [1623] Predicted.\n",
      "Image [1624] Predicted.\n",
      "Image [1625] Predicted.\n",
      "Image [1626] Predicted.\n",
      "Image [1627] Predicted.\n",
      "Image [1628] Predicted.\n",
      "Image [1629] Predicted.\n",
      "Image [1630] Predicted.\n",
      "Image [1631] Predicted.\n",
      "Image [1632] Predicted.\n",
      "Image [1633] Predicted.\n",
      "Image [1634] Predicted.\n",
      "Image [1635] Predicted.\n",
      "Image [1636] Predicted.\n",
      "Image [1637] Predicted.\n",
      "Image [1638] Predicted.\n",
      "Image [1639] Predicted.\n",
      "Image [1640] Predicted.\n",
      "Image [1641] Predicted.\n",
      "Image [1642] Predicted.\n",
      "Image [1643] Predicted.\n",
      "Image [1644] Predicted.\n",
      "Image [1645] Predicted.\n",
      "Image [1646] Predicted.\n",
      "Image [1647] Predicted.\n",
      "Image [1648] Predicted.\n",
      "Image [1649] Predicted.\n",
      "Image [1650] Predicted.\n",
      "Image [1651] Predicted.\n",
      "Image [1652] Predicted.\n",
      "Image [1653] Predicted.\n",
      "Image [1654] Predicted.\n",
      "Image [1655] Predicted.\n",
      "Image [1656] Predicted.\n",
      "Image [1657] Predicted.\n",
      "Image [1658] Predicted.\n",
      "Image [1659] Predicted.\n",
      "Image [1660] Predicted.\n",
      "Image [1661] Predicted.\n",
      "Image [1662] Predicted.\n",
      "Image [1663] Predicted.\n",
      "Image [1664] Predicted.\n",
      "Image [1665] Predicted.\n",
      "Image [1666] Predicted.\n",
      "Image [1667] Predicted.\n",
      "Image [1668] Predicted.\n",
      "Image [1669] Predicted.\n",
      "Image [1670] Predicted.\n",
      "Image [1671] Predicted.\n",
      "Image [1672] Predicted.\n",
      "Image [1673] Predicted.\n",
      "Image [1674] Predicted.\n",
      "Image [1675] Predicted.\n",
      "Image [1676] Predicted.\n",
      "Image [1677] Predicted.\n",
      "Image [1678] Predicted.\n",
      "Image [1679] Predicted.\n",
      "Image [1680] Predicted.\n",
      "Image [1681] Predicted.\n",
      "Image [1682] Predicted.\n",
      "Image [1683] Predicted.\n",
      "Image [1684] Predicted.\n",
      "Image [1685] Predicted.\n",
      "Image [1686] Predicted.\n",
      "Image [1687] Predicted.\n",
      "Image [1688] Predicted.\n",
      "Image [1689] Predicted.\n",
      "Image [1690] Predicted.\n",
      "Image [1691] Predicted.\n",
      "Image [1692] Predicted.\n",
      "Image [1693] Predicted.\n",
      "Image [1694] Predicted.\n",
      "Image [1695] Predicted.\n",
      "Image [1696] Predicted.\n",
      "Image [1697] Predicted.\n",
      "Image [1698] Predicted.\n",
      "Image [1699] Predicted.\n",
      "Image [1700] Predicted.\n",
      "Image [1701] Predicted.\n",
      "Image [1702] Predicted.\n",
      "Image [1703] Predicted.\n",
      "Image [1704] Predicted.\n",
      "Image [1705] Predicted.\n",
      "Image [1706] Predicted.\n",
      "Image [1707] Predicted.\n",
      "Image [1708] Predicted.\n",
      "Image [1709] Predicted.\n",
      "Image [1710] Predicted.\n",
      "Image [1711] Predicted.\n",
      "Image [1712] Predicted.\n",
      "Image [1713] Predicted.\n",
      "Image [1714] Predicted.\n",
      "Image [1715] Predicted.\n",
      "Image [1716] Predicted.\n",
      "Image [1717] Predicted.\n",
      "Image [1718] Predicted.\n",
      "Image [1719] Predicted.\n",
      "Image [1720] Predicted.\n",
      "Image [1721] Predicted.\n",
      "Image [1722] Predicted.\n",
      "Image [1723] Predicted.\n",
      "Image [1724] Predicted.\n",
      "Image [1725] Predicted.\n",
      "Image [1726] Predicted.\n",
      "Image [1727] Predicted.\n",
      "Image [1728] Predicted.\n",
      "Image [1729] Predicted.\n",
      "Image [1730] Predicted.\n",
      "Image [1731] Predicted.\n",
      "Image [1732] Predicted.\n",
      "Image [1733] Predicted.\n",
      "Image [1734] Predicted.\n",
      "Image [1735] Predicted.\n",
      "Image [1736] Predicted.\n",
      "Image [1737] Predicted.\n",
      "Image [1738] Predicted.\n",
      "Image [1739] Predicted.\n",
      "Image [1740] Predicted.\n",
      "Image [1741] Predicted.\n",
      "Image [1742] Predicted.\n",
      "Image [1743] Predicted.\n",
      "Image [1744] Predicted.\n",
      "Image [1745] Predicted.\n",
      "Image [1746] Predicted.\n",
      "Image [1747] Predicted.\n",
      "Image [1748] Predicted.\n",
      "Image [1749] Predicted.\n",
      "Image [1750] Predicted.\n",
      "Image [1751] Predicted.\n",
      "Image [1752] Predicted.\n",
      "Image [1753] Predicted.\n",
      "Image [1754] Predicted.\n",
      "Image [1755] Predicted.\n",
      "Image [1756] Predicted.\n",
      "Image [1757] Predicted.\n",
      "Image [1758] Predicted.\n",
      "Image [1759] Predicted.\n",
      "Image [1760] Predicted.\n",
      "Image [1761] Predicted.\n",
      "Image [1762] Predicted.\n",
      "Image [1763] Predicted.\n",
      "Image [1764] Predicted.\n",
      "Image [1765] Predicted.\n",
      "Image [1766] Predicted.\n",
      "Image [1767] Predicted.\n",
      "Image [1768] Predicted.\n",
      "Image [1769] Predicted.\n",
      "Image [1770] Predicted.\n",
      "Image [1771] Predicted.\n",
      "Image [1772] Predicted.\n",
      "Image [1773] Predicted.\n",
      "Image [1774] Predicted.\n",
      "Image [1775] Predicted.\n",
      "Image [1776] Predicted.\n",
      "Image [1777] Predicted.\n",
      "Image [1778] Predicted.\n",
      "Image [1779] Predicted.\n",
      "Image [1780] Predicted.\n",
      "Image [1781] Predicted.\n",
      "Image [1782] Predicted.\n",
      "Image [1783] Predicted.\n",
      "Image [1784] Predicted.\n",
      "Image [1785] Predicted.\n",
      "Image [1786] Predicted.\n",
      "Image [1787] Predicted.\n",
      "Image [1788] Predicted.\n",
      "Image [1789] Predicted.\n",
      "Image [1790] Predicted.\n",
      "Image [1791] Predicted.\n",
      "Image [1792] Predicted.\n",
      "Image [1793] Predicted.\n",
      "Image [1794] Predicted.\n",
      "Image [1795] Predicted.\n",
      "Image [1796] Predicted.\n",
      "Image [1797] Predicted.\n",
      "Image [1798] Predicted.\n",
      "Image [1799] Predicted.\n",
      "Image [1800] Predicted.\n",
      "Image [1801] Predicted.\n",
      "Image [1802] Predicted.\n",
      "Image [1803] Predicted.\n",
      "Image [1804] Predicted.\n",
      "Image [1805] Predicted.\n",
      "Image [1806] Predicted.\n",
      "Image [1807] Predicted.\n",
      "Image [1808] Predicted.\n",
      "Image [1809] Predicted.\n",
      "Image [1810] Predicted.\n",
      "Image [1811] Predicted.\n",
      "Image [1812] Predicted.\n",
      "Image [1813] Predicted.\n",
      "Image [1814] Predicted.\n",
      "Image [1815] Predicted.\n",
      "Image [1816] Predicted.\n",
      "Image [1817] Predicted.\n",
      "Image [1818] Predicted.\n",
      "Image [1819] Predicted.\n",
      "Image [1820] Predicted.\n",
      "Image [1821] Predicted.\n",
      "Image [1822] Predicted.\n",
      "Image [1823] Predicted.\n",
      "Image [1824] Predicted.\n",
      "Image [1825] Predicted.\n",
      "Image [1826] Predicted.\n",
      "Image [1827] Predicted.\n",
      "Image [1828] Predicted.\n",
      "Image [1829] Predicted.\n",
      "Image [1830] Predicted.\n",
      "Image [1831] Predicted.\n",
      "Image [1832] Predicted.\n",
      "Image [1833] Predicted.\n",
      "Image [1834] Predicted.\n",
      "Image [1835] Predicted.\n",
      "Image [1836] Predicted.\n",
      "Image [1837] Predicted.\n",
      "Image [1838] Predicted.\n",
      "Image [1839] Predicted.\n",
      "Image [1840] Predicted.\n",
      "Image [1841] Predicted.\n",
      "Image [1842] Predicted.\n",
      "Image [1843] Predicted.\n",
      "Image [1844] Predicted.\n",
      "Image [1845] Predicted.\n",
      "Image [1846] Predicted.\n",
      "Image [1847] Predicted.\n",
      "Image [1848] Predicted.\n",
      "Image [1849] Predicted.\n",
      "Image [1850] Predicted.\n",
      "Image [1851] Predicted.\n",
      "Image [1852] Predicted.\n",
      "Image [1853] Predicted.\n",
      "Image [1854] Predicted.\n",
      "Image [1855] Predicted.\n",
      "Image [1856] Predicted.\n",
      "Image [1857] Predicted.\n",
      "Image [1858] Predicted.\n",
      "Image [1859] Predicted.\n",
      "Image [1860] Predicted.\n",
      "Image [1861] Predicted.\n",
      "Image [1862] Predicted.\n",
      "Image [1863] Predicted.\n",
      "Image [1864] Predicted.\n",
      "Image [1865] Predicted.\n",
      "Image [1866] Predicted.\n",
      "Image [1867] Predicted.\n",
      "Image [1868] Predicted.\n",
      "Image [1869] Predicted.\n",
      "Image [1870] Predicted.\n",
      "Image [1871] Predicted.\n",
      "Image [1872] Predicted.\n",
      "Image [1873] Predicted.\n",
      "Image [1874] Predicted.\n",
      "Image [1875] Predicted.\n",
      "Image [1876] Predicted.\n",
      "Image [1877] Predicted.\n",
      "Image [1878] Predicted.\n",
      "Image [1879] Predicted.\n",
      "Image [1880] Predicted.\n",
      "Done\n",
      "Loading test data...\n",
      "Loaded.\n",
      "Predicting test data...\n",
      "Image [0] Predicted.\n",
      "Image [1] Predicted.\n",
      "Image [2] Predicted.\n",
      "Image [3] Predicted.\n",
      "Image [4] Predicted.\n",
      "Image [5] Predicted.\n",
      "Image [6] Predicted.\n",
      "Image [7] Predicted.\n",
      "Image [8] Predicted.\n",
      "Image [9] Predicted.\n",
      "Image [10] Predicted.\n",
      "Image [11] Predicted.\n",
      "Image [12] Predicted.\n",
      "Image [13] Predicted.\n",
      "Image [14] Predicted.\n",
      "Image [15] Predicted.\n",
      "Image [16] Predicted.\n",
      "Image [17] Predicted.\n",
      "Image [18] Predicted.\n",
      "Image [19] Predicted.\n",
      "Image [20] Predicted.\n",
      "Image [21] Predicted.\n",
      "Image [22] Predicted.\n",
      "Image [23] Predicted.\n",
      "Image [24] Predicted.\n",
      "Image [25] Predicted.\n",
      "Image [26] Predicted.\n",
      "Image [27] Predicted.\n",
      "Image [28] Predicted.\n",
      "Image [29] Predicted.\n",
      "Image [30] Predicted.\n",
      "Image [31] Predicted.\n",
      "Image [32] Predicted.\n",
      "Image [33] Predicted.\n",
      "Image [34] Predicted.\n",
      "Image [35] Predicted.\n",
      "Image [36] Predicted.\n",
      "Image [37] Predicted.\n",
      "Image [38] Predicted.\n",
      "Image [39] Predicted.\n",
      "Image [40] Predicted.\n",
      "Image [41] Predicted.\n",
      "Image [42] Predicted.\n",
      "Image [43] Predicted.\n",
      "Image [44] Predicted.\n",
      "Image [45] Predicted.\n",
      "Image [46] Predicted.\n",
      "Image [47] Predicted.\n",
      "Image [48] Predicted.\n",
      "Image [49] Predicted.\n",
      "Image [50] Predicted.\n",
      "Image [51] Predicted.\n",
      "Image [52] Predicted.\n",
      "Image [53] Predicted.\n",
      "Image [54] Predicted.\n",
      "Image [55] Predicted.\n",
      "Image [56] Predicted.\n",
      "Image [57] Predicted.\n",
      "Image [58] Predicted.\n",
      "Image [59] Predicted.\n",
      "Image [60] Predicted.\n",
      "Image [61] Predicted.\n",
      "Image [62] Predicted.\n",
      "Image [63] Predicted.\n",
      "Image [64] Predicted.\n",
      "Image [65] Predicted.\n",
      "Image [66] Predicted.\n",
      "Image [67] Predicted.\n",
      "Image [68] Predicted.\n",
      "Image [69] Predicted.\n",
      "Image [70] Predicted.\n",
      "Image [71] Predicted.\n",
      "Image [72] Predicted.\n",
      "Image [73] Predicted.\n",
      "Image [74] Predicted.\n",
      "Image [75] Predicted.\n",
      "Image [76] Predicted.\n",
      "Image [77] Predicted.\n",
      "Image [78] Predicted.\n",
      "Image [79] Predicted.\n",
      "Image [80] Predicted.\n",
      "Image [81] Predicted.\n",
      "Image [82] Predicted.\n",
      "Image [83] Predicted.\n",
      "Image [84] Predicted.\n",
      "Image [85] Predicted.\n",
      "Image [86] Predicted.\n",
      "Image [87] Predicted.\n",
      "Image [88] Predicted.\n",
      "Image [89] Predicted.\n",
      "Image [90] Predicted.\n",
      "Image [91] Predicted.\n",
      "Image [92] Predicted.\n",
      "Image [93] Predicted.\n",
      "Image [94] Predicted.\n",
      "Image [95] Predicted.\n",
      "Image [96] Predicted.\n",
      "Image [97] Predicted.\n",
      "Image [98] Predicted.\n",
      "Image [99] Predicted.\n",
      "Image [100] Predicted.\n",
      "Image [101] Predicted.\n",
      "Image [102] Predicted.\n",
      "Image [103] Predicted.\n",
      "Image [104] Predicted.\n",
      "Image [105] Predicted.\n",
      "Image [106] Predicted.\n",
      "Image [107] Predicted.\n",
      "Image [108] Predicted.\n",
      "Image [109] Predicted.\n",
      "Image [110] Predicted.\n",
      "Image [111] Predicted.\n",
      "Image [112] Predicted.\n",
      "Image [113] Predicted.\n",
      "Image [114] Predicted.\n",
      "Image [115] Predicted.\n",
      "Image [116] Predicted.\n",
      "Image [117] Predicted.\n",
      "Image [118] Predicted.\n",
      "Image [119] Predicted.\n",
      "Image [120] Predicted.\n",
      "Image [121] Predicted.\n",
      "Image [122] Predicted.\n",
      "Image [123] Predicted.\n",
      "Image [124] Predicted.\n",
      "Image [125] Predicted.\n",
      "Image [126] Predicted.\n",
      "Image [127] Predicted.\n",
      "Image [128] Predicted.\n",
      "Image [129] Predicted.\n",
      "Image [130] Predicted.\n",
      "Image [131] Predicted.\n",
      "Image [132] Predicted.\n",
      "Image [133] Predicted.\n",
      "Image [134] Predicted.\n",
      "Image [135] Predicted.\n",
      "Image [136] Predicted.\n",
      "Image [137] Predicted.\n",
      "Image [138] Predicted.\n",
      "Image [139] Predicted.\n",
      "Image [140] Predicted.\n",
      "Image [141] Predicted.\n",
      "Image [142] Predicted.\n",
      "Image [143] Predicted.\n",
      "Image [144] Predicted.\n",
      "Image [145] Predicted.\n",
      "Image [146] Predicted.\n",
      "Image [147] Predicted.\n",
      "Image [148] Predicted.\n",
      "Image [149] Predicted.\n",
      "Image [150] Predicted.\n",
      "Image [151] Predicted.\n",
      "Image [152] Predicted.\n",
      "Image [153] Predicted.\n",
      "Image [154] Predicted.\n",
      "Image [155] Predicted.\n",
      "Image [156] Predicted.\n",
      "Image [157] Predicted.\n",
      "Image [158] Predicted.\n",
      "Image [159] Predicted.\n",
      "Image [160] Predicted.\n",
      "Image [161] Predicted.\n",
      "Image [162] Predicted.\n",
      "Image [163] Predicted.\n",
      "Image [164] Predicted.\n",
      "Image [165] Predicted.\n",
      "Image [166] Predicted.\n",
      "Image [167] Predicted.\n",
      "Image [168] Predicted.\n",
      "Image [169] Predicted.\n",
      "Image [170] Predicted.\n",
      "Image [171] Predicted.\n",
      "Image [172] Predicted.\n",
      "Image [173] Predicted.\n",
      "Image [174] Predicted.\n",
      "Image [175] Predicted.\n",
      "Image [176] Predicted.\n",
      "Image [177] Predicted.\n",
      "Image [178] Predicted.\n",
      "Image [179] Predicted.\n",
      "Image [180] Predicted.\n",
      "Image [181] Predicted.\n",
      "Image [182] Predicted.\n",
      "Image [183] Predicted.\n",
      "Image [184] Predicted.\n",
      "Image [185] Predicted.\n",
      "Image [186] Predicted.\n",
      "Image [187] Predicted.\n",
      "Image [188] Predicted.\n",
      "Image [189] Predicted.\n",
      "Image [190] Predicted.\n",
      "Image [191] Predicted.\n",
      "Image [192] Predicted.\n",
      "Image [193] Predicted.\n",
      "Image [194] Predicted.\n",
      "Image [195] Predicted.\n",
      "Image [196] Predicted.\n",
      "Image [197] Predicted.\n",
      "Image [198] Predicted.\n",
      "Image [199] Predicted.\n",
      "Image [200] Predicted.\n",
      "Image [201] Predicted.\n",
      "Image [202] Predicted.\n",
      "Image [203] Predicted.\n",
      "Image [204] Predicted.\n",
      "Image [205] Predicted.\n",
      "Image [206] Predicted.\n",
      "Image [207] Predicted.\n",
      "Image [208] Predicted.\n",
      "Image [209] Predicted.\n",
      "Image [210] Predicted.\n",
      "Image [211] Predicted.\n",
      "Image [212] Predicted.\n",
      "Image [213] Predicted.\n",
      "Image [214] Predicted.\n",
      "Image [215] Predicted.\n",
      "Image [216] Predicted.\n",
      "Image [217] Predicted.\n",
      "Image [218] Predicted.\n",
      "Image [219] Predicted.\n",
      "Image [220] Predicted.\n",
      "Image [221] Predicted.\n",
      "Image [222] Predicted.\n",
      "Image [223] Predicted.\n",
      "Image [224] Predicted.\n",
      "Image [225] Predicted.\n",
      "Image [226] Predicted.\n",
      "Image [227] Predicted.\n",
      "Image [228] Predicted.\n",
      "Image [229] Predicted.\n",
      "Image [230] Predicted.\n",
      "Image [231] Predicted.\n",
      "Image [232] Predicted.\n",
      "Image [233] Predicted.\n",
      "Image [234] Predicted.\n",
      "Image [235] Predicted.\n",
      "Image [236] Predicted.\n",
      "Image [237] Predicted.\n",
      "Image [238] Predicted.\n",
      "Image [239] Predicted.\n",
      "Image [240] Predicted.\n",
      "Image [241] Predicted.\n",
      "Image [242] Predicted.\n",
      "Image [243] Predicted.\n",
      "Image [244] Predicted.\n",
      "Image [245] Predicted.\n",
      "Image [246] Predicted.\n",
      "Image [247] Predicted.\n",
      "Image [248] Predicted.\n",
      "Image [249] Predicted.\n",
      "Image [250] Predicted.\n",
      "Image [251] Predicted.\n",
      "Image [252] Predicted.\n",
      "Image [253] Predicted.\n",
      "Image [254] Predicted.\n",
      "Image [255] Predicted.\n",
      "Image [256] Predicted.\n",
      "Image [257] Predicted.\n",
      "Image [258] Predicted.\n",
      "Image [259] Predicted.\n",
      "Image [260] Predicted.\n",
      "Image [261] Predicted.\n",
      "Image [262] Predicted.\n",
      "Image [263] Predicted.\n",
      "Image [264] Predicted.\n",
      "Image [265] Predicted.\n",
      "Image [266] Predicted.\n",
      "Image [267] Predicted.\n",
      "Image [268] Predicted.\n",
      "Image [269] Predicted.\n",
      "Image [270] Predicted.\n",
      "Image [271] Predicted.\n",
      "Image [272] Predicted.\n",
      "Image [273] Predicted.\n",
      "Image [274] Predicted.\n",
      "Image [275] Predicted.\n",
      "Image [276] Predicted.\n",
      "Image [277] Predicted.\n",
      "Image [278] Predicted.\n",
      "Image [279] Predicted.\n",
      "Image [280] Predicted.\n",
      "Image [281] Predicted.\n",
      "Image [282] Predicted.\n",
      "Image [283] Predicted.\n",
      "Image [284] Predicted.\n",
      "Image [285] Predicted.\n",
      "Image [286] Predicted.\n",
      "Image [287] Predicted.\n",
      "Image [288] Predicted.\n",
      "Image [289] Predicted.\n",
      "Image [290] Predicted.\n",
      "Image [291] Predicted.\n",
      "Image [292] Predicted.\n",
      "Image [293] Predicted.\n",
      "Image [294] Predicted.\n",
      "Image [295] Predicted.\n",
      "Image [296] Predicted.\n",
      "Image [297] Predicted.\n",
      "Image [298] Predicted.\n",
      "Image [299] Predicted.\n",
      "Image [300] Predicted.\n",
      "Image [301] Predicted.\n",
      "Image [302] Predicted.\n",
      "Image [303] Predicted.\n",
      "Image [304] Predicted.\n",
      "Image [305] Predicted.\n",
      "Image [306] Predicted.\n",
      "Image [307] Predicted.\n",
      "Image [308] Predicted.\n",
      "Image [309] Predicted.\n",
      "Image [310] Predicted.\n",
      "Image [311] Predicted.\n",
      "Image [312] Predicted.\n",
      "Image [313] Predicted.\n",
      "Image [314] Predicted.\n",
      "Image [315] Predicted.\n",
      "Image [316] Predicted.\n",
      "Image [317] Predicted.\n",
      "Image [318] Predicted.\n",
      "Image [319] Predicted.\n",
      "Image [320] Predicted.\n",
      "Image [321] Predicted.\n",
      "Image [322] Predicted.\n",
      "Image [323] Predicted.\n",
      "Image [324] Predicted.\n",
      "Image [325] Predicted.\n",
      "Image [326] Predicted.\n",
      "Image [327] Predicted.\n",
      "Image [328] Predicted.\n",
      "Image [329] Predicted.\n",
      "Image [330] Predicted.\n",
      "Image [331] Predicted.\n",
      "Image [332] Predicted.\n",
      "Image [333] Predicted.\n",
      "Image [334] Predicted.\n",
      "Image [335] Predicted.\n",
      "Image [336] Predicted.\n",
      "Image [337] Predicted.\n",
      "Image [338] Predicted.\n",
      "Image [339] Predicted.\n",
      "Image [340] Predicted.\n",
      "Image [341] Predicted.\n",
      "Image [342] Predicted.\n",
      "Image [343] Predicted.\n",
      "Image [344] Predicted.\n",
      "Image [345] Predicted.\n",
      "Image [346] Predicted.\n",
      "Image [347] Predicted.\n",
      "Image [348] Predicted.\n",
      "Image [349] Predicted.\n",
      "Image [350] Predicted.\n",
      "Image [351] Predicted.\n",
      "Image [352] Predicted.\n",
      "Image [353] Predicted.\n",
      "Image [354] Predicted.\n",
      "Image [355] Predicted.\n",
      "Image [356] Predicted.\n",
      "Image [357] Predicted.\n",
      "Image [358] Predicted.\n",
      "Image [359] Predicted.\n",
      "Image [360] Predicted.\n",
      "Image [361] Predicted.\n",
      "Image [362] Predicted.\n",
      "Image [363] Predicted.\n",
      "Image [364] Predicted.\n",
      "Image [365] Predicted.\n",
      "Image [366] Predicted.\n",
      "Image [367] Predicted.\n",
      "Image [368] Predicted.\n",
      "Image [369] Predicted.\n",
      "Image [370] Predicted.\n",
      "Image [371] Predicted.\n",
      "Image [372] Predicted.\n",
      "Image [373] Predicted.\n",
      "Image [374] Predicted.\n",
      "Image [375] Predicted.\n",
      "Image [376] Predicted.\n",
      "Image [377] Predicted.\n",
      "Image [378] Predicted.\n",
      "Image [379] Predicted.\n",
      "Image [380] Predicted.\n",
      "Image [381] Predicted.\n",
      "Image [382] Predicted.\n",
      "Image [383] Predicted.\n",
      "Image [384] Predicted.\n",
      "Image [385] Predicted.\n",
      "Image [386] Predicted.\n",
      "Image [387] Predicted.\n",
      "Image [388] Predicted.\n",
      "Image [389] Predicted.\n",
      "Image [390] Predicted.\n",
      "Image [391] Predicted.\n",
      "Image [392] Predicted.\n",
      "Image [393] Predicted.\n",
      "Image [394] Predicted.\n",
      "Image [395] Predicted.\n",
      "Image [396] Predicted.\n",
      "Image [397] Predicted.\n",
      "Image [398] Predicted.\n",
      "Image [399] Predicted.\n",
      "Image [400] Predicted.\n",
      "Image [401] Predicted.\n",
      "Image [402] Predicted.\n",
      "Image [403] Predicted.\n",
      "Image [404] Predicted.\n",
      "Image [405] Predicted.\n",
      "Image [406] Predicted.\n",
      "Image [407] Predicted.\n",
      "Image [408] Predicted.\n",
      "Image [409] Predicted.\n",
      "Image [410] Predicted.\n",
      "Image [411] Predicted.\n",
      "Image [412] Predicted.\n",
      "Image [413] Predicted.\n",
      "Image [414] Predicted.\n",
      "Image [415] Predicted.\n",
      "Image [416] Predicted.\n",
      "Image [417] Predicted.\n",
      "Image [418] Predicted.\n",
      "Image [419] Predicted.\n",
      "Image [420] Predicted.\n",
      "Image [421] Predicted.\n",
      "Image [422] Predicted.\n",
      "Image [423] Predicted.\n",
      "Image [424] Predicted.\n",
      "Image [425] Predicted.\n",
      "Image [426] Predicted.\n",
      "Image [427] Predicted.\n",
      "Image [428] Predicted.\n",
      "Image [429] Predicted.\n",
      "Image [430] Predicted.\n",
      "Image [431] Predicted.\n",
      "Image [432] Predicted.\n",
      "Image [433] Predicted.\n",
      "Image [434] Predicted.\n",
      "Image [435] Predicted.\n",
      "Image [436] Predicted.\n",
      "Image [437] Predicted.\n",
      "Image [438] Predicted.\n",
      "Image [439] Predicted.\n",
      "Image [440] Predicted.\n",
      "Image [441] Predicted.\n",
      "Image [442] Predicted.\n",
      "Image [443] Predicted.\n",
      "Image [444] Predicted.\n",
      "Image [445] Predicted.\n",
      "Image [446] Predicted.\n",
      "Image [447] Predicted.\n",
      "Image [448] Predicted.\n",
      "Image [449] Predicted.\n",
      "Image [450] Predicted.\n",
      "Image [451] Predicted.\n",
      "Image [452] Predicted.\n",
      "Image [453] Predicted.\n",
      "Image [454] Predicted.\n",
      "Image [455] Predicted.\n",
      "Image [456] Predicted.\n",
      "Image [457] Predicted.\n",
      "Image [458] Predicted.\n",
      "Image [459] Predicted.\n",
      "Image [460] Predicted.\n",
      "Image [461] Predicted.\n",
      "Image [462] Predicted.\n",
      "Image [463] Predicted.\n",
      "Image [464] Predicted.\n",
      "Image [465] Predicted.\n",
      "Image [466] Predicted.\n",
      "Image [467] Predicted.\n",
      "Image [468] Predicted.\n",
      "Image [469] Predicted.\n",
      "Image [470] Predicted.\n",
      "Image [471] Predicted.\n",
      "Image [472] Predicted.\n",
      "Image [473] Predicted.\n",
      "Image [474] Predicted.\n",
      "Image [475] Predicted.\n",
      "Image [476] Predicted.\n",
      "Image [477] Predicted.\n",
      "Image [478] Predicted.\n",
      "Image [479] Predicted.\n",
      "Image [480] Predicted.\n",
      "Image [481] Predicted.\n",
      "Image [482] Predicted.\n",
      "Image [483] Predicted.\n",
      "Image [484] Predicted.\n",
      "Image [485] Predicted.\n",
      "Image [486] Predicted.\n",
      "Image [487] Predicted.\n",
      "Image [488] Predicted.\n",
      "Image [489] Predicted.\n",
      "Image [490] Predicted.\n",
      "Image [491] Predicted.\n",
      "Image [492] Predicted.\n",
      "Image [493] Predicted.\n",
      "Image [494] Predicted.\n",
      "Image [495] Predicted.\n",
      "Image [496] Predicted.\n",
      "Image [497] Predicted.\n",
      "Image [498] Predicted.\n",
      "Image [499] Predicted.\n",
      "Image [500] Predicted.\n",
      "Image [501] Predicted.\n",
      "Image [502] Predicted.\n",
      "Image [503] Predicted.\n",
      "Image [504] Predicted.\n",
      "Image [505] Predicted.\n",
      "Image [506] Predicted.\n",
      "Image [507] Predicted.\n",
      "Image [508] Predicted.\n",
      "Image [509] Predicted.\n",
      "Image [510] Predicted.\n",
      "Image [511] Predicted.\n",
      "Image [512] Predicted.\n",
      "Image [513] Predicted.\n",
      "Image [514] Predicted.\n",
      "Image [515] Predicted.\n",
      "Image [516] Predicted.\n",
      "Image [517] Predicted.\n",
      "Image [518] Predicted.\n",
      "Image [519] Predicted.\n",
      "Image [520] Predicted.\n",
      "Image [521] Predicted.\n",
      "Image [522] Predicted.\n",
      "Image [523] Predicted.\n",
      "Image [524] Predicted.\n",
      "Image [525] Predicted.\n",
      "Image [526] Predicted.\n",
      "Image [527] Predicted.\n",
      "Image [528] Predicted.\n",
      "Image [529] Predicted.\n",
      "Image [530] Predicted.\n",
      "Image [531] Predicted.\n",
      "Image [532] Predicted.\n",
      "Image [533] Predicted.\n",
      "Image [534] Predicted.\n",
      "Image [535] Predicted.\n",
      "Image [536] Predicted.\n",
      "Image [537] Predicted.\n",
      "Image [538] Predicted.\n",
      "Image [539] Predicted.\n",
      "Image [540] Predicted.\n",
      "Image [541] Predicted.\n",
      "Image [542] Predicted.\n",
      "Image [543] Predicted.\n",
      "Image [544] Predicted.\n",
      "Image [545] Predicted.\n",
      "Image [546] Predicted.\n",
      "Image [547] Predicted.\n",
      "Image [548] Predicted.\n",
      "Image [549] Predicted.\n",
      "Image [550] Predicted.\n",
      "Image [551] Predicted.\n",
      "Image [552] Predicted.\n",
      "Image [553] Predicted.\n",
      "Image [554] Predicted.\n",
      "Image [555] Predicted.\n",
      "Image [556] Predicted.\n",
      "Image [557] Predicted.\n",
      "Image [558] Predicted.\n",
      "Image [559] Predicted.\n",
      "Image [560] Predicted.\n",
      "Image [561] Predicted.\n",
      "Image [562] Predicted.\n",
      "Image [563] Predicted.\n",
      "Image [564] Predicted.\n",
      "Image [565] Predicted.\n",
      "Image [566] Predicted.\n",
      "Image [567] Predicted.\n",
      "Image [568] Predicted.\n",
      "Image [569] Predicted.\n",
      "Image [570] Predicted.\n",
      "Image [571] Predicted.\n",
      "Image [572] Predicted.\n",
      "Image [573] Predicted.\n",
      "Image [574] Predicted.\n",
      "Image [575] Predicted.\n",
      "Image [576] Predicted.\n",
      "Image [577] Predicted.\n",
      "Image [578] Predicted.\n",
      "Image [579] Predicted.\n",
      "Image [580] Predicted.\n",
      "Image [581] Predicted.\n",
      "Image [582] Predicted.\n",
      "Image [583] Predicted.\n",
      "Image [584] Predicted.\n",
      "Image [585] Predicted.\n",
      "Image [586] Predicted.\n",
      "Image [587] Predicted.\n",
      "Image [588] Predicted.\n",
      "Image [589] Predicted.\n",
      "Image [590] Predicted.\n",
      "Image [591] Predicted.\n",
      "Image [592] Predicted.\n",
      "Image [593] Predicted.\n",
      "Image [594] Predicted.\n",
      "Image [595] Predicted.\n",
      "Image [596] Predicted.\n",
      "Image [597] Predicted.\n",
      "Image [598] Predicted.\n",
      "Image [599] Predicted.\n",
      "Image [600] Predicted.\n",
      "Image [601] Predicted.\n",
      "Image [602] Predicted.\n",
      "Image [603] Predicted.\n",
      "Image [604] Predicted.\n",
      "Image [605] Predicted.\n",
      "Image [606] Predicted.\n",
      "Image [607] Predicted.\n",
      "Image [608] Predicted.\n",
      "Image [609] Predicted.\n",
      "Image [610] Predicted.\n",
      "Image [611] Predicted.\n",
      "Image [612] Predicted.\n",
      "Image [613] Predicted.\n",
      "Image [614] Predicted.\n",
      "Image [615] Predicted.\n",
      "Image [616] Predicted.\n",
      "Image [617] Predicted.\n",
      "Image [618] Predicted.\n",
      "Image [619] Predicted.\n",
      "Image [620] Predicted.\n",
      "Image [621] Predicted.\n",
      "Image [622] Predicted.\n",
      "Image [623] Predicted.\n",
      "Image [624] Predicted.\n",
      "Image [625] Predicted.\n",
      "Image [626] Predicted.\n",
      "Image [627] Predicted.\n",
      "Image [628] Predicted.\n",
      "Image [629] Predicted.\n",
      "Image [630] Predicted.\n",
      "Image [631] Predicted.\n",
      "Image [632] Predicted.\n",
      "Image [633] Predicted.\n",
      "Image [634] Predicted.\n",
      "Image [635] Predicted.\n",
      "Image [636] Predicted.\n",
      "Image [637] Predicted.\n",
      "Image [638] Predicted.\n",
      "Image [639] Predicted.\n",
      "Image [640] Predicted.\n",
      "Image [641] Predicted.\n",
      "Image [642] Predicted.\n",
      "Image [643] Predicted.\n",
      "Image [644] Predicted.\n",
      "Image [645] Predicted.\n",
      "Image [646] Predicted.\n",
      "Image [647] Predicted.\n",
      "Image [648] Predicted.\n",
      "Image [649] Predicted.\n",
      "Image [650] Predicted.\n",
      "Image [651] Predicted.\n",
      "Image [652] Predicted.\n",
      "Image [653] Predicted.\n",
      "Image [654] Predicted.\n",
      "Image [655] Predicted.\n",
      "Image [656] Predicted.\n",
      "Image [657] Predicted.\n",
      "Image [658] Predicted.\n",
      "Image [659] Predicted.\n",
      "Image [660] Predicted.\n",
      "Image [661] Predicted.\n",
      "Image [662] Predicted.\n",
      "Image [663] Predicted.\n",
      "Image [664] Predicted.\n",
      "Image [665] Predicted.\n",
      "Image [666] Predicted.\n",
      "Image [667] Predicted.\n",
      "Image [668] Predicted.\n",
      "Image [669] Predicted.\n",
      "Image [670] Predicted.\n",
      "Image [671] Predicted.\n",
      "Image [672] Predicted.\n",
      "Image [673] Predicted.\n",
      "Image [674] Predicted.\n",
      "Image [675] Predicted.\n",
      "Image [676] Predicted.\n",
      "Image [677] Predicted.\n",
      "Image [678] Predicted.\n",
      "Image [679] Predicted.\n",
      "Image [680] Predicted.\n",
      "Image [681] Predicted.\n",
      "Image [682] Predicted.\n",
      "Image [683] Predicted.\n",
      "Image [684] Predicted.\n",
      "Image [685] Predicted.\n",
      "Image [686] Predicted.\n",
      "Image [687] Predicted.\n",
      "Image [688] Predicted.\n",
      "Image [689] Predicted.\n",
      "Image [690] Predicted.\n",
      "Image [691] Predicted.\n",
      "Image [692] Predicted.\n",
      "Image [693] Predicted.\n",
      "Image [694] Predicted.\n",
      "Image [695] Predicted.\n",
      "Image [696] Predicted.\n",
      "Image [697] Predicted.\n",
      "Image [698] Predicted.\n",
      "Image [699] Predicted.\n",
      "Image [700] Predicted.\n",
      "Image [701] Predicted.\n",
      "Image [702] Predicted.\n",
      "Image [703] Predicted.\n",
      "Image [704] Predicted.\n",
      "Image [705] Predicted.\n",
      "Image [706] Predicted.\n",
      "Image [707] Predicted.\n",
      "Image [708] Predicted.\n",
      "Image [709] Predicted.\n",
      "Image [710] Predicted.\n",
      "Image [711] Predicted.\n",
      "Image [712] Predicted.\n",
      "Image [713] Predicted.\n",
      "Image [714] Predicted.\n",
      "Image [715] Predicted.\n",
      "Image [716] Predicted.\n",
      "Image [717] Predicted.\n",
      "Image [718] Predicted.\n",
      "Image [719] Predicted.\n",
      "Image [720] Predicted.\n",
      "Image [721] Predicted.\n",
      "Image [722] Predicted.\n",
      "Image [723] Predicted.\n",
      "Image [724] Predicted.\n",
      "Image [725] Predicted.\n",
      "Image [726] Predicted.\n",
      "Image [727] Predicted.\n",
      "Image [728] Predicted.\n",
      "Image [729] Predicted.\n",
      "Image [730] Predicted.\n",
      "Image [731] Predicted.\n",
      "Image [732] Predicted.\n",
      "Image [733] Predicted.\n",
      "Image [734] Predicted.\n",
      "Image [735] Predicted.\n",
      "Image [736] Predicted.\n",
      "Image [737] Predicted.\n",
      "Image [738] Predicted.\n",
      "Image [739] Predicted.\n",
      "Image [740] Predicted.\n",
      "Image [741] Predicted.\n",
      "Image [742] Predicted.\n",
      "Image [743] Predicted.\n",
      "Image [744] Predicted.\n",
      "Image [745] Predicted.\n",
      "Image [746] Predicted.\n",
      "Image [747] Predicted.\n",
      "Image [748] Predicted.\n",
      "Image [749] Predicted.\n",
      "Image [750] Predicted.\n",
      "Image [751] Predicted.\n",
      "Image [752] Predicted.\n",
      "Image [753] Predicted.\n",
      "Image [754] Predicted.\n",
      "Image [755] Predicted.\n",
      "Image [756] Predicted.\n",
      "Image [757] Predicted.\n",
      "Image [758] Predicted.\n",
      "Image [759] Predicted.\n",
      "Image [760] Predicted.\n",
      "Image [761] Predicted.\n",
      "Image [762] Predicted.\n",
      "Image [763] Predicted.\n",
      "Image [764] Predicted.\n",
      "Image [765] Predicted.\n",
      "Image [766] Predicted.\n",
      "Image [767] Predicted.\n",
      "Image [768] Predicted.\n",
      "Image [769] Predicted.\n",
      "Image [770] Predicted.\n",
      "Image [771] Predicted.\n",
      "Image [772] Predicted.\n",
      "Image [773] Predicted.\n",
      "Image [774] Predicted.\n",
      "Image [775] Predicted.\n",
      "Image [776] Predicted.\n",
      "Image [777] Predicted.\n",
      "Image [778] Predicted.\n",
      "Image [779] Predicted.\n",
      "Image [780] Predicted.\n",
      "Image [781] Predicted.\n",
      "Image [782] Predicted.\n",
      "Image [783] Predicted.\n",
      "Image [784] Predicted.\n",
      "Image [785] Predicted.\n",
      "Image [786] Predicted.\n",
      "Image [787] Predicted.\n",
      "Image [788] Predicted.\n",
      "Image [789] Predicted.\n",
      "Image [790] Predicted.\n",
      "Image [791] Predicted.\n",
      "Image [792] Predicted.\n",
      "Image [793] Predicted.\n",
      "Image [794] Predicted.\n",
      "Image [795] Predicted.\n",
      "Image [796] Predicted.\n",
      "Image [797] Predicted.\n",
      "Image [798] Predicted.\n",
      "Image [799] Predicted.\n",
      "Image [800] Predicted.\n",
      "Image [801] Predicted.\n",
      "Image [802] Predicted.\n",
      "Image [803] Predicted.\n",
      "Image [804] Predicted.\n",
      "Image [805] Predicted.\n",
      "Image [806] Predicted.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Reshape\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# -- DEFINE CONSTANTS -- #\n",
    "config_dict = {\n",
    "    'layers':[{'units':2048,'activation':'relu'},{'units':1024,'activation':'relu'}],\n",
    "    'img_size':64,\n",
    "    'weights_path': os.getcwd() + '/model0.h5'\n",
    "    }\n",
    "classes = ['coast','forest','highway','inside_city','mountain','Opencountry','street','tallbuilding']\n",
    "data_dir = path1\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print('Load Model')\n",
    "    # -- LOAD Model -- #\n",
    "    model = Model_MLP(config_dict)\n",
    "    print(config_dict['weights_path'])\n",
    "    print('Loaded')\n",
    "\n",
    "    # -- LOAD DATA -- #\n",
    "    print('Loading train data...')\n",
    "    train_getter = DataGetter(data_dir, config_dict['img_size'], classes)\n",
    "    train_getter.load_data()\n",
    "    print('Loaded.')\n",
    "\n",
    "    # -- PREDICT DATA -- #\n",
    "    print('Predicting train data...')\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    for k,(tensor,label) in enumerate(train_getter):\n",
    "        outputs.append(model.predict(tensor))\n",
    "        labels.append(label)\n",
    "        print('Image [{0}] Predicted.'.format(k))\n",
    "    print('Done')\n",
    "\n",
    "    with open('./task2_train_feat.pkl','wb') as file:\n",
    "        pickle.dump(outputs,file)\n",
    "    with open('./task2_train_label.pkl','wb') as file:\n",
    "        pickle.dump(labels,file)\n",
    "    \n",
    "    # -- LOAD DATA -- #\n",
    "    print('Loading test data...')\n",
    "    test_getter = DataGetter(data_dir, config_dict['img_size'], classes, phase='test')\n",
    "    test_getter.load_data()\n",
    "    print('Loaded.')\n",
    "\n",
    "    # -- PREDICT DATA -- #\n",
    "    print('Predicting test data...')\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    for k,(tensor,label) in enumerate(test_getter):\n",
    "        outputs.append(model.predict(tensor))\n",
    "        labels.append(label)\n",
    "        print('Image [{0}] Predicted.'.format(k))\n",
    "    print('Done')\n",
    "\n",
    "    with open('./task2_test_feat.pkl','wb') as file:\n",
    "        pickle.dump(outputs,file)\n",
    "    with open('./task2_test_label.pkl','wb') as file:\n",
    "        pickle.dump(labels,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U5-GVWSaChY"
   },
   "source": [
    "# Applying SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TEeAXulf-pV1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def histogram_intersection_kernel(a, b):\n",
    "    K = np.empty(shape=(a.shape[0], b.shape[0]), dtype=np.float32)\n",
    "    for i in range(a.shape[0]):\n",
    "        K[i] = np.sum(np.minimum(a[i], b), axis=1)\n",
    "    return K\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G4Qsht8weCc5"
   },
   "outputs": [],
   "source": [
    "class Model_MLPatches():\n",
    "    \"\"\"CLASS::Model_MLPatches\"\"\"\n",
    "    def __init__(self,config_dict, phase='train', trained=False):\n",
    "        self.model = self.get_model_structure(config_dict, phase)\n",
    "        if trained:\n",
    "            self.model.load_weights(config_dict['weights_path'])\n",
    "\n",
    "    def get_model_with_layer_name(self,layer_name):\n",
    "        return Model(inputs=self.model.inputs,outputs=self.model.get_layer(layer_name).output)\n",
    "        \n",
    "    def get_model_structure(self,config_dict, phase):\n",
    "        model = Sequential()\n",
    "        size = config_dict['img_size']\n",
    "        model.add(Reshape((size*size*3,),input_shape=(size, size, 3)))\n",
    "        for k,layer in enumerate(config_dict['layers']):\n",
    "            model.add(Dense(units=layer['units'], activation=layer['activation'],name='dense{0}'.format(k)))\n",
    "        if phase is 'train':\n",
    "            model.add(Dense(units=8, activation='softmax'))\n",
    "        else:\n",
    "            model.add(Dense(units=8, activation='linear'))\n",
    "        return model\n",
    "\n",
    "    def predict(self,tensor):\n",
    "        return self.model.predict(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TNHuiE4IfNuG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "\n",
    "class VisualWords():\n",
    "\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def fit(self, descriptors):\n",
    "        self.codebook = MiniBatchKMeans(n_clusters=self.n_clusters,\n",
    "            verbose=False,\n",
    "            batch_size=self.n_clusters*20,\n",
    "            compute_labels=False,\n",
    "            reassignment_ratio=10**-4,\n",
    "            random_state=42)\n",
    "        descriptors = np.vstack(descriptors)\n",
    "        self.codebook.fit(descriptors)\n",
    "\n",
    "    def get_visual_words(self, descriptors):\n",
    "        visual_words = np.empty((len(descriptors), self.n_clusters), dtype=np.float32)\n",
    "        for i, descriptor in enumerate(descriptors):\n",
    "            words = self.codebook.predict(descriptor)\n",
    "            visual_words[i,:] = np.bincount(words, minlength=self.n_clusters)\n",
    "        return visual_words\n",
    "\n",
    "class VisualWordsPyramid():\n",
    "\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def fit(self, descriptors):\n",
    "        self.codebook = MiniBatchKMeans(n_clusters=self.n_clusters,\n",
    "            verbose=False,\n",
    "            batch_size=self.n_clusters*20,\n",
    "            compute_labels=False,\n",
    "            reassignment_ratio=10**-4,\n",
    "            random_state=42)\n",
    "        full_descriptors = []\n",
    "        for des in descriptors:\n",
    "            to_append = []\n",
    "            for subdes in des:\n",
    "                to_append.extend(subdes)\n",
    "            full_descriptors.append(to_append)\n",
    "        full_descriptors = np.vstack(full_descriptors)\n",
    "        self.codebook.fit(full_descriptors)\n",
    "\n",
    "    # def get_visual_words(self, descriptors):\n",
    "    #     visual_words = np.empty((len(descriptors), self.n_clusters*len(descriptors[0])), dtype=np.float32)\n",
    "    #     for i, descriptor in enumerate(descriptors):\n",
    "    #         for j, subdescriptor in enumerate(descriptor):\n",
    "    #             words = self.codebook.predict(subdescriptor)\n",
    "    #             visual_words[i,j*self.n_clusters:(j+1)*self.n_clusters] = np.bincount(words, minlength=self.n_clusters)\n",
    "    #     return visual_words\n",
    "\n",
    "    def get_visual_words(self, descriptors):\n",
    "        visual_words = np.empty((len(descriptors), self.n_clusters*(len(descriptors[0])+1)), dtype=np.float32)\n",
    "        for i, descriptor in enumerate(descriptors):\n",
    "            full_descriptor = []\n",
    "            for subdes in descriptor:\n",
    "                full_descriptor.extend(subdes)\n",
    "            words = self.codebook.predict(full_descriptor)\n",
    "            visual_words[i,:self.n_clusters] = np.bincount(words, minlength=self.n_clusters)\n",
    "\n",
    "            for j, subdescriptor in enumerate(descriptor):\n",
    "                words = self.codebook.predict(subdescriptor)\n",
    "                visual_words[i,(j+1)*self.n_clusters:(j+2)*self.n_clusters] = np.bincount(words, minlength=self.n_clusters)\n",
    "        return visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JagSx0gHdqKK",
    "outputId": "ba1e6aa7-bf46-41f3-bc90-6a4467cf20cb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model..\n",
      "Loaded\n",
      "Get train descriptors...\n",
      "Get test descriptors...\n",
      "Train Visual Words...\n",
      "Trained.\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   47.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.5390749601275917\n",
      "Test accuracy score: 0.43866171003717475\n",
      "Best params: {'C': 0.01, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}\n",
      "\n",
      "All results: {'mean_fit_time': array([1.15183463, 1.1144331 , 1.21177363, 1.23597813, 1.22925515,\n",
      "       1.22979169, 1.24300141, 1.25235453, 1.25770545, 1.36136646,\n",
      "       1.34179606, 1.27591562]), 'std_fit_time': array([0.06858321, 0.07908577, 0.00909694, 0.0135922 , 0.02549342,\n",
      "       0.01727217, 0.01387497, 0.00448138, 0.00296472, 0.01967411,\n",
      "       0.04032944, 0.04528149]), 'mean_score_time': array([0.28782506, 0.2900423 , 0.30185204, 0.30612359, 0.30458121,\n",
      "       0.30722237, 0.30362482, 0.3057126 , 0.30509562, 0.30063887,\n",
      "       0.30162201, 0.2733098 ]), 'std_score_time': array([0.0166974 , 0.0107861 , 0.00539509, 0.00590133, 0.00358776,\n",
      "       0.00621746, 0.00465614, 0.00147469, 0.00438852, 0.00314019,\n",
      "       0.00399577, 0.04525204]), 'param_C': masked_array(data=[0.001389, 0.001389, 0.001389, 0.01, 0.01, 0.01, 0.1,\n",
      "                   0.1, 0.1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.001, 0.0001, 'scale', 0.001, 0.0001, 'scale', 0.001,\n",
      "                   0.0001, 'scale', 0.001, 0.0001, 'scale'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=[<function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001389, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}], 'split0_test_score': array([0.15649867, 0.15649867, 0.15649867, 0.4801061 , 0.4801061 ,\n",
      "       0.4801061 , 0.47480106, 0.47480106, 0.47480106, 0.4137931 ,\n",
      "       0.4137931 , 0.4137931 ]), 'split1_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.46010638, 0.46010638,\n",
      "       0.46010638, 0.46010638, 0.46010638, 0.46010638, 0.39095745,\n",
      "       0.39095745, 0.39095745]), 'split2_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.50531915, 0.50531915,\n",
      "       0.50531915, 0.51329787, 0.51329787, 0.51329787, 0.38297872,\n",
      "       0.38297872, 0.38297872]), 'split3_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.47074468, 0.47074468,\n",
      "       0.47074468, 0.46808511, 0.46808511, 0.46808511, 0.39893617,\n",
      "       0.39893617, 0.39893617]), 'split4_test_score': array([0.15691489, 0.15691489, 0.15691489, 0.25797872, 0.25797872,\n",
      "       0.25797872, 0.23670213, 0.23670213, 0.23670213, 0.21542553,\n",
      "       0.21542553, 0.21542553]), 'mean_test_score': array([0.1552359 , 0.1552359 , 0.1552359 , 0.43485101, 0.43485101,\n",
      "       0.43485101, 0.43059851, 0.43059851, 0.43059851, 0.3604182 ,\n",
      "       0.3604182 , 0.3604182 ]), 'std_test_score': array([0.00120816, 0.00120816, 0.00120816, 0.08969256, 0.08969256,\n",
      "       0.08969256, 0.09865578, 0.09865578, 0.09865578, 0.07320794,\n",
      "       0.07320794, 0.07320794]), 'rank_test_score': array([10, 10, 10,  1,  1,  1,  4,  4,  4,  7,  7,  7], dtype=int32)}\n",
      "CLUSTER: 128\n",
      "Train Visual Words...\n",
      "Trained.\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.7602339181286549\n",
      "Test accuracy score: 0.44981412639405205\n",
      "Best params: {'C': 0.1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}\n",
      "\n",
      "All results: {'mean_fit_time': array([2.08523998, 2.06638379, 2.06535654, 2.05480647, 2.05985641,\n",
      "       2.04840465, 2.07080035, 2.0777071 , 2.06592617, 2.1963521 ,\n",
      "       2.15063729, 2.14543152]), 'std_fit_time': array([0.06531006, 0.03261763, 0.02785528, 0.0340289 , 0.01437351,\n",
      "       0.04529686, 0.01193434, 0.03494619, 0.01061312, 0.0441279 ,\n",
      "       0.02489398, 0.13502491]), 'mean_score_time': array([0.53717089, 0.54147282, 0.52714696, 0.53552046, 0.52357574,\n",
      "       0.52024984, 0.51334291, 0.5225482 , 0.51477799, 0.52320275,\n",
      "       0.51159248, 0.48450875]), 'std_score_time': array([0.02712358, 0.03760563, 0.01406005, 0.02699575, 0.0133173 ,\n",
      "       0.01736063, 0.00606943, 0.01508437, 0.00834699, 0.01412681,\n",
      "       0.00564836, 0.08848572]), 'param_C': masked_array(data=[0.001389, 0.001389, 0.001389, 0.01, 0.01, 0.01, 0.1,\n",
      "                   0.1, 0.1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.001, 0.0001, 'scale', 0.001, 0.0001, 'scale', 0.001,\n",
      "                   0.0001, 'scale', 0.001, 0.0001, 'scale'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=[<function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001389, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}], 'split0_test_score': array([0.15649867, 0.15649867, 0.15649867, 0.4403183 , 0.4403183 ,\n",
      "       0.4403183 , 0.4535809 , 0.4535809 , 0.4535809 , 0.37931034,\n",
      "       0.37931034, 0.37931034]), 'split1_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.45212766, 0.45212766,\n",
      "       0.45212766, 0.47340426, 0.47340426, 0.47340426, 0.35638298,\n",
      "       0.35638298, 0.35638298]), 'split2_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.49734043, 0.49734043,\n",
      "       0.49734043, 0.49734043, 0.49734043, 0.49734043, 0.42553191,\n",
      "       0.42553191, 0.42553191]), 'split3_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.46542553, 0.46542553,\n",
      "       0.46542553, 0.49468085, 0.49468085, 0.49468085, 0.44680851,\n",
      "       0.44680851, 0.44680851]), 'split4_test_score': array([0.15691489, 0.15691489, 0.15691489, 0.24202128, 0.24202128,\n",
      "       0.24202128, 0.23404255, 0.23404255, 0.23404255, 0.19148936,\n",
      "       0.19148936, 0.19148936]), 'mean_test_score': array([0.1552359 , 0.1552359 , 0.1552359 , 0.41944664, 0.41944664,\n",
      "       0.41944664, 0.4306098 , 0.4306098 , 0.4306098 , 0.35990462,\n",
      "       0.35990462, 0.35990462]), 'std_test_score': array([0.00120816, 0.00120816, 0.00120816, 0.09073581, 0.09073581,\n",
      "       0.09073581, 0.0995548 , 0.0995548 , 0.0995548 , 0.09012426,\n",
      "       0.09012426, 0.09012426]), 'rank_test_score': array([10, 10, 10,  4,  4,  4,  1,  1,  1,  7,  7,  7], dtype=int32)}\n",
      "CLUSTER: 256\n",
      "Train Visual Words...\n",
      "Trained.\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.8463583200425305\n",
      "Test accuracy score: 0.43866171003717475\n",
      "Best params: {'C': 0.1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}\n",
      "\n",
      "All results: {'mean_fit_time': array([4.12681623, 4.21534929, 4.19103642, 4.23379259, 4.2224493 ,\n",
      "       4.18347054, 4.24361329, 4.16164055, 4.25517826, 4.25210123,\n",
      "       4.23947959, 3.97125015]), 'std_fit_time': array([0.06539348, 0.08144531, 0.07264437, 0.08968844, 0.11044687,\n",
      "       0.07557764, 0.08957614, 0.04384409, 0.07078512, 0.08370881,\n",
      "       0.02563407, 0.58775521]), 'mean_score_time': array([1.04966121, 1.08546338, 1.05509753, 1.07935452, 1.06443276,\n",
      "       1.06692753, 1.06222663, 1.07371883, 1.06581469, 1.06866288,\n",
      "       1.07042446, 0.97823615]), 'std_score_time': array([0.0343994 , 0.06253325, 0.02966489, 0.04086204, 0.0316233 ,\n",
      "       0.03312362, 0.05789181, 0.04073155, 0.03685017, 0.02723637,\n",
      "       0.01984078, 0.15052909]), 'param_C': masked_array(data=[0.001389, 0.001389, 0.001389, 0.01, 0.01, 0.01, 0.1,\n",
      "                   0.1, 0.1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.001, 0.0001, 'scale', 0.001, 0.0001, 'scale', 0.001,\n",
      "                   0.0001, 'scale', 0.001, 0.0001, 'scale'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=[<function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001389, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}], 'split0_test_score': array([0.15649867, 0.15649867, 0.15649867, 0.37400531, 0.37400531,\n",
      "       0.37400531, 0.48275862, 0.48275862, 0.48275862, 0.42440318,\n",
      "       0.42440318, 0.42440318]), 'split1_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.39361702, 0.39361702,\n",
      "       0.39361702, 0.45744681, 0.45744681, 0.45744681, 0.39893617,\n",
      "       0.39893617, 0.39893617]), 'split2_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.41489362, 0.41489362,\n",
      "       0.41489362, 0.5212766 , 0.5212766 , 0.5212766 , 0.48670213,\n",
      "       0.48670213, 0.48670213]), 'split3_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.43085106, 0.43085106,\n",
      "       0.43085106, 0.48404255, 0.48404255, 0.48404255, 0.43617021,\n",
      "       0.43617021, 0.43617021]), 'split4_test_score': array([0.15691489, 0.15691489, 0.15691489, 0.25797872, 0.25797872,\n",
      "       0.25797872, 0.26861702, 0.26861702, 0.26861702, 0.23670213,\n",
      "       0.23670213, 0.23670213]), 'mean_test_score': array([0.1552359 , 0.1552359 , 0.1552359 , 0.37426915, 0.37426915,\n",
      "       0.37426915, 0.44282832, 0.44282832, 0.44282832, 0.39658276,\n",
      "       0.39658276, 0.39658276]), 'std_test_score': array([0.00120816, 0.00120816, 0.00120816, 0.06123681, 0.06123681,\n",
      "       0.06123681, 0.0894544 , 0.0894544 , 0.0894544 , 0.08488816,\n",
      "       0.08488816, 0.08488816]), 'rank_test_score': array([10, 10, 10,  7,  7,  7,  1,  1,  1,  4,  4,  4], dtype=int32)}\n",
      "CLUSTER: 512\n",
      "Train Visual Words...\n",
      "Trained.\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.9138755980861244\n",
      "Test accuracy score: 0.436183395291202\n",
      "Best params: {'C': 0.1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}\n",
      "\n",
      "All results: {'mean_fit_time': array([7.83242245, 7.90555854, 7.90894108, 7.88882093, 7.84117126,\n",
      "       7.89069939, 7.767208  , 7.86411381, 7.81504807, 7.88123913,\n",
      "       7.81082263, 7.33760653]), 'std_fit_time': array([0.21256069, 0.06083288, 0.07030625, 0.05734805, 0.02149737,\n",
      "       0.16421162, 0.21583331, 0.24817392, 0.26866658, 0.27890032,\n",
      "       0.28257415, 1.3314244 ]), 'mean_score_time': array([1.98171024, 2.00207829, 2.00112529, 2.00625234, 1.97356801,\n",
      "       1.96719122, 1.91705103, 1.93966889, 1.94544683, 1.9316586 ,\n",
      "       1.90757642, 1.7779573 ]), 'std_score_time': array([0.05325597, 0.03212866, 0.01289112, 0.02676971, 0.02606403,\n",
      "       0.09361342, 0.05819558, 0.0659612 , 0.0468448 , 0.04245098,\n",
      "       0.04077482, 0.36643734]), 'param_C': masked_array(data=[0.001389, 0.001389, 0.001389, 0.01, 0.01, 0.01, 0.1,\n",
      "                   0.1, 0.1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.001, 0.0001, 'scale', 0.001, 0.0001, 'scale', 0.001,\n",
      "                   0.0001, 'scale', 0.001, 0.0001, 'scale'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=[<function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>,\n",
      "                   <function histogram_intersection_kernel at 0x7f05c77fe598>],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001389, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.001389, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.01, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 0.1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 0.0001, 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}, {'C': 1, 'gamma': 'scale', 'kernel': <function histogram_intersection_kernel at 0x7f05c77fe598>}], 'split0_test_score': array([0.15649867, 0.15649867, 0.15649867, 0.32360743, 0.32360743,\n",
      "       0.32360743, 0.47480106, 0.47480106, 0.47480106, 0.42970822,\n",
      "       0.42970822, 0.42970822]), 'split1_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.31117021, 0.31117021,\n",
      "       0.31117021, 0.48404255, 0.48404255, 0.48404255, 0.44680851,\n",
      "       0.44680851, 0.44680851]), 'split2_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.34574468, 0.34574468,\n",
      "       0.34574468, 0.55319149, 0.55319149, 0.55319149, 0.48138298,\n",
      "       0.48138298, 0.48138298]), 'split3_test_score': array([0.15425532, 0.15425532, 0.15425532, 0.33244681, 0.33244681,\n",
      "       0.33244681, 0.46276596, 0.46276596, 0.46276596, 0.43085106,\n",
      "       0.43085106, 0.43085106]), 'split4_test_score': array([0.15691489, 0.15691489, 0.15691489, 0.23138298, 0.23138298,\n",
      "       0.23138298, 0.24202128, 0.24202128, 0.24202128, 0.23138298,\n",
      "       0.23138298, 0.23138298]), 'mean_test_score': array([0.1552359 , 0.1552359 , 0.1552359 , 0.30887042, 0.30887042,\n",
      "       0.30887042, 0.44336447, 0.44336447, 0.44336447, 0.40402675,\n",
      "       0.40402675, 0.40402675]), 'std_test_score': array([0.00120816, 0.00120816, 0.00120816, 0.04035425, 0.04035425,\n",
      "       0.04035425, 0.10547079, 0.10547079, 0.10547079, 0.08831672,\n",
      "       0.08831672, 0.08831672]), 'rank_test_score': array([10, 10, 10,  7,  7,  7,  1,  1,  1,  4,  4,  4], dtype=int32)}\n",
      "CLUSTER: 1024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction import image as skImage\n",
    "# from utils.Kernels import histogram_intersection_kernel, softmax\n",
    "# from utils.Model import Model_MLPatches\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "# from utils.VisualWords import VisualWords\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "MODEL_DIR = os.getcwd() + '/Week3/model11.h5'\n",
    "DATASET_DIR = path1\n",
    "PATCH_SIZE = 64\n",
    "LAYER = 'dense0'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Loading Model..')\n",
    "    config_dict = {\n",
    "        'layers':[{'units':3072,'activation':'relu'}],\n",
    "        'img_size':PATCH_SIZE,\n",
    "        'weights_path':MODEL_DIR\n",
    "    \n",
    "    }\n",
    "    mlp_model = Model_MLPatches(config_dict,phase='test',trained=True)\n",
    "    feat_extractor = mlp_model.get_model_with_layer_name(LAYER)\n",
    "    features = feat_extractor.output.shape[1]\n",
    "    print('Loaded')\n",
    "\n",
    "    train_dir = DATASET_DIR+'/train'\n",
    "    test_dir = DATASET_DIR+'/test'\n",
    "    classes = {'coast':0,'forest':1,'highway':2,'inside_city':3,'mountain':4,'Opencountry':5,'street':6,'tallbuilding':7}\n",
    "    num_patches = int(256/PATCH_SIZE)**2\n",
    "\n",
    "    if not os.path.isfile('Week3/task5_train_desc_2.pkl'):\n",
    "        print('Get train descriptors...')\n",
    "        num_img = 1881\n",
    "        count=0\n",
    "        train_desc = []\n",
    "        for class_dir in os.listdir(train_dir):\n",
    "            cls = classes[class_dir]\n",
    "            for imname in os.listdir(os.path.join(train_dir,class_dir)):\n",
    "                im = Image.open(os.path.join(train_dir,class_dir,imname))\n",
    "                patches = skImage.extract_patches_2d(np.array(im), (PATCH_SIZE, PATCH_SIZE), max_patches=num_patches)\n",
    "                out = feat_extractor.predict(patches/255.)\n",
    "                train_desc.append(out)\n",
    "                count += 1\n",
    "        with open('Week3/task5_train_desc_2.pkl','wb') as file:\n",
    "            pickle.dump(train_desc,file)\n",
    "\n",
    "    if not os.path.isfile('Week3/task5_test_desc_2.pkl'):\n",
    "        print('Get test descriptors...')\n",
    "        num_img = 807\n",
    "        count=0\n",
    "        test_desc = []\n",
    "        for class_dir in os.listdir(test_dir):\n",
    "            cls = classes[class_dir]\n",
    "            for imname in os.listdir(os.path.join(test_dir,class_dir)):\n",
    "                im = Image.open(os.path.join(test_dir,class_dir,imname))\n",
    "                patches = skImage.extract_patches_2d(np.array(im), (PATCH_SIZE, PATCH_SIZE), max_patches=num_patches)\n",
    "                out = feat_extractor.predict(patches/255.)\n",
    "                test_desc.append(out)\n",
    "                count += 1\n",
    "        with open('Week3/task5_test_desc_2.pkl','wb') as file:\n",
    "            pickle.dump(test_desc,file)\n",
    "\n",
    "    train_labels = pickle.load(open('task2_train_label.pkl','rb'))\n",
    "    test_labels = pickle.load(open('task2_test_label.pkl','rb'))\n",
    "    train_desc = pickle.load(open('Week3/task5_train_desc_2.pkl','rb'))\n",
    "    test_desc = pickle.load(open('Week3/task5_test_desc_2.pkl','rb'))\n",
    "\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "    best_params = []\n",
    "    N_CLUSTERS = [128, 256, 512, 1024]\n",
    "    for k,n_cluster in enumerate(N_CLUSTERS):\n",
    "        print('Train Visual Words...')\n",
    "        visualWords = VisualWords(n_cluster)\n",
    "        visualWords.fit(train_desc)\n",
    "        feature_train = visualWords.get_visual_words(train_desc)\n",
    "        feature_test = visualWords.get_visual_words(test_desc)\n",
    "        print('Trained.')\n",
    "\n",
    "        K_FOLDS = 5\n",
    "        PARAM_GRID = {'C': [0.001389, 0.01, 0.1, 1], 'kernel': [histogram_intersection_kernel], 'gamma': [1e-3, 1e-4, 'scale']}\n",
    "\n",
    "        cv = GridSearchCV(SVC(), param_grid=PARAM_GRID, cv=K_FOLDS, n_jobs=-1, verbose=5)\n",
    "        cv.fit(feature_train, train_labels)\n",
    "\n",
    "        results_train.append(cv.score(feature_train, train_labels))\n",
    "        results_test.append(cv.score(feature_test, test_labels))\n",
    "        best_params.append(cv.best_params_)\n",
    "\n",
    "        print(\"Train accuracy score: {}\\nTest accuracy score: {}\\nBest params: {}\\n\".format(results_train[-1], results_test[-1], cv.best_params_))\n",
    "        print(\"All results: {}\".format(cv.cv_results_))\n",
    "        print('CLUSTER: {0}'.format(n_cluster))\n",
    "    \n",
    "    with open('Week3/task5_results_2.pkl','wb') as file:\n",
    "        pickle.dump((results_train,results_test,best_params),file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChcFtd21rnUr"
   },
   "source": [
    "Here we are applying the SVM and we are getting a train accuracy of 91% and a test accuracy of 43% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "M3 Week 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
